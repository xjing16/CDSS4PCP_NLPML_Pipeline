{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69e7d352-8d49-4c9e-958a-72d09209c1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "sys.path.insert(1, '../modules/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cfdab91-9c8d-4bbd-9eb2-a7f81e1ceb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_json_array(path):\n",
    "    '''Read JSON given array of dictionaries'''\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as fp:\n",
    "        datas = json.loads(fp.read())\n",
    "    return datas\n",
    "\n",
    "trainData = read_json_array(\"../data/pubmed_data/json_data_synthetic_labels/v2_train.json\")\n",
    "testData = read_json_array(\"../data/pubmed_data/json_data_synthetic_labels/v2_test.json\")\n",
    "gs40Data = read_json_array(\"../data/pubmed_data/json_data_synthetic_labels/testgs.json\")\n",
    "gs91Data = read_json_array(\"../data/pubmed_data/json_data_synthetic_labels/v2_testgs91.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6a1c2e2-7eb0-49cd-a7b4-982d89c82b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import contractions\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "import nltk\n",
    "import logging\n",
    "import re\n",
    "import string\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "#deselect 'no' and 'not' from stop words\n",
    "stop_words.remove('no')\n",
    "stop_words.remove('not')\n",
    "\n",
    "## Do not remove '.' ',' ';' ':'\n",
    "english_punctuations = ['``','?', '（','）','(', ')',\n",
    "                '[', ']', '&', '!', '*', '@', '#', '$', '%','\\\\','\\\"','}','{','=','/','>','<','|','+','_','~']\n",
    "english_punctuations_arr= ''.join(english_punctuations)\n",
    "\n",
    "def sent2words(sent):\n",
    "    '''Pre-process sentence text to words'''\n",
    "    \n",
    "    ## Expand Words\n",
    "    sent = contractions.fix(sent)\n",
    "    \n",
    "    ## Convert sentence to lowercase and strip whitespaces\n",
    "    sent = sent.lower().strip()\n",
    "    \n",
    "    ## Convert unicode characters in sentence to ASCII\n",
    "    sent = unidecode.unidecode(sent)\n",
    "    sent = sent.encode(\"ascii\", \"ignore\").decode()\n",
    "    \n",
    "    ## Remove URL's from Sentence\n",
    "    sent = re.sub('http[s]?://\\S+', '', sent)\n",
    "    \n",
    "    ## Remove words like 2.0-2\n",
    "    sent = re.sub(' \\d*\\.*\\d*\\-+\\d*\\.*\\d* ', ' ', sent)\n",
    "    \n",
    "    # Remove punctuation characters\n",
    "    sent = sent.translate(str.maketrans(english_punctuations_arr,' '*len(english_punctuations_arr)))\n",
    "    \n",
    "    pos, length = {}, {}\n",
    "    words = word_tokenize(sent)\n",
    "    for i, (w, p) in enumerate(nltk.pos_tag(words)):\n",
    "        # Computational features\n",
    "        pos[w] = p\n",
    "        length[w] = len(w)\n",
    "    \n",
    "    # Remove Stop Words\n",
    "    # words = [word for word in word_tokenize(sent) if not word in stop_words]\n",
    "    \n",
    "    # Remove punctuation only strings from sentence\n",
    "    words = [word for word in words if not all(c in string.punctuation for c in word) and len(word)>1]\n",
    "    \n",
    "    # Remove Numericals from sentence\n",
    "    words = [x for x in words if not all(c.isdigit() for c in x)] \n",
    "    \n",
    "    ## Return words, POS tags, lengths of words, processed sentence\n",
    "    return words, pos, length, ' '.join(words)\n",
    "\n",
    "# Mark Keyphrases with BIO Format Labels\n",
    "def mark_keyword_all_sentences(keywords, sentences):\n",
    "\n",
    "    sentence_lengths = [len(sent) for sent in sentences]\n",
    "    logger.debug(\"Sentence length: %s\"%sentence_lengths)\n",
    "\n",
    "    complete_text = []\n",
    "    for sent in sentences:\n",
    "        complete_text.extend(sent)\n",
    "    logger.debug(\"Complete Text: %s\"%complete_text)\n",
    "\n",
    "    complete_text_len = len(complete_text)\n",
    "    mapper = ['O']*complete_text_len\n",
    "    kws = [sent2words(x)[0] for x in keywords]\n",
    "\n",
    "    for kw in kws:\n",
    "        kw_len=len(kw)\n",
    "        if kw_len == 0:\n",
    "            continue\n",
    "        i=0\n",
    "        while i<complete_text_len-kw_len:\n",
    "            if complete_text[i:i+kw_len]==kw and mapper[i:i+kw_len]==['O']*kw_len:\n",
    "                mapper[i:i+kw_len]=['I-KP']*kw_len\n",
    "                mapper[i]='B-KP'\n",
    "            i+=1\n",
    "\n",
    "    final_mapper = []\n",
    "    final_tokens = []\n",
    "    start=0\n",
    "\n",
    "    for slen in sentence_lengths:\n",
    "        final_mapper.append(mapper[start:start+slen])\n",
    "        final_tokens.append(complete_text[start:start+slen])\n",
    "        start+=slen\n",
    "    \n",
    "    return complete_text, final_mapper, final_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78bad0b1-d1fb-4a8f-9a81-e3210ee4e29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBERTtSV(data,filename):\n",
    "    # import csv\n",
    "    # trainCSV = \"../data/trainBERT.tsv\"\n",
    "    f = open(filename,'w')\n",
    "    f.close()\n",
    "\n",
    "    for article in data:\n",
    "        textData = []\n",
    "        for sent in sent_tokenize(article['title']+' '+article['abstract']):\n",
    "            words, _, _, _ = sent2words(sent)\n",
    "            # words.append('.')\n",
    "            textData.append(words)\n",
    "        # textData = [word_tokenize(sent) for sent in sent_tokenize(article['title']+' '+article['abstract'])]\n",
    "        #print(textData)\n",
    "        _, mapper, tokens = mark_keyword_all_sentences(article['keywords'],textData)\n",
    "        with open(filename,'a') as f:\n",
    "        # with open(trainCSV, 'w', encoding='utf8', newline='') as tsv_file:\n",
    "        #     tsv_writer = csv.writer(tsv_file, delimiter='\\t', lineterminator='\\n')\n",
    "        #     tsv_writer.writerow([\"Word\", \"Count\"])\n",
    "            print(\"-DOCSTART- -X- O O\", file=f)\n",
    "            for sentM, sentT in zip(mapper, tokens):\n",
    "                for wordM, wordT in zip(sentM, sentT):\n",
    "                    print(\"{}\\t{}\".format(wordT,wordM), file=f)\n",
    "        # print(mapper, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9da0152f-c2d5-4a2c-9adb-88b207211622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: 3110, Train: 2488.0 Val: 622.0\n",
      "GS Data: 42, GS Train: 33.6 GS Val: 8.4\n"
     ]
    }
   ],
   "source": [
    "totalData = trainData+testData\n",
    "datalen = len(totalData)\n",
    "print(\"Data: {}, Train: {} Val: {}\".format(datalen, datalen*0.8, datalen*0.2))\n",
    "createBERTtSV(totalData[:int(0.8*datalen)],'../data/trainBERT.tsv')\n",
    "createBERTtSV(totalData[int(0.8*datalen):],'../data/valBERT.tsv')\n",
    "createBERTtSV(gs40Data,'../data/finetuneBERT.tsv')\n",
    "gs_datalen = len(gs40Data)\n",
    "print(\"GS Data: {}, GS Train: {} GS Val: {}\".format(gs_datalen, gs_datalen*0.8, gs_datalen*0.2))\n",
    "createBERTtSV(gs40Data[:int(0.8*gs_datalen)],'../data/finetuneBERT_T.tsv')\n",
    "createBERTtSV(gs40Data[int(0.8*gs_datalen):],'../data/finetuneBERT_V.tsv')\n",
    "createBERTtSV(gs91Data,'../data/testBERT.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "299c68ad-5bd5-4ce5-b0c2-c1defe6cc019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m spacy convert trainBERT.tsv ./ -t json -n 1 -c iob\n",
    "# python -m spacy convert valBERT.tsv ./ -t json -n 1 -c iob\n",
    "# python -m spacy convert finetuneBERT.tsv ./ -t json -n 1 -c iob\n",
    "# python -m spacy convert finetuneBERT_T.tsv ./ -t json -n 1 -c iob\n",
    "# python -m spacy convert finetuneBERT_V.tsv ./ -t json -n 1 -c iob\n",
    "# python -m spacy convert testBERT.tsv ./ -t json -n 1 -c iob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3467ad09-2e40-458b-ad26-4c5cd87f1076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m spacy convert trainBERT.json ./ -t spacy\n",
    "# python -m spacy convert valBERT.json ./ -t spacy\n",
    "# python -m spacy convert finetuneBERT.json ./ -t spacy\n",
    "# python -m spacy convert finetuneBERT_T.json ./ -t spacy\n",
    "# python -m spacy convert finetuneBERT_V.json ./ -t spacy\n",
    "# python -m spacy convert testBERT.json ./ -t spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3328c03-ad60-4399-ad7f-266273cef1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (pytorch) [rgoli@node0092 MetaMap-src]$ python -m spacy init fill-config base_config.cfg config.cfg\n",
    "# (pytorch) [rgoli@node0092 MetaMap-src]$ python -m spacy train -g 0 keywordExtraction/config.cfg --output ./cdssBERToutput --paths.train ./data/trainBERT.spacy --paths.dev ./data/valBERT.spacy \n",
    "# ℹ Saving to output directory: cdssBERToutput\n",
    "# ℹ Using GPU: 0\n",
    "\n",
    "# =========================== Initializing pipeline ===========================\n",
    "# [2022-08-21 16:30:21,565] [INFO] Set up nlp object from config\n",
    "# [2022-08-21 16:30:21,573] [INFO] Pipeline: ['transformer', 'ner']\n",
    "# [2022-08-21 16:30:21,576] [INFO] Created vocabulary\n",
    "# [2022-08-21 16:30:21,577] [INFO] Finished initializing nlp object\n",
    "# Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
    "# - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
    "# - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
    "# [2022-08-21 16:30:40,873] [INFO] Initialized pipeline components: ['transformer', 'ner']\n",
    "# ✔ Initialized pipeline\n",
    "\n",
    "# ============================= Training pipeline =============================\n",
    "# ℹ Pipeline: ['transformer', 'ner']\n",
    "# ℹ Initial learn rate: 0.0\n",
    "# E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
    "# ---  ------  -------------  --------  ------  ------  ------  ------\n",
    "#   0       0       11835.34    813.72    0.94    2.13    0.60    0.01\n",
    "\n",
    "#   0     200      368174.14  86589.40   66.50   69.84   63.46    0.66\n",
    "#   0     400       10601.42  16174.71   81.82   81.70   81.95    0.82\n",
    "#   1     600        3710.65   4980.88   75.95   64.41   92.55    0.76\n",
    "#   1     800        4241.40   5441.69   87.19   83.35   91.39    0.87\n",
    "#   2    1000        2000.63   2331.30   89.06   91.56   86.69    0.89\n",
    "#   2    1200        2140.98   2292.71   89.96   90.97   88.98    0.90\n",
    "#   3    1400        2050.20   2001.31   89.92   92.31   87.64    0.90\n",
    "#   3    1600        1542.22   1511.29   91.90   91.72   92.07    0.92\n",
    "#   4    1800        1634.71   1524.12   91.61   90.44   92.81    0.92\n",
    "#   4    2000        1514.30   1392.00   91.19   89.42   93.04    0.91\n",
    "#   5    2200        1266.26   1175.33   90.58   86.93   94.55    0.91\n",
    "#   5    2400        1230.94   1113.63   92.44   92.49   92.38    0.92\n",
    "#   6    2600        1191.09   1025.46   92.35   90.89   93.87    0.92\n",
    "#   6    2800        1018.01    887.95   92.21   89.29   95.32    0.92\n",
    "#   7    3000         741.42    681.03   92.45   91.14   93.81    0.92\n",
    "#   7    3200        1176.01    904.78   92.35   90.27   94.53    0.92\n",
    "#   8    3400        1003.15    802.40   92.36   90.25   94.56    0.92\n",
    "#   8    3600         746.13    616.04   92.11   90.42   93.87    0.92\n",
    "#   9    3800         885.09    706.52   92.16   90.00   94.43    0.92\n",
    "#   9    4000         518.79    446.13   91.90   88.98   95.01    0.92\n",
    "#   9    4200         731.12    590.08   91.22   88.17   94.48    0.91\n",
    "#  10    4400         514.87    433.87   92.89   91.64   94.18    0.93\n",
    "#  10    4600         469.26    420.22   91.79   89.71   93.96    0.92\n",
    "#  11    4800         376.35    356.56   91.44   89.40   93.59    0.91\n",
    "#  11    5000         519.54    433.74   92.48   90.62   94.42    0.92\n",
    "#  12    5200         488.42    404.42   90.82   87.42   94.48    0.91\n",
    "#  12    5400         244.71    248.49   91.50   87.72   95.63    0.92\n",
    "#  13    5600         222.53    252.38   92.75   91.73   93.79    0.93\n",
    "#  13    5800         302.91    291.42   92.11   89.51   94.87    0.92\n",
    "#  14    6000         600.91    489.17   92.24   90.16   94.40    0.92\n",
    "# ✔ Saved pipeline to output directory\n",
    "# cdssBERToutput/model-last\n",
    "# (pytorch) [rgoli@node0092 MetaMap-src]$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b95e9068-8c30-4d60-af50-78d51d024525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rgoli/MetaMap-src/keywordExtraction\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a2602e7-d43f-42fb-97ab-e1f2c656a0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('../cdssBERToutput/model-best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e065937-a2c8-4352-bd10-5536728d1720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTargetPreds(data):\n",
    "    comb_arr = []\n",
    "    for article in data:\n",
    "        comb_arr.append(article['title']+' '+article['abstract'])\n",
    "\n",
    "    y_preds, y_targets = [], []\n",
    "    for idx, doc in enumerate(nlp.pipe(comb_arr)):\n",
    "\n",
    "        kws = [str(x) for x in doc.ents]\n",
    "        textData = []\n",
    "        for sent in sent_tokenize(article['title']+' '+article['abstract']):\n",
    "            words, _, _, _ = sent2words(sent)\n",
    "            textData.append(words)\n",
    "        # textData = [word_tokenize(sent) for sent in sent_tokenize(data[idx]['title']+' '+data[idx]['abstract'])]\n",
    "\n",
    "        _, target, _ = mark_keyword_all_sentences(data[idx]['keywords'],textData)\n",
    "        _, predict, _ = mark_keyword_all_sentences(kws,textData)\n",
    "        #print(gs40Data[idx]['id'],gs40Data[idx]['keywords'],kws,sep='\\n')\n",
    "\n",
    "        #print(target,predict,sep='\\n')\n",
    "        y_preds.extend(predict)\n",
    "        y_targets.extend(target)\n",
    "    \n",
    "    return y_preds, y_targets\n",
    "\n",
    "y_preds, y_targets = getTargetPreds(gs40Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33086467-bd8e-447a-bea8-3e011fa30b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GS42 SeqEval Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          KP       0.41      0.76      0.53       197\n",
      "\n",
      "   micro avg       0.41      0.76      0.53       197\n",
      "   macro avg       0.41      0.76      0.53       197\n",
      "weighted avg       0.41      0.76      0.53       197\n",
      "\n",
      "Precision given by SeqEval: 40.98%\n",
      "Recall given by SeqEval: 76.14%\n",
      "F1-Score given by SeqEval: 53.29%\n",
      "Accuracy given by SeqEval: 96.69%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from seqeval.metrics import classification_report, accuracy_score, f1_score, recall_score, precision_score\n",
    "from seqeval.scheme import IOB2\n",
    "print('GS42 SeqEval Metrics on roberta-base:')\n",
    "print(classification_report(y_targets, y_preds, mode='strict', scheme=IOB2))\n",
    "print(\"Precision given by SeqEval: {:.2f}%\".format(precision_score(y_targets, y_preds)*100))\n",
    "print(\"Recall given by SeqEval: {:.2f}%\".format(recall_score(y_targets, y_preds)*100))\n",
    "print(\"F1-Score given by SeqEval: {:.2f}%\".format(f1_score(y_targets, y_preds)*100))\n",
    "print(\"Accuracy given by SeqEval: {:.2f}%\".format(accuracy_score(y_targets, y_preds)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23a8edf5-02b7-4f7a-8faa-6135a7aceae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GS91 SeqEval Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          KP       0.61      0.86      0.71       347\n",
      "\n",
      "   micro avg       0.61      0.86      0.71       347\n",
      "   macro avg       0.61      0.86      0.71       347\n",
      "weighted avg       0.61      0.86      0.71       347\n",
      "\n",
      "Precision given by SeqEval: 61.19%\n",
      "Recall given by SeqEval: 85.88%\n",
      "F1-Score given by SeqEval: 71.46%\n",
      "Accuracy given by SeqEval: 98.93%\n"
     ]
    }
   ],
   "source": [
    "y_preds, y_targets = getTargetPreds(gs91Data)\n",
    "print('GS91 SeqEval Metrics on roberta-base:')\n",
    "print(classification_report(y_targets, y_preds, mode='strict', scheme=IOB2))\n",
    "print(\"Precision given by SeqEval: {:.2f}%\".format(precision_score(y_targets, y_preds)*100))\n",
    "print(\"Recall given by SeqEval: {:.2f}%\".format(recall_score(y_targets, y_preds)*100))\n",
    "print(\"F1-Score given by SeqEval: {:.2f}%\".format(f1_score(y_targets, y_preds)*100))\n",
    "print(\"Accuracy given by SeqEval: {:.2f}%\".format(accuracy_score(y_targets, y_preds)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f3bf902-9424-4968-b390-d8703ef3dd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GS42 SeqEval Metrics on allenai/scibert_scivocab_cased:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          KP       0.43      0.73      0.54       197\n",
      "\n",
      "   micro avg       0.43      0.73      0.54       197\n",
      "   macro avg       0.43      0.73      0.54       197\n",
      "weighted avg       0.43      0.73      0.54       197\n",
      "\n",
      "Precision given by SeqEval: 43.33%\n",
      "Recall given by SeqEval: 72.59%\n",
      "F1-Score given by SeqEval: 54.27%\n",
      "Accuracy given by SeqEval: 97.09%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from seqeval.metrics import classification_report, accuracy_score, f1_score, recall_score, precision_score\n",
    "from seqeval.scheme import IOB2\n",
    "print('GS42 SeqEval Metrics on allenai/scibert_scivocab_cased:')\n",
    "print(classification_report(y_targets, y_preds, mode='strict', scheme=IOB2))\n",
    "print(\"Precision given by SeqEval: {:.2f}%\".format(precision_score(y_targets, y_preds)*100))\n",
    "print(\"Recall given by SeqEval: {:.2f}%\".format(recall_score(y_targets, y_preds)*100))\n",
    "print(\"F1-Score given by SeqEval: {:.2f}%\".format(f1_score(y_targets, y_preds)*100))\n",
    "print(\"Accuracy given by SeqEval: {:.2f}%\".format(accuracy_score(y_targets, y_preds)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00b779bf-3d8d-4e3f-ad1a-1f90a132706a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GS91 SeqEval Metrics on allenai/scibert_scivocab_cased:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          KP       0.76      0.87      0.81       347\n",
      "\n",
      "   micro avg       0.76      0.87      0.81       347\n",
      "   macro avg       0.76      0.87      0.81       347\n",
      "weighted avg       0.76      0.87      0.81       347\n",
      "\n",
      "Precision given by SeqEval: 76.01%\n",
      "Recall given by SeqEval: 86.74%\n",
      "F1-Score given by SeqEval: 81.02%\n",
      "Accuracy given by SeqEval: 99.37%\n"
     ]
    }
   ],
   "source": [
    "y_preds, y_targets = getTargetPreds(gs91Data)\n",
    "print('GS91 SeqEval Metrics on allenai/scibert_scivocab_cased:')\n",
    "print(classification_report(y_targets, y_preds, mode='strict', scheme=IOB2))\n",
    "print(\"Precision given by SeqEval: {:.2f}%\".format(precision_score(y_targets, y_preds)*100))\n",
    "print(\"Recall given by SeqEval: {:.2f}%\".format(recall_score(y_targets, y_preds)*100))\n",
    "print(\"F1-Score given by SeqEval: {:.2f}%\".format(f1_score(y_targets, y_preds)*100))\n",
    "print(\"Accuracy given by SeqEval: {:.2f}%\".format(accuracy_score(y_targets, y_preds)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3b59519-a794-4240-a286-5664ae081267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from seqeval.metrics import classification_report, accuracy_score, f1_score, recall_score, precision_score\n",
    "from seqeval.scheme import IOB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a9e2d53-c71e-4e74-ad32-b6ef79074111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GS91 SeqEval Metrics on allenai/scibert_scivocab_cased + 42GS Train + 91GS Test:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          KP       0.70      0.58      0.64       347\n",
      "\n",
      "   micro avg       0.70      0.58      0.64       347\n",
      "   macro avg       0.70      0.58      0.64       347\n",
      "weighted avg       0.70      0.58      0.64       347\n",
      "\n",
      "Precision given by SeqEval: 69.90%\n",
      "Recall given by SeqEval: 58.21%\n",
      "F1-Score given by SeqEval: 63.52%\n",
      "Accuracy given by SeqEval: 98.93%\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('../cdssBER42GS/model-best')\n",
    "y_preds, y_targets = getTargetPreds(gs91Data)\n",
    "print('GS91 SeqEval Metrics on allenai/scibert_scivocab_cased + 42GS Train + 91GS Test:\\n')\n",
    "print(classification_report(y_targets, y_preds, mode='strict', scheme=IOB2))\n",
    "print(\"Precision given by SeqEval: {:.2f}%\".format(precision_score(y_targets, y_preds)*100))\n",
    "print(\"Recall given by SeqEval: {:.2f}%\".format(recall_score(y_targets, y_preds)*100))\n",
    "print(\"F1-Score given by SeqEval: {:.2f}%\".format(f1_score(y_targets, y_preds)*100))\n",
    "print(\"Accuracy given by SeqEval: {:.2f}%\".format(accuracy_score(y_targets, y_preds)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ead2abe6-8696-4e90-bbd4-c743a3623383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GS91 SeqEval Metrics on allenai/scibert_scivocab_cased + 91GS Train + 42GS Test:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          KP       0.47      0.71      0.57       197\n",
      "\n",
      "   micro avg       0.47      0.71      0.57       197\n",
      "   macro avg       0.47      0.71      0.57       197\n",
      "weighted avg       0.47      0.71      0.57       197\n",
      "\n",
      "Precision given by SeqEval: 47.46%\n",
      "Recall given by SeqEval: 71.07%\n",
      "F1-Score given by SeqEval: 56.91%\n",
      "Accuracy given by SeqEval: 97.26%\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('../cdssBER91GS/model-best')\n",
    "y_preds, y_targets = getTargetPreds(gs40Data)\n",
    "print('GS91 SeqEval Metrics on allenai/scibert_scivocab_cased + 91GS Train + 42GS Test:\\n')\n",
    "print(classification_report(y_targets, y_preds, mode='strict', scheme=IOB2))\n",
    "print(\"Precision given by SeqEval: {:.2f}%\".format(precision_score(y_targets, y_preds)*100))\n",
    "print(\"Recall given by SeqEval: {:.2f}%\".format(recall_score(y_targets, y_preds)*100))\n",
    "print(\"F1-Score given by SeqEval: {:.2f}%\".format(f1_score(y_targets, y_preds)*100))\n",
    "print(\"Accuracy given by SeqEval: {:.2f}%\".format(accuracy_score(y_targets, y_preds)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4b1c5c2-f5c8-49ac-873a-b027da7889fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GS91 SeqEval Metrics on en_core_sci_lg + 91GS Test:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          KP       0.23      0.59      0.33       347\n",
      "\n",
      "   micro avg       0.23      0.59      0.33       347\n",
      "   macro avg       0.23      0.59      0.33       347\n",
      "weighted avg       0.23      0.59      0.33       347\n",
      "\n",
      "Precision given by SeqEval: 22.67%\n",
      "Recall given by SeqEval: 58.79%\n",
      "F1-Score given by SeqEval: 32.72%\n",
      "Accuracy given by SeqEval: 96.49%\n",
      "\n",
      "GS91 SeqEval Metrics on en_core_sci_lg + 42GS Test:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          KP       0.18      0.62      0.28       197\n",
      "\n",
      "   micro avg       0.18      0.62      0.28       197\n",
      "   macro avg       0.18      0.62      0.28       197\n",
      "weighted avg       0.18      0.62      0.28       197\n",
      "\n",
      "Precision given by SeqEval: 18.07%\n",
      "Recall given by SeqEval: 61.93%\n",
      "F1-Score given by SeqEval: 27.98%\n",
      "Accuracy given by SeqEval: 93.17%\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_sci_lg')\n",
    "y_preds, y_targets = getTargetPreds(gs91Data)\n",
    "print('\\nGS91 SeqEval Metrics on en_core_sci_lg + 91GS Test:\\n')\n",
    "print(classification_report(y_targets, y_preds, mode='strict', scheme=IOB2))\n",
    "print(\"Precision given by SeqEval: {:.2f}%\".format(precision_score(y_targets, y_preds)*100))\n",
    "print(\"Recall given by SeqEval: {:.2f}%\".format(recall_score(y_targets, y_preds)*100))\n",
    "print(\"F1-Score given by SeqEval: {:.2f}%\".format(f1_score(y_targets, y_preds)*100))\n",
    "print(\"Accuracy given by SeqEval: {:.2f}%\".format(accuracy_score(y_targets, y_preds)*100))\n",
    "\n",
    "y_preds, y_targets = getTargetPreds(gs40Data)\n",
    "print('\\nGS91 SeqEval Metrics on en_core_sci_lg + 42GS Test:\\n')\n",
    "print(classification_report(y_targets, y_preds, mode='strict', scheme=IOB2))\n",
    "print(\"Precision given by SeqEval: {:.2f}%\".format(precision_score(y_targets, y_preds)*100))\n",
    "print(\"Recall given by SeqEval: {:.2f}%\".format(recall_score(y_targets, y_preds)*100))\n",
    "print(\"F1-Score given by SeqEval: {:.2f}%\".format(f1_score(y_targets, y_preds)*100))\n",
    "print(\"Accuracy given by SeqEval: {:.2f}%\".format(accuracy_score(y_targets, y_preds)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce34b0bb-ae54-4bef-842a-caec14345745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SeqEval Metrics on en_core_sci_lg + Train/Val 42GS + 91GS Test:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          KP       0.52      0.52      0.52       347\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       347\n",
      "   macro avg       0.52      0.52      0.52       347\n",
      "weighted avg       0.52      0.52      0.52       347\n",
      "\n",
      "Precision given by SeqEval: 52.34%\n",
      "Recall given by SeqEval: 51.59%\n",
      "F1-Score given by SeqEval: 51.96%\n",
      "Accuracy given by SeqEval: 98.53%\n",
      "\n",
      "GS91 SeqEval Metrics on en_core_sci_lg + Train/Val 42GS + 42GS Test:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          KP       0.71      0.92      0.81       197\n",
      "\n",
      "   micro avg       0.71      0.92      0.81       197\n",
      "   macro avg       0.71      0.92      0.81       197\n",
      "weighted avg       0.71      0.92      0.81       197\n",
      "\n",
      "Precision given by SeqEval: 71.37%\n",
      "Recall given by SeqEval: 92.39%\n",
      "F1-Score given by SeqEval: 80.53%\n",
      "Accuracy given by SeqEval: 99.00%\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('../cdssSpacyBERToutput/model-best')\n",
    "y_preds, y_targets = getTargetPreds(gs91Data)\n",
    "print('\\nSeqEval Metrics on en_core_sci_lg + Train/Val 42GS + 91GS Test:\\n')\n",
    "print(classification_report(y_targets, y_preds, mode='strict', scheme=IOB2))\n",
    "print(\"Precision given by SeqEval: {:.2f}%\".format(precision_score(y_targets, y_preds)*100))\n",
    "print(\"Recall given by SeqEval: {:.2f}%\".format(recall_score(y_targets, y_preds)*100))\n",
    "print(\"F1-Score given by SeqEval: {:.2f}%\".format(f1_score(y_targets, y_preds)*100))\n",
    "print(\"Accuracy given by SeqEval: {:.2f}%\".format(accuracy_score(y_targets, y_preds)*100))\n",
    "\n",
    "y_preds, y_targets = getTargetPreds(gs40Data)\n",
    "print('\\nGS91 SeqEval Metrics on en_core_sci_lg + Train/Val 42GS + 42GS Test:\\n')\n",
    "print(classification_report(y_targets, y_preds, mode='strict', scheme=IOB2))\n",
    "print(\"Precision given by SeqEval: {:.2f}%\".format(precision_score(y_targets, y_preds)*100))\n",
    "print(\"Recall given by SeqEval: {:.2f}%\".format(recall_score(y_targets, y_preds)*100))\n",
    "print(\"F1-Score given by SeqEval: {:.2f}%\".format(f1_score(y_targets, y_preds)*100))\n",
    "print(\"Accuracy given by SeqEval: {:.2f}%\".format(accuracy_score(y_targets, y_preds)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93ac0753-d54f-4879-93ec-50bd22704253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SeqEval Metrics on en_core_sci_lg + Train:42GS Val:91GS + 91GS Test:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          KP       0.60      0.51      0.55       347\n",
      "\n",
      "   micro avg       0.60      0.51      0.55       347\n",
      "   macro avg       0.60      0.51      0.55       347\n",
      "weighted avg       0.60      0.51      0.55       347\n",
      "\n",
      "Precision given by SeqEval: 59.80%\n",
      "Recall given by SeqEval: 51.01%\n",
      "F1-Score given by SeqEval: 55.05%\n",
      "Accuracy given by SeqEval: 98.67%\n",
      "\n",
      "GS91 SeqEval Metrics on en_core_sci_lg + Train:42GS Val:91GS + 42GS Test:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          KP       0.63      0.83      0.72       197\n",
      "\n",
      "   micro avg       0.63      0.83      0.72       197\n",
      "   macro avg       0.63      0.83      0.72       197\n",
      "weighted avg       0.63      0.83      0.72       197\n",
      "\n",
      "Precision given by SeqEval: 63.18%\n",
      "Recall given by SeqEval: 82.74%\n",
      "F1-Score given by SeqEval: 71.65%\n",
      "Accuracy given by SeqEval: 98.38%\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('../cdssSpacyBERToutput2/model-best')\n",
    "y_preds, y_targets = getTargetPreds(gs91Data)\n",
    "print('\\nSeqEval Metrics on en_core_sci_lg + Train:42GS Val:91GS + 91GS Test:\\n')\n",
    "print(classification_report(y_targets, y_preds, mode='strict', scheme=IOB2))\n",
    "print(\"Precision given by SeqEval: {:.2f}%\".format(precision_score(y_targets, y_preds)*100))\n",
    "print(\"Recall given by SeqEval: {:.2f}%\".format(recall_score(y_targets, y_preds)*100))\n",
    "print(\"F1-Score given by SeqEval: {:.2f}%\".format(f1_score(y_targets, y_preds)*100))\n",
    "print(\"Accuracy given by SeqEval: {:.2f}%\".format(accuracy_score(y_targets, y_preds)*100))\n",
    "\n",
    "y_preds, y_targets = getTargetPreds(gs40Data)\n",
    "print('\\nGS91 SeqEval Metrics on en_core_sci_lg + Train:42GS Val:91GS + 42GS Test:\\n')\n",
    "print(classification_report(y_targets, y_preds, mode='strict', scheme=IOB2))\n",
    "print(\"Precision given by SeqEval: {:.2f}%\".format(precision_score(y_targets, y_preds)*100))\n",
    "print(\"Recall given by SeqEval: {:.2f}%\".format(recall_score(y_targets, y_preds)*100))\n",
    "print(\"F1-Score given by SeqEval: {:.2f}%\".format(f1_score(y_targets, y_preds)*100))\n",
    "print(\"Accuracy given by SeqEval: {:.2f}%\".format(accuracy_score(y_targets, y_preds)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9896d41a-17ef-4465-8756-4b1155324a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SeqEval Metrics on en_core_sci_lg + Train:33GS Val:9GS + 91GS Test:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          KP       0.68      0.51      0.58       347\n",
      "\n",
      "   micro avg       0.68      0.51      0.58       347\n",
      "   macro avg       0.68      0.51      0.58       347\n",
      "weighted avg       0.68      0.51      0.58       347\n",
      "\n",
      "Precision given by SeqEval: 67.95%\n",
      "Recall given by SeqEval: 50.72%\n",
      "F1-Score given by SeqEval: 58.09%\n",
      "Accuracy given by SeqEval: 98.81%\n",
      "\n",
      "GS91 SeqEval Metrics on en_core_sci_lg + Train:33GS Val:9GS + 42GS Test:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          KP       0.56      0.67      0.61       197\n",
      "\n",
      "   micro avg       0.56      0.67      0.61       197\n",
      "   macro avg       0.56      0.67      0.61       197\n",
      "weighted avg       0.56      0.67      0.61       197\n",
      "\n",
      "Precision given by SeqEval: 55.93%\n",
      "Recall given by SeqEval: 67.01%\n",
      "F1-Score given by SeqEval: 60.97%\n",
      "Accuracy given by SeqEval: 97.83%\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('../cdssSpacyBERToutput3/model-best')\n",
    "y_preds, y_targets = getTargetPreds(gs91Data)\n",
    "print('\\nSeqEval Metrics on en_core_sci_lg + Train:33GS Val:9GS + 91GS Test:\\n')\n",
    "print(classification_report(y_targets, y_preds, mode='strict', scheme=IOB2))\n",
    "print(\"Precision given by SeqEval: {:.2f}%\".format(precision_score(y_targets, y_preds)*100))\n",
    "print(\"Recall given by SeqEval: {:.2f}%\".format(recall_score(y_targets, y_preds)*100))\n",
    "print(\"F1-Score given by SeqEval: {:.2f}%\".format(f1_score(y_targets, y_preds)*100))\n",
    "print(\"Accuracy given by SeqEval: {:.2f}%\".format(accuracy_score(y_targets, y_preds)*100))\n",
    "\n",
    "y_preds, y_targets = getTargetPreds(gs40Data)\n",
    "print('\\nGS91 SeqEval Metrics on en_core_sci_lg + Train:33GS Val:9GS + 42GS Test:\\n')\n",
    "print(classification_report(y_targets, y_preds, mode='strict', scheme=IOB2))\n",
    "print(\"Precision given by SeqEval: {:.2f}%\".format(precision_score(y_targets, y_preds)*100))\n",
    "print(\"Recall given by SeqEval: {:.2f}%\".format(recall_score(y_targets, y_preds)*100))\n",
    "print(\"F1-Score given by SeqEval: {:.2f}%\".format(f1_score(y_targets, y_preds)*100))\n",
    "print(\"Accuracy given by SeqEval: {:.2f}%\".format(accuracy_score(y_targets, y_preds)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0316877e-fb89-4dc9-b1e6-ce7dff3810cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "pytorch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
