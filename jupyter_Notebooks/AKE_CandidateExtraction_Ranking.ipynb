{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pubmed_parser as pp\n",
    "\n",
    "dicts_out = pp.parse_medline_xml('data/pubmed_data/raw_data/44_abstracts_test.xml',\n",
    "                                 year_info_only=False,\n",
    "                                 nlm_category=False,\n",
    "                                 author_list=False,\n",
    "                                 reference_list=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11604796\n",
      "24730353\n",
      "29295283\n",
      "23232759\n",
      "26539547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Existing computer-based ordering systems for physicians provide effective drug-centered checks but offer little assistance for optimizing the overall patient-centered treatment strategy. Evidence-based clinical practice guidelines have been developed to disseminate state-of-the-art information concerning treatment strategy but these guidelines are poorly used in routine practice. The ASTI project aims to design a guideline-based ordering system to enable general practitioners to avoid prescription errors and to improve compliance with best therapeutic practices. The \" critic mode \" operates as a background process and corrects the physician\\'s prescription on the basis of automatically triggered elementary rules that account for isolated guideline recommendations. The \" guided mode \" directs the physician to the best treatment by browsing a comprehensive guideline knowledge base represented as a decision tree. A first prototype, applied to hypertension, is currently under development.',\n",
       " 'OBJECTIVE\\nTo construct a clinical decision support system (CDSS) for undergoing surgery based on domain ontology and rules reasoning in the setting of hospitalized diabetic patients.\\n\\n\\nMATERIALS AND METHODS\\nThe ontology was created with a modified ontology development method, including specification and conceptualization, formalization, implementation, and evaluation and maintenance. The Protégé-Web Ontology Language editor was used to implement the ontology. Embedded clinical knowledge was elicited to complement the domain ontology with formal concept analysis. The decision rules were translated into JENA format, which JENA can use to infer recommendations based on patient clinical situations.\\n\\n\\nRESULTS\\nThe ontology includes 31 classes and 13 properties, plus 38 JENA rules that were built to generate recommendations. The evaluation studies confirmed the correctness of the ontology, acceptance of recommendations, satisfaction with the system, and usefulness of the ontology for glycemic management of diabetic patients undergoing surgery, especially for domain experts.\\n\\n\\nCONCLUSIONS\\nThe contribution of this research is to set up an evidence-based hybrid ontology and an evaluation method for CDSS. The system can help clinicians to achieve inpatient glycemic control in diabetic patients undergoing surgery while avoiding hypoglycemia.',\n",
       " 'Clinical decision support systems (CDSSs) have been proved as an efficient way to improve health care quality. However, the inflexibility in integrating multiple clinical practice guidelines (multi-CPGs), the mass input workload of patient data, and the difficulty in system sharing become barriers of CDSSs implementation. In this paper, we proposed a framework of CDSS for chronic disease based on ontology and service-oriented architecture (SOA) to improve these defects. We used ontology for knowledge base construction on multi-CPGs integration to overcome their differences as well as reduce the input procedure of patient data by ontology reasoning. Furthermore, we built the CDSS on an SOA structure to provide flexibility in system and data sharing, such that patients could get suggestions from the same system for self-management of chronic disease. A typical case was used to validate the CDSS functions and accuracy. Two clients were developed to illustrate the SOA superiority.',\n",
       " 'OBJECTIVES\\nThe purpose of this study was to create a task-based support architecture for developing clinical decision support systems (CDSSs) that assist physicians in making decisions at the point-of-care in the emergency department (ED). The backbone of the proposed architecture was established by a task-based emergency workflow model for a patient-physician encounter.\\n\\n\\nMETHODS\\nThe architecture was designed according to an agent-oriented paradigm. Specifically, we used the O-MaSE (Organization-based Multi-agent System Engineering) method that allows for iterative translation of functional requirements into architectural components (e.g., agents). The agent-oriented paradigm was extended with ontology-driven design to implement ontological models representing knowledge required by specific agents to operate.\\n\\n\\nRESULTS\\nThe task-based architecture allows for the creation of a CDSS that is aligned with the task-based emergency workflow model. It facilitates decoupling of executable components (agents) from embedded domain knowledge (ontological models), thus supporting their interoperability, sharing, and reuse. The generic architecture was implemented as a pilot system, MET3-AE--a CDSS to help with the management of pediatric asthma exacerbation in the ED. The system was evaluated in a hospital ED.\\n\\n\\nCONCLUSIONS\\nThe architecture allows for the creation of a CDSS that integrates support for all tasks from the task-based emergency workflow model, and interacts with hospital information systems. Proposed architecture also allows for reusing and sharing system components and knowledge across disease-specific CDSSs.',\n",
       " 'UNLABELLED\\nThe Learning Health System (LHS) describes linking routine healthcare systems directly with both research translation and knowledge translation as an extension of the evidence-based medicine paradigm, taking advantage of the ubiquitous use of electronic health record (EHR) systems. TRANSFoRm is an EU FP7 project that seeks to develop an infrastructure for the LHS in European primary care.\\n\\n\\nMETHODS\\nThe project is based on three clinical use cases, a genotype-phenotype study in diabetes, a randomised controlled trial with gastroesophageal reflux disease, and a diagnostic decision support system for chest pain, abdominal pain, and shortness of breath.\\n\\n\\nRESULTS\\nFour models were developed (clinical research, clinical data, provenance, and diagnosis) that form the basis of the projects approach to interoperability. These models are maintained as ontologies with binding of terms to define precise data elements. CDISC ODM and SDM standards are extended using an archetype approach to enable a two-level model of individual data elements, representing both research content and clinical content. Separate configurations of the TRANSFoRm tools serve each use case.\\n\\n\\nCONCLUSIONS\\nThe project has been successful in using ontologies and archetypes to develop a highly flexible solution to the problem of heterogeneity of data sources presented by the LHS.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_abstracts = []\n",
    "for x in dicts_out[0:5]: print(x['pmid']);test_abstracts.append(x['abstract'])\n",
    "test_abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_candidate_chunks(text, grammar=r'KT: {(<JJ>* <NN.*>+ <IN>)? <JJ>* <NN.*>+}'):\n",
    "    import itertools, nltk, string\n",
    "    \n",
    "    # exclude candidates that are stop words or entirely punctuation\n",
    "    punct = set(string.punctuation)\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    # tokenize, POS-tag, and chunk using regular expressions\n",
    "    chunker = nltk.chunk.regexp.RegexpParser(grammar)\n",
    "    tagged_sents = nltk.pos_tag_sents(nltk.word_tokenize(sent) for sent in nltk.sent_tokenize(text))\n",
    "    all_chunks = list(itertools.chain.from_iterable(nltk.chunk.tree2conlltags(chunker.parse(tagged_sent))\n",
    "                                                    for tagged_sent in tagged_sents))\n",
    "    # join constituent chunk words into a single chunked phrase\n",
    "    ## candidates = [' '.join(word for word, pos, chunk in group).lower() for key, group in itertools.groupby(all_chunks, lambda (word,pos,chunk): chunk != 'O') if key]\n",
    "    candidates = [' '.join(word for word, pos, chunk in group).lower() for key, group in itertools.groupby(all_chunks, lambda word_features: word_features[2] != 'O') if key]\n",
    "\n",
    "    return [cand for cand in candidates if cand not in stop_words and not all(char in punct for char in cand)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'development', 'guideline-based ordering system', 'routine practice', 'therapeutic practices', 'systems for physicians', 'general practitioners', 'prescription errors', 'critic mode', 'little assistance', 'elementary rules', 'prescription', 'evidence-based clinical practice guidelines', 'hypertension', 'compliance', 'background process', 'first prototype', 'basis', 'asti project', 'state-of-the-art information', 'mode', 'comprehensive guideline knowledge base', 'overall patient-centered treatment strategy', 'physician', 'isolated guideline recommendations', 'decision tree', 'effective drug-centered checks', 'treatment strategy', 'guidelines', 'treatment'}\n",
      "\n",
      "{'usefulness', 'jena format', 'decision rules', 'ontology for glycemic management', 'classes', 'jena', 'methods', 'materials', 'domain ontology', 'diabetic patients', 'domain experts', 'specification', 'correctness', 'evaluation', 'jena rules', 'patient clinical situations', 'research', 'properties', 'modified ontology development method', 'embedded clinical knowledge', 'implementation', 'system', 'protégé-web ontology language editor', 'clinicians', 'evidence-based hybrid ontology', 'acceptance of recommendations', 'contribution', 'clinical decision support system', 'conclusions', 'setting', 'hypoglycemia', 'domain ontology with formal concept analysis', 'satisfaction', 'objective', 'inpatient glycemic control in diabetic patients', 'rules', 'evaluation studies', 'cdss', 'conceptualization', 'recommendations', 'ontology', 'maintenance', 'surgery', 'evaluation method for cdss', 'formalization'}\n",
      "\n",
      "{'clients', 'differences', 'defects', 'typical case', 'multi-cpgs', 'health care quality', 'patients', 'soa structure', 'efficient way', 'multiple clinical practice guidelines', 'same system for self-management', 'soa superiority', 'flexibility in system', 'data', 'chronic disease', 'inflexibility', 'multi-cpgs integration', 'suggestions', 'accuracy', 'clinical decision support systems', 'cdss functions', 'soa', 'become barriers of cdsss implementation', 'input procedure of patient data', 'mass input workload of patient data', 'paper', 'service-oriented architecture', 'difficulty in system', 'cdsss', 'cdss', 'ontology', 'framework of cdss', 'ontology reasoning', 'ontology for knowledge base construction'}\n",
      "\n",
      "{'point-of-care', 'emergency department', 'task-based emergency workflow model', 'sharing', 'study', 'architectural components', 'agents', 'tasks', 'reuse', 'knowledge', 'met3-ae', 'interacts with hospital information systems', 'ontological models', 'system', 'clinical decision support systems', 'organization-based multi-agent system engineering', 'decisions', 'assist physicians', 'method', 'ontology-driven design', 'conclusions', 'agent-oriented paradigm', 'iterative translation of functional requirements', 'generic architecture', 'patient-physician encounter', 'creation', 'e.g.', 'disease-specific cdsss', 'architecture', 'backbone', 'hospital ed', 'support', 'task-based support architecture', 'specific agents', 'executable components', 'cdsss', 'domain knowledge', 'ed', 'purpose', 'o-mase', 'task-based architecture', 'cdss', 'pilot system', 'management of pediatric asthma exacerbation', 'system components', 'methods', 'interoperability'}\n",
      "\n",
      "{'clinical research', 'ehr', 'results', 'archetypes', 'research translation', 'problem of heterogeneity', 'ontologies with binding', 'clinical data', 'advantage', 'provenance', 'routine healthcare systems', 'genotype-phenotype study in diabetes', 'abdominal pain', 'extension', 'diagnosis', 'research content', 'flexible solution', 'projects', 'cdisc odm', 'archetype approach', 'transform tools', 'clinical use cases', 'infrastructure', 'sdm standards', 'ubiquitous use of electronic health record', 'learning health system', 'models', 'terms', 'eu fp7 project', 'shortness of breath', 'conclusions', 'basis', 'ontologies', 'precise data elements', 'diagnostic decision support system for chest pain', 'lhs in european primary care', 'knowledge translation', 'project', 'lhs', 'trial with gastroesophageal reflux disease', 'use case', 'data sources', 'clinical content', 'transform', 'separate configurations', 'methods', 'systems', 'evidence-based medicine paradigm', 'interoperability', 'two-level model of individual data elements'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in test_abstracts:\n",
    "    print(set(extract_candidate_chunks(text)),end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_candidate_words(text, good_tags=set(['JJ','JJR','JJS','NN','NNP','NNS','NNPS'])):\n",
    "    import itertools, nltk, string\n",
    "\n",
    "    # exclude candidates that are stop words or entirely punctuation\n",
    "    punct = set(string.punctuation)\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    # tokenize and POS-tag words\n",
    "    tagged_words = itertools.chain.from_iterable(nltk.pos_tag_sents(nltk.word_tokenize(sent)\n",
    "                                                                    for sent in nltk.sent_tokenize(text)))\n",
    "    # filter on certain POS tags and lowercase all words\n",
    "    candidates = [word.lower() for word, tag in tagged_words\n",
    "                  if tag in good_tags and word.lower() not in stop_words\n",
    "                  and not all(char in punct for char in word)]\n",
    "\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'development', 'checks', 'systems', 'effective', 'base', 'first', 'guideline-based', 'assistance', 'evidence-based', 'patient-centered', 'comprehensive', 'prescription', 'best', 'strategy', 'hypertension', 'compliance', 'physicians', 'state-of-the-art', 'general', 'knowledge', 'tree', 'prototype', 'system', 'errors', 'drug-centered', 'little', 'isolated', 'critic', 'decision', 'practitioners', 'practices', 'practice', 'computer-based', 'clinical', 'basis', 'guideline', 'project', 'asti', 'mode', 'process', 'ordering', 'therapeutic', 'physician', 'routine', 'overall', 'information', 'recommendations', 'background', 'rules', 'guidelines', 'treatment', 'elementary'}\n",
      "\n",
      "{'experts', 'usefulness', 'development', 'acceptance', 'maintenance', 'classes', 'jena', 'patients', 'glycemic', 'materials', 'editor', 'specification', 'correctness', 'concept', 'evaluation', 'evidence-based', 'management', 'situations', 'formal', 'inpatient', 'protégé-web', 'knowledge', 'analysis', 'properties', 'modified', 'research', 'system', 'implementation', 'hybrid', 'diabetic', 'clinicians', 'method', 'decision', 'conclusions', 'language', 'format', 'patient', 'contribution', 'clinical', 'setting', 'hypoglycemia', 'satisfaction', 'support', 'objective', 'domain', 'rules', 'embedded', 'cdss', 'conceptualization', 'recommendations', 'studies', 'control', 'ontology', 'methods', 'surgery', 'formalization'}\n",
      "\n",
      "{'clients', 'differences', 'defects', 'input', 'multi-cpgs', 'service-oriented', 'systems', 'framework', 'integration', 'base', 'patients', 'mass', 'typical', 'become', 'way', 'functions', 'flexibility', 'reasoning', 'superiority', 'data', 'workload', 'inflexibility', 'multiple', 'chronic', 'suggestions', 'difficulty', 'knowledge', 'care', 'system', 'structure', 'implementation', 'accuracy', 'soa', 'construction', 'self-management', 'decision', 'patient', 'health', 'practice', 'clinical', 'efficient', 'paper', 'case', 'architecture', 'support', 'cdsss', 'quality', 'cdss', 'ontology', 'guidelines', 'barriers', 'disease', 'procedure'}\n",
      "\n",
      "{'requirements', 'point-of-care', 'organization-based', 'executable', 'ontological', 'sharing', 'ontology-driven', 'design', 'assist', 'disease-specific', 'functional', 'study', 'paradigm', 'workflow', 'pilot', 'agents', 'management', 'hospital', 'tasks', 'engineering', 'physicians', 'knowledge', 'generic', 'met3-ae', 'task-based', 'pediatric', 'system', 'iterative', 'patient-physician', 'translation', 'models', 'department', 'asthma', 'exacerbation', 'decisions', 'method', 'decision', 'components', 'emergency', 'conclusions', 'interacts', 'clinical', 'multi-agent', 'architectural', 'agent-oriented', 'creation', 'e.g.', 'architecture', 'backbone', 'support', 'reuse', 'domain', 'cdsss', 'ed', 'purpose', 'o-mase', 'specific', 'cdss', 'information', 'encounter', 'model', 'methods', 'systems', 'interoperability'}\n",
      "\n",
      "{'separate', 'successful', 'individual', 'solution', 'chest', 'data', 'provenance', 'precise', 'projects', 'infrastructure', 'standards', 'configurations', 'terms', 'genotype-phenotype', 'ontologies', 'diagnostic', 'abdominal', 'lhs', 'learning', 'archetype', 'elements', 'ehr', 'paradigm', 'extension', 'diagnosis', 'tools', 'care', 'models', 'clinical', 'case', 'heterogeneity', 'transform', 'model', 'interoperability', 'ubiquitous', 'cdisc', 'breath', 'evidence-based', 'flexible', 'advantage', 'primary', 'european', 'knowledge', 'system', 'sdm', 'healthcare', 'translation', 'decision', 'content', 'health', 'diabetes', 'gastroesophageal', 'project', 'binding', 'record', 'support', 'routine', 'approach', 'systems', 'shortness', 'results', 'archetypes', 'medicine', 'study', 'eu', 'research', 'trial', 'odm', 'use', 'conclusions', 'problem', 'basis', 'pain', 'two-level', 'electronic', 'cases', 'fp7', 'reflux', 'sources', 'methods', 'disease'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in test_abstracts:\n",
    "    print(set(extract_candidate_words(text)),end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_keyphrases_by_tfidf(texts, candidates='chunks'):\n",
    "    import gensim, nltk\n",
    "    \n",
    "    # extract candidates from each text in texts, either chunks or words\n",
    "    if candidates == 'chunks':\n",
    "        boc_texts = [extract_candidate_chunks(text) for text in texts]\n",
    "    elif candidates == 'words':\n",
    "        boc_texts = [extract_candidate_words(text) for text in texts]\n",
    "    # make gensim dictionary and corpus\n",
    "    dictionary = gensim.corpora.Dictionary(boc_texts)\n",
    "    corpus = [dictionary.doc2bow(boc_text) for boc_text in boc_texts]\n",
    "    # transform corpus with tf*idf model\n",
    "    tfidf = gensim.models.TfidfModel(corpus)\n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "    \n",
    "    return corpus_tfidf, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.357: physician\n",
      "0.179: asti project\n",
      "0.179: background process\n",
      "0.179: compliance\n",
      "0.179: comprehensive guideline knowledge base\n",
      "0.179: critic mode\n",
      "0.179: decision tree\n",
      "0.179: development\n",
      "0.179: effective drug-centered checks\n",
      "0.179: elementary rules\n",
      "0.179: evidence-based clinical practice guidelines\n",
      "0.179: first prototype\n",
      "0.179: general practitioners\n",
      "0.179: guideline-based ordering system\n",
      "0.179: guidelines\n",
      "0.179: hypertension\n",
      "0.179: isolated guideline recommendations\n",
      "0.179: little assistance\n",
      "0.179: mode\n",
      "0.179: overall patient-centered treatment strategy\n",
      "\n",
      "0.385: surgery\n",
      "0.292: ontology\n",
      "0.257: diabetic patients\n",
      "0.257: recommendations\n",
      "0.146: system\n",
      "0.128: acceptance of recommendations\n",
      "0.128: classes\n",
      "0.128: clinical decision support system\n",
      "0.128: clinicians\n",
      "0.128: conceptualization\n",
      "0.128: contribution\n",
      "0.128: correctness\n",
      "0.128: decision rules\n",
      "0.128: domain experts\n",
      "0.128: domain ontology\n",
      "0.128: domain ontology with formal concept analysis\n",
      "0.128: embedded clinical knowledge\n",
      "0.128: evaluation\n",
      "0.128: evaluation method for cdss\n",
      "0.128: evaluation studies\n",
      "\n",
      "0.343: chronic disease\n",
      "0.171: accuracy\n",
      "0.171: become barriers of cdsss implementation\n",
      "0.171: cdss functions\n",
      "0.171: clients\n",
      "0.171: data\n",
      "0.171: defects\n",
      "0.171: differences\n",
      "0.171: difficulty in system\n",
      "0.171: efficient way\n",
      "0.171: flexibility in system\n",
      "0.171: framework of cdss\n",
      "0.171: health care quality\n",
      "0.171: inflexibility\n",
      "0.171: input procedure of patient data\n",
      "0.171: mass input workload of patient data\n",
      "0.171: multi-cpgs\n",
      "0.171: multi-cpgs integration\n",
      "0.171: multiple clinical practice guidelines\n",
      "0.171: ontology for knowledge base construction\n",
      "\n",
      "0.446: architecture\n",
      "0.335: task-based emergency workflow model\n",
      "0.223: agent-oriented paradigm\n",
      "0.223: agents\n",
      "0.223: creation\n",
      "0.223: ed\n",
      "0.223: ontological models\n",
      "0.112: architectural components\n",
      "0.112: assist physicians\n",
      "0.112: backbone\n",
      "0.112: decisions\n",
      "0.112: disease-specific cdsss\n",
      "0.112: domain knowledge\n",
      "0.112: e.g.\n",
      "0.112: emergency department\n",
      "0.112: executable components\n",
      "0.112: generic architecture\n",
      "0.112: hospital ed\n",
      "0.112: interacts with hospital information systems\n",
      "0.112: iterative translation of functional requirements\n",
      "\n",
      "0.268: lhs\n",
      "0.268: models\n",
      "0.268: project\n",
      "0.134: abdominal pain\n",
      "0.134: advantage\n",
      "0.134: archetype approach\n",
      "0.134: archetypes\n",
      "0.134: cdisc odm\n",
      "0.134: clinical content\n",
      "0.134: clinical data\n",
      "0.134: clinical research\n",
      "0.134: clinical use cases\n",
      "0.134: data sources\n",
      "0.134: diagnosis\n",
      "0.134: diagnostic decision support system for chest pain\n",
      "0.134: ehr\n",
      "0.134: eu fp7 project\n",
      "0.134: evidence-based medicine paradigm\n",
      "0.134: extension\n",
      "0.134: flexible solution\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import heapq \n",
    "from operator import itemgetter\n",
    "\n",
    "tfidfs, id2word = score_keyphrases_by_tfidf(test_abstracts)\n",
    "# fileids = texts.fileids()\n",
    "\n",
    "# Print top keywords by TF-IDF\n",
    "for idx, doc in enumerate(tfidfs):\n",
    "    #print(\"Document '{}' key phrases:\".format(fileids[idx]))\n",
    "    # Get top 20 terms by TF-IDF score\n",
    "    for wid, score in heapq.nlargest(20, doc, key=itemgetter(1)):\n",
    "        print(\"{:0.3f}: {}\".format(score, id2word[wid]))\n",
    "\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_keyphrases_by_textrank(text, n_keywords=0.05):\n",
    "    from itertools import takewhile, tee\n",
    "    import networkx, nltk\n",
    "    \n",
    "    # tokenize for all words, and extract *candidate* words\n",
    "    words = [word.lower()\n",
    "             for sent in nltk.sent_tokenize(text)\n",
    "             for word in nltk.word_tokenize(sent)]\n",
    "    candidates = extract_candidate_words(text)\n",
    "    # build graph, each node is a unique candidate\n",
    "    graph = networkx.Graph()\n",
    "    graph.add_nodes_from(set(candidates))\n",
    "    # iterate over word-pairs, add unweighted edges into graph\n",
    "    def pairwise(iterable):\n",
    "        \"\"\"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\"\"\n",
    "        a, b = tee(iterable)\n",
    "        next(b, None)\n",
    "        return zip(a, b)\n",
    "    for w1, w2 in pairwise(candidates):\n",
    "        if w2:\n",
    "            graph.add_edge(*sorted([w1, w2]))\n",
    "    # score nodes using default pagerank algorithm, sort by score, keep top n_keywords\n",
    "    ranks = networkx.pagerank(graph)\n",
    "    if 0 < n_keywords < 1:\n",
    "        n_keywords = int(round(len(candidates) * n_keywords))\n",
    "    word_ranks = {word_rank[0]: word_rank[1]\n",
    "                  for word_rank in sorted(ranks.items(), key=lambda x: x[1], reverse=True)[:n_keywords]}\n",
    "    keywords = set(word_ranks.keys())\n",
    "    # merge keywords into keyphrases\n",
    "    keyphrases = {}\n",
    "    j = 0\n",
    "    for i, word in enumerate(words):\n",
    "        if i < j:\n",
    "            continue\n",
    "        if word in keywords:\n",
    "            kp_words = list(takewhile(lambda x: x in keywords, words[i:i+10]))\n",
    "            avg_pagerank = sum(word_ranks[w] for w in kp_words) / float(len(kp_words))\n",
    "            keyphrases[' '.join(kp_words)] = avg_pagerank\n",
    "            # counter as hackish way to ensure merged keyphrases are non-overlapping\n",
    "            j = i + len(kp_words)\n",
    "    \n",
    "    return sorted(keyphrases.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('treatment', 0.035435595386177486), ('prescription', 0.0304338902313484), ('guideline', 0.03038849408029296)]\n",
      "\n",
      "[('ontology', 0.09994400148702443), ('clinical', 0.0356274537523074), ('evaluation', 0.03414810855673551), ('recommendations', 0.033103198353565524)]\n",
      "\n",
      "[('soa', 0.04076361751032182), ('cdss', 0.03934718824443082), ('system', 0.038598515429225176), ('ontology', 0.03834964909616907)]\n",
      "\n",
      "[('architecture', 0.0541778824359536), ('task-based architecture', 0.043141343771745055), ('system', 0.03739572555558461), ('system components', 0.03341824682594001), ('task-based', 0.032104805107536515), ('components', 0.029440768096295415), ('ed', 0.028745688609939896)]\n",
      "\n",
      "[('data', 0.030239250904916765), ('clinical data', 0.027035401505245707), ('use', 0.026148841959380175), ('project', 0.025532042634200194), ('clinical use', 0.024990197032477415), ('clinical', 0.023831552105574652), ('lhs', 0.02218841241579772)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in test_abstracts:\n",
    "    print(score_keyphrases_by_textrank(text),end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_candidate_features(candidates, doc_text, doc_excerpt, doc_title):\n",
    "    import collections, math, nltk, re\n",
    "    \n",
    "    candidate_scores = collections.OrderedDict()\n",
    "    \n",
    "    # get word counts for document\n",
    "    doc_word_counts = collections.Counter(word.lower()\n",
    "                                          for sent in nltk.sent_tokenize(doc_text)\n",
    "                                          for word in nltk.word_tokenize(sent))\n",
    "    \n",
    "    for candidate in candidates:\n",
    "        \n",
    "        pattern = re.compile(r'\\b'+re.escape(candidate)+r'(\\b|[,;.!?]|\\s)', re.IGNORECASE)\n",
    "        \n",
    "        # frequency-based\n",
    "        # number of times candidate appears in document\n",
    "        cand_doc_count = len(pattern.findall(doc_text))\n",
    "        # count could be 0 for multiple reasons; shit happens in a simplified example\n",
    "        if not cand_doc_count:\n",
    "            print('**WARNING:', candidate, 'not found!')\n",
    "            continue\n",
    "    \n",
    "        # statistical\n",
    "        candidate_words = candidate.split()\n",
    "        max_word_length = max(len(w) for w in candidate_words)\n",
    "        term_length = len(candidate_words)\n",
    "        # get frequencies for term and constituent words\n",
    "        sum_doc_word_counts = float(sum(doc_word_counts[w] for w in candidate_words))\n",
    "        try:\n",
    "            # lexical cohesion doesn't make sense for 1-word terms\n",
    "            if term_length == 1:\n",
    "                lexical_cohesion = 0.0\n",
    "            else:\n",
    "                lexical_cohesion = term_length * (1 + math.log(cand_doc_count, 10)) * cand_doc_count / sum_doc_word_counts\n",
    "        except (ValueError, ZeroDivisionError) as e:\n",
    "            lexical_cohesion = 0.0\n",
    "        \n",
    "        # positional\n",
    "        # found in title, key excerpt\n",
    "        in_title = 1 if pattern.search(doc_title) else 0\n",
    "        in_excerpt = 1 if pattern.search(doc_excerpt) else 0\n",
    "        # first/last position, difference between them (spread)\n",
    "        doc_text_length = float(len(doc_text))\n",
    "        first_match = pattern.search(doc_text)\n",
    "        abs_first_occurrence = first_match.start() / doc_text_length\n",
    "        if cand_doc_count == 1:\n",
    "            spread = 0.0\n",
    "            abs_last_occurrence = abs_first_occurrence\n",
    "        else:\n",
    "            for last_match in pattern.finditer(doc_text):\n",
    "                pass\n",
    "            abs_last_occurrence = last_match.start() / doc_text_length\n",
    "            spread = abs_last_occurrence - abs_first_occurrence\n",
    "\n",
    "        candidate_scores[candidate] = {'term_count': cand_doc_count,\n",
    "                                       'term_length': term_length, 'max_word_length': max_word_length,\n",
    "                                       'spread': spread, 'lexical_cohesion': lexical_cohesion,\n",
    "                                       'in_excerpt': in_excerpt, 'in_title': in_title,\n",
    "                                       'abs_first_occurrence': abs_first_occurrence,\n",
    "                                       'abs_last_occurrence': abs_last_occurrence}\n",
    "\n",
    "    return candidate_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('development',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 11,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.9879759519038076,\n",
       "               'abs_last_occurrence': 0.9879759519038076}),\n",
       "             ('guideline-based ordering system',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 3,\n",
       "               'max_word_length': 15,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.75,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.41783567134268534,\n",
       "               'abs_last_occurrence': 0.41783567134268534}),\n",
       "             ('routine practice',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 2,\n",
       "               'max_word_length': 8,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.6666666666666666,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.3657314629258517,\n",
       "               'abs_last_occurrence': 0.3657314629258517}),\n",
       "             ('therapeutic practices',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 2,\n",
       "               'max_word_length': 11,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 1.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.5470941883767535,\n",
       "               'abs_last_occurrence': 0.5470941883767535}),\n",
       "             ('systems for physicians',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 3,\n",
       "               'max_word_length': 10,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.6,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.033066132264529056,\n",
       "               'abs_last_occurrence': 0.033066132264529056}),\n",
       "             ('general practitioners',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 2,\n",
       "               'max_word_length': 13,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 1.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.45991983967935873,\n",
       "               'abs_last_occurrence': 0.45991983967935873}),\n",
       "             ('prescription errors',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 2,\n",
       "               'max_word_length': 12,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.6666666666666666,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.4909819639278557,\n",
       "               'abs_last_occurrence': 0.4909819639278557}),\n",
       "             ('critic mode',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 2,\n",
       "               'max_word_length': 6,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.6666666666666666,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.5761523046092184,\n",
       "               'abs_last_occurrence': 0.5761523046092184}),\n",
       "             ('little assistance',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 2,\n",
       "               'max_word_length': 10,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 1.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.10521042084168336,\n",
       "               'abs_last_occurrence': 0.10521042084168336}),\n",
       "             ('elementary rules',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 2,\n",
       "               'max_word_length': 10,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 1.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.7054108216432866,\n",
       "               'abs_last_occurrence': 0.7054108216432866}),\n",
       "             ('prescription',\n",
       "              {'term_count': 2,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 12,\n",
       "               'spread': 0.1613226452905812,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.4909819639278557,\n",
       "               'abs_last_occurrence': 0.6523046092184369}),\n",
       "             ('evidence-based clinical practice guidelines',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 4,\n",
       "               'max_word_length': 14,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.6666666666666666,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.187374749498998,\n",
       "               'abs_last_occurrence': 0.187374749498998}),\n",
       "             ('hypertension',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 12,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.9549098196392786,\n",
       "               'abs_last_occurrence': 0.9549098196392786}),\n",
       "             ('compliance',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 10,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.5260521042084169,\n",
       "               'abs_last_occurrence': 0.5260521042084169}),\n",
       "             ('background process',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 2,\n",
       "               'max_word_length': 10,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 1.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.6042084168336673,\n",
       "               'abs_last_occurrence': 0.6042084168336673}),\n",
       "             ('first prototype',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 2,\n",
       "               'max_word_length': 9,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 1.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.9268537074148296,\n",
       "               'abs_last_occurrence': 0.9268537074148296}),\n",
       "             ('basis',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 5,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.6723446893787575,\n",
       "               'abs_last_occurrence': 0.6723446893787575}),\n",
       "             ('asti project',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 2,\n",
       "               'max_word_length': 7,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 1.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.3877755511022044,\n",
       "               'abs_last_occurrence': 0.3877755511022044}),\n",
       "             ('state-of-the-art information',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 2,\n",
       "               'max_word_length': 16,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 1.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.2665330661322645,\n",
       "               'abs_last_occurrence': 0.2665330661322645}),\n",
       "             ('mode',\n",
       "              {'term_count': 2,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 4,\n",
       "               'spread': 0.2054108216432865,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.5831663326653307,\n",
       "               'abs_last_occurrence': 0.7885771543086172}),\n",
       "             ('comprehensive guideline knowledge base',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 4,\n",
       "               'max_word_length': 13,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.8,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.8537074148296593,\n",
       "               'abs_last_occurrence': 0.8537074148296593}),\n",
       "             ('overall patient-centered treatment strategy',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 4,\n",
       "               'max_word_length': 16,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.5714285714285714,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.14228456913827656,\n",
       "               'abs_last_occurrence': 0.14228456913827656}),\n",
       "             ('physician',\n",
       "              {'term_count': 2,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 9,\n",
       "               'spread': 0.16733466933867736,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.6402805611222445,\n",
       "               'abs_last_occurrence': 0.8076152304609219}),\n",
       "             ('isolated guideline recommendations',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 3,\n",
       "               'max_word_length': 15,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.75,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.7394789579158316,\n",
       "               'abs_last_occurrence': 0.7394789579158316}),\n",
       "             ('decision tree',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 2,\n",
       "               'max_word_length': 8,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 1.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.9098196392785571,\n",
       "               'abs_last_occurrence': 0.9098196392785571}),\n",
       "             ('effective drug-centered checks',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 3,\n",
       "               'max_word_length': 13,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 1.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.06412825651302605,\n",
       "               'abs_last_occurrence': 0.06412825651302605}),\n",
       "             ('treatment strategy',\n",
       "              {'term_count': 2,\n",
       "               'term_length': 2,\n",
       "               'max_word_length': 9,\n",
       "               'spread': 0.13927855711422843,\n",
       "               'lexical_cohesion': 1.040823996531185,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.16733466933867736,\n",
       "               'abs_last_occurrence': 0.3066132264529058}),\n",
       "             ('guidelines',\n",
       "              {'term_count': 2,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 10,\n",
       "               'spread': 0.11523046092184369,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.22044088176352705,\n",
       "               'abs_last_occurrence': 0.33567134268537074}),\n",
       "             ('treatment',\n",
       "              {'term_count': 3,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 9,\n",
       "               'spread': 0.6623246492985972,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.16733466933867736,\n",
       "               'abs_last_occurrence': 0.8296593186372746}),\n",
       "             ('checks',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 6,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.08817635270541083,\n",
       "               'abs_last_occurrence': 0.08817635270541083}),\n",
       "             ('systems',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 7,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.033066132264529056,\n",
       "               'abs_last_occurrence': 0.033066132264529056}),\n",
       "             ('effective',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 9,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.06412825651302605,\n",
       "               'abs_last_occurrence': 0.06412825651302605}),\n",
       "             ('base',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 4,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.8877755511022044,\n",
       "               'abs_last_occurrence': 0.8877755511022044}),\n",
       "             ('first',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 5,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.9268537074148296,\n",
       "               'abs_last_occurrence': 0.9268537074148296}),\n",
       "             ('guideline-based',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 15,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 1,\n",
       "               'abs_first_occurrence': 0.41783567134268534,\n",
       "               'abs_last_occurrence': 0.41783567134268534}),\n",
       "             ('assistance',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 10,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.11222444889779559,\n",
       "               'abs_last_occurrence': 0.11222444889779559}),\n",
       "             ('evidence-based',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 14,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.187374749498998,\n",
       "               'abs_last_occurrence': 0.187374749498998}),\n",
       "             ('patient-centered',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 16,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.15030060120240482,\n",
       "               'abs_last_occurrence': 0.15030060120240482}),\n",
       "             ('comprehensive',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 13,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.8537074148296593,\n",
       "               'abs_last_occurrence': 0.8537074148296593}),\n",
       "             ('best',\n",
       "              {'term_count': 2,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 4,\n",
       "               'spread': 0.282565130260521,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.5420841683366734,\n",
       "               'abs_last_occurrence': 0.8246492985971944}),\n",
       "             ('strategy',\n",
       "              {'term_count': 2,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 8,\n",
       "               'spread': 0.13927855711422843,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.17735470941883769,\n",
       "               'abs_last_occurrence': 0.3166332665330661}),\n",
       "             ('physicians',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 10,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.045090180360721446,\n",
       "               'abs_last_occurrence': 0.045090180360721446}),\n",
       "             ('state-of-the-art',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 16,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.2665330661322645,\n",
       "               'abs_last_occurrence': 0.2665330661322645}),\n",
       "             ('general',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 7,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.45991983967935873,\n",
       "               'abs_last_occurrence': 0.45991983967935873}),\n",
       "             ('knowledge',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 9,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.8777555110220441,\n",
       "               'abs_last_occurrence': 0.8777555110220441}),\n",
       "             ('tree',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 4,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.9188376753507014,\n",
       "               'abs_last_occurrence': 0.9188376753507014}),\n",
       "             ('prototype',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 9,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.9328657314629258,\n",
       "               'abs_last_occurrence': 0.9328657314629258}),\n",
       "             ('system',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 6,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 1,\n",
       "               'abs_first_occurrence': 0.44288577154308617,\n",
       "               'abs_last_occurrence': 0.44288577154308617}),\n",
       "             ('errors',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 6,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.5040080160320641,\n",
       "               'abs_last_occurrence': 0.5040080160320641}),\n",
       "             ('drug-centered',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 13,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.07414829659318638,\n",
       "               'abs_last_occurrence': 0.07414829659318638}),\n",
       "             ('little',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 6,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.10521042084168336,\n",
       "               'abs_last_occurrence': 0.10521042084168336}),\n",
       "             ('isolated',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 8,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.7394789579158316,\n",
       "               'abs_last_occurrence': 0.7394789579158316}),\n",
       "             ('critic',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 6,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.5761523046092184,\n",
       "               'abs_last_occurrence': 0.5761523046092184}),\n",
       "             ('decision',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 8,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.9098196392785571,\n",
       "               'abs_last_occurrence': 0.9098196392785571}),\n",
       "             ('practitioners',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 13,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.467935871743487,\n",
       "               'abs_last_occurrence': 0.467935871743487}),\n",
       "             ('practices',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 9,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.5591182364729459,\n",
       "               'abs_last_occurrence': 0.5591182364729459}),\n",
       "             ('practice',\n",
       "              {'term_count': 2,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 8,\n",
       "               'spread': 0.1623246492985972,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.21142284569138275,\n",
       "               'abs_last_occurrence': 0.37374749498997994}),\n",
       "             ('computer-based',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 14,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.009018036072144289,\n",
       "               'abs_last_occurrence': 0.009018036072144289}),\n",
       "             ('clinical',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 8,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.20240480961923848,\n",
       "               'abs_last_occurrence': 0.20240480961923848}),\n",
       "             ('guideline',\n",
       "              {'term_count': 3,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 9,\n",
       "               'spread': 0.4498997995991984,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 1,\n",
       "               'abs_first_occurrence': 0.41783567134268534,\n",
       "               'abs_last_occurrence': 0.8677354709418837}),\n",
       "             ('project',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 7,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.3927855711422846,\n",
       "               'abs_last_occurrence': 0.3927855711422846}),\n",
       "             ('asti',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 4,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 1,\n",
       "               'abs_first_occurrence': 0.3877755511022044,\n",
       "               'abs_last_occurrence': 0.3877755511022044}),\n",
       "             ('process',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 7,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.6152304609218436,\n",
       "               'abs_last_occurrence': 0.6152304609218436}),\n",
       "             ('ordering',\n",
       "              {'term_count': 2,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 8,\n",
       "               'spread': 0.4098196392785571,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 1,\n",
       "               'abs_first_occurrence': 0.02404809619238477,\n",
       "               'abs_last_occurrence': 0.4338677354709419}),\n",
       "             ('therapeutic',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 11,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.5470941883767535,\n",
       "               'abs_last_occurrence': 0.5470941883767535}),\n",
       "             ('routine',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 7,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.3657314629258517,\n",
       "               'abs_last_occurrence': 0.3657314629258517}),\n",
       "             ('overall',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 7,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.14228456913827656,\n",
       "               'abs_last_occurrence': 0.14228456913827656}),\n",
       "             ('information',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 11,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.2835671342685371,\n",
       "               'abs_last_occurrence': 0.2835671342685371}),\n",
       "             ('recommendations',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 15,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.7585170340681363,\n",
       "               'abs_last_occurrence': 0.7585170340681363}),\n",
       "             ('background',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 10,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.6042084168336673,\n",
       "               'abs_last_occurrence': 0.6042084168336673}),\n",
       "             ('rules',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 5,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.7164328657314629,\n",
       "               'abs_last_occurrence': 0.7164328657314629}),\n",
       "             ('elementary',\n",
       "              {'term_count': 1,\n",
       "               'term_length': 1,\n",
       "               'max_word_length': 10,\n",
       "               'spread': 0.0,\n",
       "               'lexical_cohesion': 0.0,\n",
       "               'in_excerpt': 0,\n",
       "               'in_title': 0,\n",
       "               'abs_first_occurrence': 0.7054108216432866,\n",
       "               'abs_last_occurrence': 0.7054108216432866})])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates = ['development', 'guideline-based ordering system', 'routine practice', 'therapeutic practices', 'systems for physicians', 'general practitioners', 'prescription errors', 'critic mode', 'little assistance', 'elementary rules', 'prescription', 'evidence-based clinical practice guidelines', 'hypertension', 'compliance', 'background process', 'first prototype', 'basis', 'asti project', 'state-of-the-art information', 'mode', 'comprehensive guideline knowledge base', 'overall patient-centered treatment strategy', 'physician', 'isolated guideline recommendations', 'decision tree', 'effective drug-centered checks', 'treatment strategy', 'guidelines', 'treatment',\n",
    "             'development', 'checks', 'systems', 'effective', 'base', 'first', 'guideline-based', 'assistance', 'evidence-based', 'patient-centered', 'comprehensive', 'prescription', 'best', 'strategy', 'hypertension', 'compliance', 'physicians', 'state-of-the-art', 'general', 'knowledge', 'tree', 'prototype', 'system', 'errors', 'drug-centered', 'little', 'isolated', 'critic', 'decision', 'practitioners', 'practices', 'practice', 'computer-based', 'clinical', 'basis', 'guideline', 'project', 'asti', 'mode', 'process', 'ordering', 'therapeutic', 'physician', 'routine', 'overall', 'information', 'recommendations', 'background', 'rules', 'guidelines', 'treatment', 'elementary']\n",
    "extract_candidate_features(candidates, test_abstracts[0],\"\",\"ASTI: a guideline-based drug-ordering system for primary care\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
