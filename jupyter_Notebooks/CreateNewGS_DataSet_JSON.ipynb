{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee8a8e07-f04a-467e-92fa-02d3c786eaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "83\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/4Rohan_FirstAnnotationResults_GS_CleanedAfter.txt\",'r') as f:\n",
    "    test42Abs = f.read().split('\\n\\n')\n",
    "print(len(test42Abs))\n",
    "\n",
    "with open(\"../data/4Rohan_SecondTimeGS.txt\",'r') as f:\n",
    "    test80Abs = f.read().split('\\n\\n')\n",
    "print(len(test80Abs))\n",
    "\n",
    "with open(\"../data/4Rohan_ACM_GS.txt\",'r') as f:\n",
    "    testACM = f.read().split('\\n\\n')\n",
    "print(len(testACM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bc933f0-7828-4325-9bde-4c24744c8ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs40Abs = {}\n",
    "for abstract in test42Abs:\n",
    "    temp = abstract.split('\\n')\n",
    "    try:\n",
    "        gs40Abs[temp[0].split(':')[1]] = temp[1:]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(temp)\n",
    "\n",
    "gs80Abs = {}\n",
    "for abstract in test80Abs:\n",
    "    temp = abstract.split('\\n')\n",
    "    try:\n",
    "        gs80Abs[temp[0].split(':')[1]] = temp[1:]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(temp)\n",
    "\n",
    "for abstract in testACM:\n",
    "    temp = abstract.split('\\n')\n",
    "    gs80Abs[temp[0]] = temp[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68bbd302-2ee7-465b-bddb-4aa15cc16655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "91\n"
     ]
    }
   ],
   "source": [
    "print(len(gs40Abs))\n",
    "print(len(gs80Abs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25c305e8-4fe0-408e-85ab-561e29485d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_json_array(path):\n",
    "    '''Read JSON given array of dictionaries'''\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as fp:\n",
    "        datas = json.loads(fp.read())\n",
    "    return datas\n",
    "\n",
    "trainData = read_json_array(\"../data/pubmed_data/json_data_synthetic_labels/train.json\")\n",
    "testData = read_json_array(\"../data/pubmed_data/json_data_synthetic_labels/test.json\")\n",
    "testgsData = read_json_array(\"../data/pubmed_data/json_data_synthetic_labels/testgs.json\")\n",
    "miscData = read_json_array(\"../data/ACM_MiscPubMed_Abstracts.json\")\n",
    "totalData = trainData + testData + testgsData + miscData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c070a2b-e226-4cff-9f90-e4a9a9d8dc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data length:  3243\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "gs80Data = []\n",
    "gs40Data = []\n",
    "visited = set()\n",
    "i=0\n",
    "j=0\n",
    "print(\"Total data length: \", len(totalData))\n",
    "while i<len(totalData):\n",
    "    abstract = totalData[i]\n",
    "    if abstract['id'] in gs80Abs:\n",
    "        # print(abstract['id'])\n",
    "        #print(\"Synthetic:\\n\",abstract['keywords'])\n",
    "        #print(\"GS:\\n\",gs80Abs[abstract['id']])\n",
    "        #print('-'*20)\n",
    "        abstract['keywords'] = gs80Abs[abstract['id']]\n",
    "        gs80Data.append(abstract)\n",
    "        visited.add(abstract['id'])\n",
    "        count+=1\n",
    "    elif abstract['id'] in gs40Abs:\n",
    "        abstract['keywords'] = gs40Abs[abstract['id']]\n",
    "        gs40Data.append(abstract)\n",
    "        visited.add(abstract['id'])\n",
    "        count+=1\n",
    "    else:\n",
    "        totalData[i] = totalData[j]\n",
    "        j+=1\n",
    "    i+=1\n",
    "    \n",
    "totalData[j:]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c540a05-3f65-4ca1-a04b-fc1d2a07d625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data length after removing GS:  3110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Total Data length after removing GS: \", len(totalData))\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "426eaf83-a0a3-48e4-b0db-d5a77831ed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in gs80Abs.items():\n",
    "    if k not in visited:\n",
    "        print(k)\n",
    "\n",
    "for k,v in gs40Abs.items():\n",
    "    if k not in visited:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "137ddeab-9d2a-4c48-913f-a0e00acaf159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "# print(gs80Data[0])\n",
    "print(len(gs80Data))\n",
    "print(len(gs40Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0866537-516c-420d-affb-6e65262b658c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'SepsisICU_ACM',\n",
       " 'title': 'Design of a probabilistic ontology-based clinical decision support system for classifying temporal patterns in the ICU: A sepsis case study',\n",
       " 'abstract': 'Medical time series contain important information about the condition of a patient. However, due to the large amount of data and the staff shortage, it is difficult for physicians to monitor these time series for trends that suggest a relevant clinical detoriation due to a complication or new pathology. This paper proposes a framework that supports physicians in detecting patterns in time series. It has three main tasks. First, the time-dependent data is gathered from heterogeneous sources and the semantics are made explicit by using an ontology. Second, Machine Learning techniques detect trends in the semantic time series data that indicate that a patient has a particular pathology. However, computerized classification techniques are not 100% accurate. Therefore, the third task consists of adding the pathology classification to the ontology with an associated probability and notifying the physician if necessary. The framework was evaluated with an ICU use case, namely detecting sepsis. Sepsis is the number one cause of death in the ICU.',\n",
       " 'keywords': ['classifying',\n",
       "  'clinical decision support system',\n",
       "  'computerized classification',\n",
       "  'death',\n",
       "  'design',\n",
       "  'detecting',\n",
       "  'evaluated',\n",
       "  'framework',\n",
       "  'monitor',\n",
       "  'notifying',\n",
       "  'ontology-based',\n",
       "  'physician',\n",
       "  'physicians',\n",
       "  'probabilistic',\n",
       "  'probability',\n",
       "  'temporal patterns',\n",
       "  'time series',\n",
       "  'time-dependent',\n",
       "  'trends']}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs80Data[86]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23f4c4d1-5135-4736-851c-73bf2f02313a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '29295283',\n",
       " 'title': 'Development of a Service-Oriented Sharable Clinical Decision Support System Based on Ontology for Chronic Disease.',\n",
       " 'abstract': 'Clinical decision support systems (CDSSs) have been proved as an efficient way to improve health care quality. However, the inflexibility in integrating multiple clinical practice guidelines (multi-CPGs), the mass input workload of patient data, and the difficulty in system sharing become barriers of CDSSs implementation. In this paper, we proposed a framework of CDSS for chronic disease based on ontology and service-oriented architecture (SOA) to improve these defects. We used ontology for knowledge base construction on multi-CPGs integration to overcome their differences as well as reduce the input procedure of patient data by ontology reasoning. Furthermore, we built the CDSS on an SOA structure to provide flexibility in system and data sharing, such that patients could get suggestions from the same system for self-management of chronic disease. A typical case was used to validate the CDSS functions and accuracy. Two clients were developed to illustrate the SOA superiority.',\n",
       " 'methods': '',\n",
       " 'results': '',\n",
       " 'keywords': ['accuracy',\n",
       "  'built',\n",
       "  'Clinical Decision Support System ',\n",
       "  'Clinical decision support systems (CDSSs) ',\n",
       "  'clinical practice guidelines',\n",
       "  'construction ',\n",
       "  'data sharing',\n",
       "  'developed',\n",
       "  'Development',\n",
       "  'functions ',\n",
       "  'implementation',\n",
       "  'integrating',\n",
       "  'integration',\n",
       "  'reasoning',\n",
       "  'Service-Oriented',\n",
       "  'service-oriented architecture (SOA) ',\n",
       "  'Sharable',\n",
       "  'sharing',\n",
       "  'used',\n",
       "  'validate']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs40Data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "696e646b-a285-406b-a913-aef2af66a439",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/pubmed_data/json_data_synthetic_labels/v2_testgs91.json\", \"w\") as outfile:\n",
    "    json.dump(gs80Data, outfile)\n",
    "\n",
    "with open(\"../data/pubmed_data/json_data_synthetic_labels/v2_testgs42.json\", \"w\") as outfile:\n",
    "    json.dump(gs40Data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "538f29a7-2c00-44ec-a5c3-50e450507c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_length = len(totalData)\n",
    "with open(\"../data/pubmed_data/json_data_synthetic_labels/v2_train.json\", \"w\") as outfile:\n",
    "    json.dump(totalData[:dataset_length//3], outfile)\n",
    "\n",
    "with open(\"../data/pubmed_data/json_data_synthetic_labels/v2_test.json\", \"w\") as outfile:\n",
    "    json.dump(totalData[dataset_length//3:], outfile)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd14dcd-a96a-4699-bfb8-8b0ca3e8e355",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "pytorch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
