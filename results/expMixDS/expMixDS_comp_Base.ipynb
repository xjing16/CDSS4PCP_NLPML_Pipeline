{
 "cells": [
  {
   "cell_type": "raw",
   "id": "cba2d8c7-ae2c-4531-9961-6d97ae675705",
   "metadata": {},
   "source": [
    "pytorch) [rgoli@node0085 NLP_KPIdentify]$ python mainV2.py -m createData\n",
    "Word Embedding Type:  word2vec\n",
    "====================================================================================================\n",
    "Mode: createData\n",
    "====================================================================================================\n",
    "Spacy Model to generate Synthetic Keywords:\n",
    "/home/rgoli/NLP_KPIdentify/cdssSciSpacy/model-best\n",
    "JSON pre-processing is completed for 3380-th document!: 100%|███████████████████████████████████████████████████| 3380/3380 [00:00<00:00, 12825.55it/s]\n",
    "Synthetic Keywrods generated for 3380-th document!: 100%|██████████████████████████████████████████████████████████| 3380/3380 [04:32<00:00, 12.39it/s]\n",
    "Total Articles removed:  99\n",
    "['33847000', '32586609', '32016531', '31834423', '31677654', '31639740', '31619073', '31415287', '31023866', '30927472', '30361207', '30215540', '29749424', '29584731', '29431386', '28743777', '28738983', '27378540', '27021287', '27001984', '26756103', '26615117', '26340249', '26213298', '25991138', '25795642', '25725294', '25265669', '24865755', '24491272', '24423993', '24199435', '24199432', '23920783', '23855147', '23844443', '23509850', '23339265', '22099568', '21485252', '20508669', '20501531', '20407194', '20407172', '20407167', '20407166', '19875424', '19748739', '19353974', '19181195', '19162835', '18582726', '18323264', '17885637', '17494351', '17468151', '17432368', '17249397', '17238552', '17160538', '17110652', '16904569', '16850545', '16751047', '16675654', '16266025', '16134538', '16075479', '15922847', '15910585', '15338527', '15283511', '15154321', '14872465', '14728406', '14679730', '12698905', '12564140', '12365298', '11840053', '11719755', '11351232', '11255624', '10622868', '10609477', '10557772', '10538678', '10538082', '10345771', '10187355', '10181184', '9611842', '10181747', '10180266', '10177690', '10177674', '9332705', '10176001', '10175323']\n",
    "Total Dataset Length:  3281\n",
    "Train Dataset Length:  1093\n",
    "Test  Dataset Length:  2188\n",
    "First-Time GS: 42\n",
    "Second-Time GS: 83\n",
    "Second-Time ACM GS: 8\n",
    "Total data length:  3281\n",
    "Saving GS91:  91\n",
    "Saving GS42:  42\n",
    "Saving Train:  1049\n",
    "Saving Test:  2099\n",
    "(pytorch) [rgoli@node0085 NLP_KPIdentify]$ python mainV2.py -m preTrain\n",
    "Word Embedding Type:  word2vec\n",
    "====================================================================================================\n",
    "Mode: preTrain\n",
    "====================================================================================================\n",
    "Total Sentences in Train Corpus:  13603\n",
    "Total Sentences in Test Corpus:  22766\n",
    "Vocabulary Size: 5043\n",
    "/home/rgoli/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
    "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
    "Bi-Directional Language Model :\n",
    "WordLSTM_v2(\n",
    "  (emb_layer): Embedding(5043, 300)\n",
    "  (lstm): LSTM(300, 128, batch_first=True, dropout=0.3, bidirectional=True)\n",
    "  (dropout): Dropout(p=0.3, inplace=False)\n",
    "  (fc): Linear(in_features=256, out_features=5043, bias=True)\n",
    ")\n",
    "Epoch: 1/20... mean_loss : 0.87, Perplexity : 2.39\n",
    "Epoch: 2/20... mean_loss : 0.23, Perplexity : 1.26\n",
    "Epoch: 3/20... mean_loss : 0.15, Perplexity : 1.16\n",
    "Epoch: 4/20... mean_loss : 0.10, Perplexity : 1.11\n",
    "Epoch: 5/20... mean_loss : 0.07, Perplexity : 1.08\n",
    "Epoch: 6/20... mean_loss : 0.05, Perplexity : 1.05\n",
    "Epoch: 7/20... mean_loss : 0.04, Perplexity : 1.04\n",
    "Epoch: 8/20... mean_loss : 0.03, Perplexity : 1.03\n",
    "Epoch: 9/20... mean_loss : 0.03, Perplexity : 1.03\n",
    "Epoch: 10/20... mean_loss : 0.02, Perplexity : 1.02\n",
    "Epoch: 11/20... mean_loss : 0.02, Perplexity : 1.02\n",
    "Epoch: 12/20... mean_loss : 0.02, Perplexity : 1.02\n",
    "Epoch: 13/20... mean_loss : 0.02, Perplexity : 1.02\n",
    "Epoch: 14/20... mean_loss : 0.01, Perplexity : 1.01\n",
    "Epoch: 15/20... mean_loss : 0.01, Perplexity : 1.01\n",
    "Epoch: 16/20... mean_loss : 0.01, Perplexity : 1.01\n",
    "Epoch: 17/20... mean_loss : 0.01, Perplexity : 1.01\n",
    "Epoch: 18/20... mean_loss : 0.01, Perplexity : 1.01\n",
    "Epoch: 19/20... mean_loss : 0.01, Perplexity : 1.01\n",
    "Epoch: 20/20... mean_loss : 0.01, Perplexity : 1.01\n",
    "Test Perplexity: 29.58\n",
    "clinical decision support systems cdss in developing in electronic medical data medical data automated clinical practice and clinical decision support decision support systems cdss developing developing developing as developing developing a as developing a business as business process intelligence and bi dashboard tracking dashboard dashboard for bi dashboards is \n",
    "\n",
    "prescription errors and management and management and when the system is seeking is seeking management platform was a clinical course of feature of secondary peritonitis 68 of were caused by the study on the gold the calling that calling time of the evaluation the correctness and applicability \n",
    "\n",
    "one of the of clinical practice data research data research articles across outcomes and increased health record health care for patients clinical conditions of clinical decision tool score categorized as low probability was probability according values probability values probability prespecification models were models can help inform health have \n",
    "\n",
    "asthma management programs for primary care providers increasing adherence to asthma guidelines designed for cncp for chronic non-cancer pain and provider pcp provider overtime provider overtime provider overtime provider provider in region have been proved in wound care and control groups detection rule in a knowledge with a clinical decision-support clinical cases of knowledge and results and \n",
    "\n",
    "(pytorch) [rgoli@node0085 NLP_KPIdentify]$ python mainV2.py -m train\n",
    "Word Embedding Type:  word2vec\n",
    "====================================================================================================\n",
    "Mode: train\n",
    "====================================================================================================\n",
    "Vocabulary Size: 5043\n",
    "Using pretrained word embeddings\n",
    "/home/rgoli/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
    "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
    "Train Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1049/1049 [00:08<00:00, 119.10it/s]\n",
    "Test Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2099/2099 [00:13<00:00, 158.76it/s]\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Start hierAttnNtwk-Bi-LSTM-CRF Train >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "Epoch: 2/30 Loss: 4.887\n",
    "Epoch: 4/30 Loss: 2.568\n",
    "Epoch: 6/30 Loss: 1.796\n",
    "Epoch: 8/30 Loss: 1.391\n",
    "Epoch: 10/30 Loss: 1.012\n",
    "Epoch: 12/30 Loss: 0.991\n",
    "Epoch: 14/30 Loss: 0.795\n",
    "Epoch: 16/30 Loss: 0.672\n",
    "Epoch: 18/30 Loss: 0.663\n",
    "Epoch: 20/30 Loss: 0.551\n",
    "Epoch: 22/30 Loss: 0.538\n",
    "Epoch: 24/30 Loss: 0.467\n",
    "Epoch: 26/30 Loss: 0.461\n",
    "Epoch: 28/30 Loss: 0.389\n",
    "Epoch: 30/30 Loss: 0.400\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< END hierAttnNtwk-Bi-LSTM-CRF Train >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< START hierAttnNtwk-Bi-LSTM-CRF Test >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "Test Loss: 10.672\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< END hierAttnNtwk-Bi-LSTM-CRF Test >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "(pytorch) [rgoli@node0085 NLP_KPIdentify]$ python mainV2.py -m test\n",
    "Word Embedding Type:  word2vec\n",
    "====================================================================================================\n",
    "Mode: test\n",
    "====================================================================================================\n",
    "Vocabulary Size: 5043\n",
    "Using pretrained word embeddings\n",
    "/home/rgoli/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
    "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
    "Test Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2099/2099 [00:13<00:00, 155.96it/s]\n",
    "Metrics on Test DS:\n",
    "SeqEval Metrics:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          KP       0.77      0.67      0.72     56162\n",
    "\n",
    "   micro avg       0.77      0.67      0.72     56162\n",
    "   macro avg       0.77      0.67      0.72     56162\n",
    "weighted avg       0.77      0.67      0.72     56162\n",
    "\n",
    "Precision given by SeqEval: 77.08%\n",
    "Recall given by SeqEval: 66.83%\n",
    "F1-Score given by SeqEval: 71.59%\n",
    "Accuracy given by SeqEval: 92.57%\n",
    "(pytorch) [rgoli@node0085 NLP_KPIdentify]$ python mainV2.py -m testGS\n",
    "Word Embedding Type:  word2vec\n",
    "====================================================================================================\n",
    "Mode: testGS\n",
    "====================================================================================================\n",
    "Vocabulary Size: 5043\n",
    "Using pretrained word embeddings\n",
    "/home/rgoli/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
    "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
    "Test GS42 Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 128.35it/s]\n",
    "Metrics on Test GS42 DS:\n",
    "SeqEval Metrics:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          KP       0.61      0.49      0.54      1048\n",
    "\n",
    "   micro avg       0.61      0.49      0.54      1048\n",
    "   macro avg       0.61      0.49      0.54      1048\n",
    "weighted avg       0.61      0.49      0.54      1048\n",
    "\n",
    "Precision given by SeqEval: 60.83%\n",
    "Recall given by SeqEval: 49.05%\n",
    "F1-Score given by SeqEval: 54.31%\n",
    "Accuracy given by SeqEval: 87.93%\n",
    "Test GS91 Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 91/91 [00:00<00:00, 171.70it/s]\n",
    "Metrics on Test GS91 DS:\n",
    "SeqEval Metrics:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          KP       0.66      0.49      0.56      2386\n",
    "\n",
    "   micro avg       0.66      0.49      0.56      2386\n",
    "   macro avg       0.66      0.49      0.56      2386\n",
    "weighted avg       0.66      0.49      0.56      2386\n",
    "\n",
    "Precision given by SeqEval: 65.62%\n",
    "Recall given by SeqEval: 48.87%\n",
    "F1-Score given by SeqEval: 56.02%\n",
    "Accuracy given by SeqEval: 89.11%\n",
    "(pytorch) [rgoli@node0085 NLP_KPIdentify]$"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f8a14781-6858-4d6d-8ed7-0797ea3dba46",
   "metadata": {},
   "source": [
    "(pytorch) [rgoli@node0085 ~]$ cd NLP_KPIdentify/\n",
    "(pytorch) [rgoli@node0085 NLP_KPIdentify]$ python mainV2.py -m expMinDS\n",
    "Word Embedding Type:  word2vec\n",
    "====================================================================================================\n",
    "Mode: expMinDS\n",
    "====================================================================================================\n",
    "Invalid option selected!!!\n",
    " Mode of opertion: train/test/predict/createData\n",
    "(pytorch) [rgoli@node0085 NLP_KPIdentify]$ python mainV2.py -m expMixDS\n",
    "Word Embedding Type:  word2vec\n",
    "====================================================================================================\n",
    "Mode: expMixDS\n",
    "====================================================================================================\n",
    "Vocabulary Size: 5043\n",
    "Combination: 100 Train : 0 GS, Experiment - #0\n",
    "Using pretrained word embeddings\n",
    "/home/rgoli/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
    "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
    "Train Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1038/1038 [00:07<00:00, 140.14it/s]\n",
    "Test Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2110/2110 [00:14<00:00, 146.23it/s]\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Start hierAttnNtwk-Bi-LSTM-CRF Train >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "Epoch: 2/30 Loss: 7.886\n",
    "Epoch: 4/30 Loss: 5.734\n",
    "Epoch: 6/30 Loss: 4.334\n",
    "Epoch: 8/30 Loss: 3.249\n",
    "Epoch: 10/30 Loss: 2.517\n",
    "Epoch: 12/30 Loss: 2.285\n",
    "Epoch: 14/30 Loss: 1.761\n",
    "Epoch: 16/30 Loss: 1.382\n",
    "Epoch: 18/30 Loss: 1.160\n",
    "Epoch: 20/30 Loss: 0.944\n",
    "Epoch: 22/30 Loss: 0.825\n",
    "Epoch: 24/30 Loss: 0.765\n",
    "Epoch: 26/30 Loss: 0.657\n",
    "Epoch: 28/30 Loss: 0.595\n",
    "Epoch: 30/30 Loss: 0.543\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< END hierAttnNtwk-Bi-LSTM-CRF Train >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< START hierAttnNtwk-Bi-LSTM-CRF Test >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "Test Loss: 0.717\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< END hierAttnNtwk-Bi-LSTM-CRF Test >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "Test Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2110/2110 [00:14<00:00, 143.10it/s]\n",
    "Metrics on Test DS:\n",
    "SeqEval Metrics:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          KP       0.98      0.97      0.97     58539\n",
    "\n",
    "   micro avg       0.98      0.97      0.97     58539\n",
    "   macro avg       0.98      0.97      0.97     58539\n",
    "weighted avg       0.98      0.97      0.97     58539\n",
    "\n",
    "Precision given by SeqEval: 97.65%\n",
    "Recall given by SeqEval: 97.27%\n",
    "F1-Score given by SeqEval: 97.46%\n",
    "Accuracy given by SeqEval: 99.28%\n",
    "Test GS91 Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:00<00:00, 161.37it/s]\n",
    "Metrics on Test GS91 DS:\n",
    "SeqEval Metrics:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          KP       0.89      0.86      0.87      2676\n",
    "\n",
    "   micro avg       0.89      0.86      0.87      2676\n",
    "   macro avg       0.89      0.86      0.87      2676\n",
    "weighted avg       0.89      0.86      0.87      2676\n",
    "\n",
    "Precision given by SeqEval: 88.50%\n",
    "Recall given by SeqEval: 85.69%\n",
    "F1-Score given by SeqEval: 87.07%\n",
    "Accuracy given by SeqEval: 97.37%\n",
    "PyTorch Memory Allocation :: 3932160\n",
    "Combination: 100 Train : 0 GS, Experiment - #1\n",
    "Using pretrained word embeddings\n",
    "Train Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1038/1038 [00:07<00:00, 147.07it/s]\n",
    "Test Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2110/2110 [00:14<00:00, 144.55it/s]\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Start hierAttnNtwk-Bi-LSTM-CRF Train >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "Epoch: 2/30 Loss: 8.598\n",
    "Epoch: 4/30 Loss: 6.555\n",
    "Epoch: 6/30 Loss: 5.288\n",
    "Epoch: 8/30 Loss: 4.503\n",
    "Epoch: 10/30 Loss: 3.604\n",
    "Epoch: 12/30 Loss: 2.923\n",
    "Epoch: 14/30 Loss: 2.424\n",
    "Epoch: 16/30 Loss: 2.227\n",
    "Epoch: 18/30 Loss: 2.012\n",
    "Epoch: 20/30 Loss: 1.714\n",
    "Epoch: 22/30 Loss: 1.464\n",
    "Epoch: 24/30 Loss: 1.342\n",
    "Epoch: 26/30 Loss: 1.449\n",
    "Epoch: 28/30 Loss: 1.225\n",
    "Epoch: 30/30 Loss: 1.340\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< END hierAttnNtwk-Bi-LSTM-CRF Train >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< START hierAttnNtwk-Bi-LSTM-CRF Test >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "Test Loss: 0.995\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< END hierAttnNtwk-Bi-LSTM-CRF Test >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "Test Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2110/2110 [00:14<00:00, 145.17it/s]\n",
    "Metrics on Test DS:\n",
    "SeqEval Metrics:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          KP       0.95      0.96      0.96     60476\n",
    "\n",
    "   micro avg       0.95      0.96      0.96     60476\n",
    "   macro avg       0.95      0.96      0.96     60476\n",
    "weighted avg       0.95      0.96      0.96     60476\n",
    "\n",
    "Precision given by SeqEval: 95.24%\n",
    "Recall given by SeqEval: 95.78%\n",
    "F1-Score given by SeqEval: 95.51%\n",
    "Accuracy given by SeqEval: 98.79%\n",
    "Test GS91 Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:00<00:00, 178.28it/s]\n",
    "Metrics on Test GS91 DS:\n",
    "SeqEval Metrics:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          KP       0.79      0.80      0.80      2232\n",
    "\n",
    "   micro avg       0.79      0.80      0.80      2232\n",
    "   macro avg       0.79      0.80      0.80      2232\n",
    "weighted avg       0.79      0.80      0.80      2232\n",
    "\n",
    "Precision given by SeqEval: 78.84%\n",
    "Recall given by SeqEval: 80.47%\n",
    "F1-Score given by SeqEval: 79.65%\n",
    "Accuracy given by SeqEval: 94.18%\n",
    "PyTorch Memory Allocation :: 3932160\n",
    "Combination: 100 Train : 0 GS, Experiment - #2\n",
    "Using pretrained word embeddings\n",
    "Train Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1038/1038 [00:07<00:00, 147.65it/s]\n",
    "Test Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2110/2110 [00:14<00:00, 143.10it/s]\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Start hierAttnNtwk-Bi-LSTM-CRF Train >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "Epoch: 2/30 Loss: 8.546\n",
    "Epoch: 4/30 Loss: 6.726\n",
    "Epoch: 6/30 Loss: 5.678\n",
    "Epoch: 8/30 Loss: 5.047\n",
    "Epoch: 10/30 Loss: 4.107\n",
    "Epoch: 12/30 Loss: 3.441\n",
    "Epoch: 14/30 Loss: 2.733\n",
    "Epoch: 16/30 Loss: 2.264\n",
    "Epoch: 18/30 Loss: 1.724\n",
    "Epoch: 20/30 Loss: 1.493\n",
    "Epoch: 22/30 Loss: 1.498\n",
    "Epoch: 24/30 Loss: 1.347\n",
    "Epoch: 26/30 Loss: 1.113\n",
    "Epoch: 28/30 Loss: 0.981\n",
    "Epoch: 30/30 Loss: 0.892\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< END hierAttnNtwk-Bi-LSTM-CRF Train >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< START hierAttnNtwk-Bi-LSTM-CRF Test >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "Test Loss: 0.778\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< END hierAttnNtwk-Bi-LSTM-CRF Test >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "Test Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2110/2110 [00:14<00:00, 146.65it/s]\n",
    "Metrics on Test DS:\n",
    "SeqEval Metrics:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          KP       0.98      0.96      0.97     62587\n",
    "\n",
    "   micro avg       0.98      0.96      0.97     62587\n",
    "   macro avg       0.98      0.96      0.97     62587\n",
    "weighted avg       0.98      0.96      0.97     62587\n",
    "\n",
    "Precision given by SeqEval: 97.78%\n",
    "Recall given by SeqEval: 96.17%\n",
    "F1-Score given by SeqEval: 96.97%\n",
    "Accuracy given by SeqEval: 99.17%\n",
    "Test GS91 Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:00<00:00, 166.77it/s]\n",
    "Metrics on Test GS91 DS:\n",
    "SeqEval Metrics:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          KP       0.89      0.80      0.84      2256\n",
    "\n",
    "   micro avg       0.89      0.80      0.84      2256\n",
    "   macro avg       0.89      0.80      0.84      2256\n",
    "weighted avg       0.89      0.80      0.84      2256\n",
    "\n",
    "Precision given by SeqEval: 88.52%\n",
    "Recall given by SeqEval: 79.96%\n",
    "F1-Score given by SeqEval: 84.02%\n",
    "Accuracy given by SeqEval: 95.27%\n",
    "PyTorch Memory Allocation :: 3932160\n",
    "Combination: 100 Train : 0 GS, Experiment - #3\n",
    "Using pretrained word embeddings\n",
    "Train Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1038/1038 [00:06<00:00, 148.41it/s]\n",
    "Test Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2110/2110 [00:14<00:00, 149.75it/s]\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Start hierAttnNtwk-Bi-LSTM-CRF Train >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "Epoch: 2/30 Loss: 8.737\n",
    "Epoch: 4/30 Loss: 6.751\n",
    "Epoch: 6/30 Loss: 5.511\n",
    "Epoch: 8/30 Loss: 4.674\n",
    "Epoch: 10/30 Loss: 3.829\n",
    "Epoch: 12/30 Loss: 3.276\n",
    "Epoch: 14/30 Loss: 2.863\n",
    "Epoch: 16/30 Loss: 2.598\n",
    "Epoch: 18/30 Loss: 2.612\n",
    "Epoch: 20/30 Loss: 2.059\n",
    "Epoch: 22/30 Loss: 1.750\n",
    "Epoch: 24/30 Loss: 1.557\n",
    "Epoch: 26/30 Loss: 1.315\n",
    "Epoch: 28/30 Loss: 1.209\n",
    "Epoch: 30/30 Loss: 1.124\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< END hierAttnNtwk-Bi-LSTM-CRF Train >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< START hierAttnNtwk-Bi-LSTM-CRF Test >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "Test Loss: 0.921\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< END hierAttnNtwk-Bi-LSTM-CRF Test >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "Test Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2110/2110 [00:14<00:00, 146.52it/s]\n",
    "Metrics on Test DS:\n",
    "SeqEval Metrics:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          KP       0.96      0.97      0.96     55740\n",
    "\n",
    "   micro avg       0.96      0.97      0.96     55740\n",
    "   macro avg       0.96      0.97      0.96     55740\n",
    "weighted avg       0.96      0.97      0.96     55740\n",
    "\n",
    "Precision given by SeqEval: 95.66%\n",
    "Recall given by SeqEval: 96.77%\n",
    "F1-Score given by SeqEval: 96.21%\n",
    "Accuracy given by SeqEval: 98.94%\n",
    "Test GS91 Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:00<00:00, 169.34it/s]\n",
    "Metrics on Test GS91 DS:\n",
    "SeqEval Metrics:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          KP       0.81      0.84      0.83      2350\n",
    "\n",
    "   micro avg       0.81      0.84      0.83      2350\n",
    "   macro avg       0.81      0.84      0.83      2350\n",
    "weighted avg       0.81      0.84      0.83      2350\n",
    "\n",
    "Precision given by SeqEval: 81.08%\n",
    "Recall given by SeqEval: 84.04%\n",
    "F1-Score given by SeqEval: 82.53%\n",
    "Accuracy given by SeqEval: 95.59%\n",
    "PyTorch Memory Allocation :: 3932160\n",
    "(pytorch) [rgoli@node0085 NLP_KPIdentify]$"
   ]
  },
  {
   "cell_type": "raw",
   "id": "74efa39d-6767-4f67-bb1d-5d619bd19e1d",
   "metadata": {},
   "source": [
    "(pytorch) [rgoli@node0085 NLP_KPIdentify]$ python mainV2.py -m expMixDS\n",
    "Word Embedding Type:  word2vec\n",
    "====================================================================================================\n",
    "Mode: expMixDS\n",
    "====================================================================================================\n",
    "Vocabulary Size: 5043\n",
    "Combination: 100 Train : 0 GS, Experiment - #0\n",
    "Using pretrained word embeddings\n",
    "/home/rgoli/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
    "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
    "Train Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1049/1049 [00:08<00:00, 120.81it/s]\n",
    "Test Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2099/2099 [00:13<00:00, 158.84it/s]\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Start hierAttnNtwk-Bi-LSTM-CRF Train >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "Epoch: 2/30 Loss: 4.887\n",
    "Epoch: 4/30 Loss: 2.568\n",
    "Epoch: 6/30 Loss: 1.796\n",
    "Epoch: 8/30 Loss: 1.391\n",
    "Epoch: 10/30 Loss: 1.012\n",
    "Epoch: 12/30 Loss: 0.991\n",
    "Epoch: 14/30 Loss: 0.795\n",
    "Epoch: 16/30 Loss: 0.672\n",
    "Epoch: 18/30 Loss: 0.663\n",
    "Epoch: 20/30 Loss: 0.551\n",
    "Epoch: 22/30 Loss: 0.538\n",
    "Epoch: 24/30 Loss: 0.467\n",
    "Epoch: 26/30 Loss: 0.461\n",
    "Epoch: 28/30 Loss: 0.389\n",
    "Epoch: 30/30 Loss: 0.400\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< END hierAttnNtwk-Bi-LSTM-CRF Train >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< START hierAttnNtwk-Bi-LSTM-CRF Test >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "Test Loss: 10.672\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< END hierAttnNtwk-Bi-LSTM-CRF Test >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "Test Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2099/2099 [00:13<00:00, 156.10it/s]\n",
    "Metrics on Test DS:\n",
    "SeqEval Metrics:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          KP       0.77      0.68      0.73     56162\n",
    "\n",
    "   micro avg       0.77      0.68      0.73     56162\n",
    "   macro avg       0.77      0.68      0.73     56162\n",
    "weighted avg       0.77      0.68      0.73     56162\n",
    "\n",
    "Precision given by SeqEval: 77.35%\n",
    "Recall given by SeqEval: 68.28%\n",
    "F1-Score given by SeqEval: 72.54%\n",
    "Accuracy given by SeqEval: 92.76%\n",
    "Test GS91 Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:00<00:00, 160.19it/s]\n",
    "Metrics on Test GS91 DS:\n",
    "SeqEval Metrics:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          KP       0.67      0.53      0.59      2676\n",
    "\n",
    "   micro avg       0.67      0.53      0.59      2676\n",
    "   macro avg       0.67      0.53      0.59      2676\n",
    "weighted avg       0.67      0.53      0.59      2676\n",
    "\n",
    "Precision given by SeqEval: 66.93%\n",
    "Recall given by SeqEval: 53.03%\n",
    "F1-Score given by SeqEval: 59.17%\n",
    "Accuracy given by SeqEval: 92.15%\n",
    "PyTorch Memory Allocation :: 3932160\n",
    "Combination: 100 Train : 0 GS, Experiment - #1\n",
    "Using pretrained word embeddings\n",
    "Train Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1049/1049 [00:08<00:00, 125.89it/s]\n",
    "Test Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2099/2099 [00:13<00:00, 157.99it/s]\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Start hierAttnNtwk-Bi-LSTM-CRF Train >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "Epoch: 2/30 Loss: 5.278\n",
    "Epoch: 4/30 Loss: 2.797\n",
    "Epoch: 6/30 Loss: 1.893\n",
    "Epoch: 8/30 Loss: 1.407\n",
    "Epoch: 10/30 Loss: 1.181\n",
    "Epoch: 12/30 Loss: 0.944\n",
    "Epoch: 14/30 Loss: 0.905\n",
    "Epoch: 16/30 Loss: 0.779\n",
    "Epoch: 18/30 Loss: 0.788\n",
    "Epoch: 20/30 Loss: 0.603\n",
    "Epoch: 22/30 Loss: 0.511\n",
    "Epoch: 24/30 Loss: 0.468\n",
    "Epoch: 26/30 Loss: 0.429\n",
    "Epoch: 28/30 Loss: 0.398\n",
    "Epoch: 30/30 Loss: 0.348\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< END hierAttnNtwk-Bi-LSTM-CRF Train >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< START hierAttnNtwk-Bi-LSTM-CRF Test >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "Test Loss: 11.110\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< END hierAttnNtwk-Bi-LSTM-CRF Test >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "Test Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2099/2099 [00:13<00:00, 156.38it/s]\n",
    "Metrics on Test DS:\n",
    "SeqEval Metrics:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          KP       0.75      0.66      0.71     56162\n",
    "\n",
    "   micro avg       0.75      0.66      0.71     56162\n",
    "   macro avg       0.75      0.66      0.71     56162\n",
    "weighted avg       0.75      0.66      0.71     56162\n",
    "\n",
    "Precision given by SeqEval: 75.43%\n",
    "Recall given by SeqEval: 66.42%\n",
    "F1-Score given by SeqEval: 70.64%\n",
    "Accuracy given by SeqEval: 92.24%\n",
    "Test GS91 Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:00<00:00, 176.05it/s]\n",
    "Metrics on Test GS91 DS:\n",
    "SeqEval Metrics:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          KP       0.64      0.49      0.55      2232\n",
    "\n",
    "   micro avg       0.64      0.49      0.55      2232\n",
    "   macro avg       0.64      0.49      0.55      2232\n",
    "weighted avg       0.64      0.49      0.55      2232\n",
    "\n",
    "Precision given by SeqEval: 63.39%\n",
    "Recall given by SeqEval: 49.33%\n",
    "F1-Score given by SeqEval: 55.48%\n",
    "Accuracy given by SeqEval: 88.02%\n",
    "PyTorch Memory Allocation :: 3932160\n",
    "Combination: 100 Train : 0 GS, Experiment - #2\n",
    "Using pretrained word embeddings\n",
    "Train Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1049/1049 [00:08<00:00, 127.72it/s]\n",
    "Test Keyword Marking:\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2099/2099 [00:12<00:00, 161.77it/s]\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Start hierAttnNtwk-Bi-LSTM-CRF Train >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "Epoch: 2/30 Loss: 5.932\n",
    "Epoch: 4/30 Loss: 3.348\n",
    "Epoch: 6/30 Loss: 2.523\n",
    "Epoch: 8/30 Loss: 1.980\n",
    "Epoch: 10/30 Loss: 1.616\n",
    "Epoch: 12/30 Loss: 1.507\n",
    "Epoch: 14/30 Loss: 1.326\n",
    "Epoch: 16/30 Loss: 1.290\n",
    "Epoch: 18/30 Loss: 1.213\n",
    "Epoch: 20/30 Loss: 1.037\n",
    "Epoch: 22/30 Loss: 1.029\n",
    "Epoch: 24/30 Loss: 0.859\n",
    "Epoch: 26/30 Loss: 0.792\n",
    "Epoch: 28/30 Loss: 0.806\n",
    "Epoch: 30/30 Loss: 0.709\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< END hierAttnNtwk-Bi-LSTM-CRF Train >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< START hierAttnNtwk-Bi-LSTM-CRF Test >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "Test Loss: 10.353\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< END hierAttnNtwk-Bi-LSTM-CRF Test >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "Test Keyword Marking:\n",
    "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2099/2099 [00:13<00:00, 160.01it/s]\n",
    "Metrics on Test DS:\n",
    "SeqEval Metrics:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          KP       0.72      0.65      0.68     56162\n",
    "\n",
    "   micro avg       0.72      0.65      0.68     56162\n",
    "   macro avg       0.72      0.65      0.68     56162\n",
    "weighted avg       0.72      0.65      0.68     56162\n",
    "\n",
    "Precision given by SeqEval: 72.41%\n",
    "Recall given by SeqEval: 64.64%\n",
    "F1-Score given by SeqEval: 68.31%\n",
    "Accuracy given by SeqEval: 91.45%\n",
    "Test GS91 Keyword Marking:\n",
    "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92/92 [00:00<00:00, 168.25it/s]\n",
    "Metrics on Test GS91 DS:\n",
    "SeqEval Metrics:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          KP       0.59      0.45      0.51      2256\n",
    "\n",
    "   micro avg       0.59      0.45      0.51      2256\n",
    "   macro avg       0.59      0.45      0.51      2256\n",
    "weighted avg       0.59      0.45      0.51      2256\n",
    "\n",
    "Precision given by SeqEval: 58.95%\n",
    "Recall given by SeqEval: 45.26%\n",
    "F1-Score given by SeqEval: 51.20%\n",
    "Accuracy given by SeqEval: 86.35%\n",
    "PyTorch Memory Allocation :: 3932160\n",
    "(pytorch) [rgoli@node0085 NLP_KPIdentify]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9438ccd4-111c-40d8-938e-98ab39a3a6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.utils import read_json_array\n",
    "from collections import Counter\n",
    "trainData = read_json_array('data/pubmed_data/json_data_synthetic_labels_v2/train.json')\n",
    "testData = read_json_array('data/pubmed_data/json_data_synthetic_labels_v2/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "389bdac7-b4e4-466b-bcc1-a52126a00bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmids = [x['id'] for x in trainData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20c8ed67-112c-47f5-b67b-5d76cc152635",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmid_counter = Counter()\n",
    "for x in trainData:\n",
    "    pmid_counter[x['id'][:3]]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc8bcd2f-0aa7-4b82-bccb-1a6a37b48bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('269', 1),\n",
       " ('273', 2),\n",
       " ('279', 6),\n",
       " ('283', 8),\n",
       " ('286', 10),\n",
       " ('288', 11),\n",
       " ('290', 12),\n",
       " ('291', 25),\n",
       " ('292', 14),\n",
       " ('293', 28),\n",
       " ('294', 15),\n",
       " ('295', 16),\n",
       " ('298', 18),\n",
       " ('300', 20),\n",
       " ('303', 47),\n",
       " ('304', 26),\n",
       " ('308', 31),\n",
       " ('310', 34),\n",
       " ('314', 118),\n",
       " ('316', 44),\n",
       " ('318', 97),\n",
       " ('326', 79),\n",
       " ('327', 82),\n",
       " ('328', 89),\n",
       " ('338', 178),\n",
       " ('339', 10),\n",
       " ('340', 10),\n",
       " ('341', 2),\n",
       " ('342', 1),\n",
       " ('343', 5),\n",
       " ('344', 5),\n",
       " ('345', 5)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(pmid_counter.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "474a331a-5c70-4080-80e2-a3b4bbb86777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pmids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a175614d-af56-49c8-ae38-9f3df7d48cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('206', 2),\n",
       " ('208', 3),\n",
       " ('212', 2),\n",
       " ('214', 2),\n",
       " ('218', 9),\n",
       " ('220', 8),\n",
       " ('222', 8),\n",
       " ('223', 5),\n",
       " ('228', 6),\n",
       " ('231', 7),\n",
       " ('232', 7),\n",
       " ('233', 21),\n",
       " ('235', 24),\n",
       " ('238', 9),\n",
       " ('239', 18),\n",
       " ('241', 10),\n",
       " ('243', 10),\n",
       " ('247', 11),\n",
       " ('249', 12),\n",
       " ('251', 26),\n",
       " ('253', 13),\n",
       " ('256', 14),\n",
       " ('261', 17),\n",
       " ('262', 35),\n",
       " ('263', 19),\n",
       " ('264', 38),\n",
       " ('265', 20),\n",
       " ('267', 21),\n",
       " ('268', 21),\n",
       " ('269', 21),\n",
       " ('273', 21),\n",
       " ('279', 21),\n",
       " ('283', 21),\n",
       " ('286', 21),\n",
       " ('288', 21),\n",
       " ('290', 21),\n",
       " ('291', 42),\n",
       " ('292', 21),\n",
       " ('293', 42),\n",
       " ('294', 21),\n",
       " ('295', 21),\n",
       " ('298', 21),\n",
       " ('300', 21),\n",
       " ('303', 42),\n",
       " ('304', 21),\n",
       " ('308', 21),\n",
       " ('310', 21),\n",
       " ('314', 63),\n",
       " ('316', 21),\n",
       " ('318', 42),\n",
       " ('326', 21),\n",
       " ('327', 21),\n",
       " ('328', 21),\n",
       " ('338', 21)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pmids_test = [x['id'] for x in testData]\n",
    "pmid_test_counter1 = Counter()\n",
    "for x in testData[:1049]:\n",
    "    pmid_test_counter1[x['id'][:3]]+=1\n",
    "sorted(pmid_test_counter1.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "afbd52c7-2681-4e55-8f49-801c2002203e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('110', 2),\n",
       " ('111', 1),\n",
       " ('114', 2),\n",
       " ('116', 1),\n",
       " ('120', 2),\n",
       " ('124', 6),\n",
       " ('128', 4),\n",
       " ('145', 2),\n",
       " ('146', 3),\n",
       " ('152', 3),\n",
       " ('153', 3),\n",
       " ('158', 4),\n",
       " ('159', 4),\n",
       " ('167', 10),\n",
       " ('171', 6),\n",
       " ('172', 12),\n",
       " ('176', 7),\n",
       " ('179', 7),\n",
       " ('180', 14),\n",
       " ('182', 8),\n",
       " ('184', 8),\n",
       " ('186', 8),\n",
       " ('187', 9),\n",
       " ('188', 18),\n",
       " ('191', 9),\n",
       " ('194', 10),\n",
       " ('197', 20),\n",
       " ('198', 11),\n",
       " ('199', 11),\n",
       " ('206', 22),\n",
       " ('208', 33),\n",
       " ('212', 11),\n",
       " ('214', 12),\n",
       " ('218', 35),\n",
       " ('220', 22),\n",
       " ('222', 24),\n",
       " ('223', 11),\n",
       " ('228', 11),\n",
       " ('231', 11),\n",
       " ('232', 11),\n",
       " ('233', 34),\n",
       " ('235', 33),\n",
       " ('238', 11),\n",
       " ('239', 22),\n",
       " ('241', 11),\n",
       " ('243', 12),\n",
       " ('247', 12),\n",
       " ('249', 11),\n",
       " ('251', 22),\n",
       " ('253', 12),\n",
       " ('256', 12),\n",
       " ('261', 11),\n",
       " ('262', 23),\n",
       " ('263', 11),\n",
       " ('264', 23),\n",
       " ('265', 11),\n",
       " ('267', 11),\n",
       " ('268', 11),\n",
       " ('269', 11),\n",
       " ('273', 11),\n",
       " ('279', 11),\n",
       " ('283', 11),\n",
       " ('286', 11),\n",
       " ('288', 11),\n",
       " ('290', 11),\n",
       " ('291', 23),\n",
       " ('292', 11),\n",
       " ('293', 23),\n",
       " ('294', 11),\n",
       " ('295', 11),\n",
       " ('298', 12),\n",
       " ('300', 11),\n",
       " ('303', 23),\n",
       " ('304', 11),\n",
       " ('308', 12),\n",
       " ('310', 11),\n",
       " ('314', 35),\n",
       " ('316', 11),\n",
       " ('318', 22),\n",
       " ('326', 11),\n",
       " ('327', 11),\n",
       " ('328', 12),\n",
       " ('338', 11)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmid_test_counter2 = Counter()\n",
    "for x in testData[1049:]:\n",
    "    pmid_test_counter2[x['id'][:3]]+=1\n",
    "sorted(pmid_test_counter2.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9db865ab-ee94-45bf-98aa-c9a3a3bd5247",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs42Data = read_json_array('data/pubmed_data/json_data_synthetic_labels_v2/testgs42.json')\n",
    "gs91Data = read_json_array('data/pubmed_data/json_data_synthetic_labels_v2/testgs91.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b3a71ab-e3ac-402e-9baf-06eaee7e1565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('111', 1),\n",
       " ('114', 1),\n",
       " ('116', 1),\n",
       " ('120', 1),\n",
       " ('146', 1),\n",
       " ('153', 1),\n",
       " ('172', 1),\n",
       " ('180', 1),\n",
       " ('187', 1),\n",
       " ('194', 1),\n",
       " ('205', 1),\n",
       " ('208', 1),\n",
       " ('220', 2),\n",
       " ('222', 1),\n",
       " ('223', 1),\n",
       " ('232', 1),\n",
       " ('233', 1),\n",
       " ('235', 1),\n",
       " ('238', 1),\n",
       " ('241', 1),\n",
       " ('247', 1),\n",
       " ('251', 1),\n",
       " ('261', 1),\n",
       " ('264', 1),\n",
       " ('265', 2),\n",
       " ('268', 1),\n",
       " ('273', 1),\n",
       " ('274', 1),\n",
       " ('283', 1),\n",
       " ('286', 1),\n",
       " ('290', 1),\n",
       " ('291', 1),\n",
       " ('292', 1),\n",
       " ('294', 2),\n",
       " ('303', 1),\n",
       " ('308', 1),\n",
       " ('310', 1),\n",
       " ('314', 2)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs42Data_counter = Counter()\n",
    "for x in gs42Data:\n",
    "    gs42Data_counter[x['id'][:3]]+=1\n",
    "sorted(gs42Data_counter.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "391691d5-9f9b-4f75-a449-179b65651923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('105', 1),\n",
       " ('106', 1),\n",
       " ('110', 2),\n",
       " ('111', 1),\n",
       " ('114', 1),\n",
       " ('124', 3),\n",
       " ('128', 2),\n",
       " ('145', 1),\n",
       " ('152', 1),\n",
       " ('158', 1),\n",
       " ('159', 1),\n",
       " ('167', 2),\n",
       " ('171', 1),\n",
       " ('172', 1),\n",
       " ('176', 1),\n",
       " ('179', 1),\n",
       " ('180', 1),\n",
       " ('182', 1),\n",
       " ('184', 1),\n",
       " ('186', 1),\n",
       " ('188', 2),\n",
       " ('191', 1),\n",
       " ('197', 2),\n",
       " ('198', 1),\n",
       " ('199', 1),\n",
       " ('206', 2),\n",
       " ('208', 2),\n",
       " ('212', 1),\n",
       " ('214', 1),\n",
       " ('218', 3),\n",
       " ('222', 1),\n",
       " ('228', 1),\n",
       " ('231', 1),\n",
       " ('233', 3),\n",
       " ('235', 2),\n",
       " ('239', 2),\n",
       " ('243', 1),\n",
       " ('249', 1),\n",
       " ('251', 1),\n",
       " ('253', 1),\n",
       " ('256', 1),\n",
       " ('262', 2),\n",
       " ('263', 1),\n",
       " ('264', 1),\n",
       " ('267', 1),\n",
       " ('269', 1),\n",
       " ('275', 1),\n",
       " ('279', 1),\n",
       " ('288', 1),\n",
       " ('291', 1),\n",
       " ('293', 2),\n",
       " ('295', 1),\n",
       " ('298', 1),\n",
       " ('300', 1),\n",
       " ('303', 1),\n",
       " ('304', 1),\n",
       " ('308', 1),\n",
       " ('314', 1),\n",
       " ('316', 1),\n",
       " ('318', 2),\n",
       " ('326', 2),\n",
       " ('327', 1),\n",
       " ('328', 1),\n",
       " ('338', 1),\n",
       " ('Arr', 1),\n",
       " ('Bre', 1),\n",
       " ('CON', 1),\n",
       " ('Lab', 1),\n",
       " ('Met', 1),\n",
       " ('Pre', 1),\n",
       " ('Ref', 1),\n",
       " ('Sep', 1)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs91Data_counter = Counter()\n",
    "for x in gs91Data:\n",
    "    gs91Data_counter[x['id'][:3]]+=1\n",
    "sorted(gs91Data_counter.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d1b017-ccb9-4ea8-96b2-be7979e5037f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "pytorch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
