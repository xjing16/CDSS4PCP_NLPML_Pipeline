(pytorch) [rgoli@node1398 MetaMap-src]$ python main.py -m test
====================================================================================================
Mode: test
Sections Included: ['title', 'abstract']
Features: ['CEM', 'WFOF', 'POS', 'LEN', 'TI', 'TR']
Vocab Stemming: no
Logging Level: warn
====================================================================================================
PARAMS: {'word_embedding_dim': 128, 'char_embedding_dim': 32, 'word_max_len': 32, 'sentence_max_len': 256, 'hidden_dim': 128, 'use_crf': 'True', 'lstm_num_layers': 1, 'is_bidirectional': 'True', 'dropout': 0.5, 'tags_path': './interim_data/tags', 'epochs': 20, 'batch_size': 128, 'lr': 0.01, 'weight_decay': 0.0001, 'optim_scheduler_factor': 0.1, 'optim_scheduler_patience': 1, 'optim_scheduler_verbose': 'True'}
BiLSTM_CRF(
  (word_embedding): Embedding(22016, 128, padding_idx=0)
  (char_embedding): CharEncode(
    (embedding): Embedding(46, 32, padding_idx=0)
    (bilstm): LSTM(32, 32, bidirectional=True)
    (out): Linear(in_features=64, out_features=32, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (feature_mapping): Linear(in_features=5, out_features=64, bias=True)
  (bilstm): LSTM(224, 128, bidirectional=True)
  (hidden2tag): Linear(in_features=352, out_features=7, bias=True)
  (crf_layer): CRF()
  (dropout): Dropout(p=0.5, inplace=False)
  (batch_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer_norm1): LayerNorm((256, 224), eps=1e-05, elementwise_affine=True)
  (layer_norm2): LayerNorm((256, 352), eps=1e-05, elementwise_affine=True)
  (loss_fuc_cel): CrossEntropyLoss()
)
finish: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 166/166 [00:12<00:00, 13.80it/s]
INFO: p: 67.94, r: 50.89, f1: 58.19

systems understanding personalized medicine lessons recommendations based multidisciplinary translational analysis copd
['U-KP', 'O', 'B-KP', 'L-KP', 'U-KP', 'U-KP', 'O', 'B-KP', 'B-KP', 'L-KP', 'U-KP']
['U-KP', 'O', 'B-KP', 'L-KP', 'U-KP', 'U-KP', 'O', 'U-KP', 'B-KP', 'L-KP', 'U-KP']

Confusion Matrix:
 [[29312.  1444.   478.  2039.  6785.]
 [ 1327.  8446.  1492.  1576.   739.]
 [  446.  1361. 30105.  1703.  6442.]
 [ 2226.   734.  2984. 75507.  7828.]
 [ 5657.   653.  6146.  4896. 88475.]]
--------------------------------------------------
Label: B-KP
TP:29312.0 FN:10746.0 FP:9656.0 TN:239087.0
--------------------------------------------------
    Accuracy:   0.929356
    Misclassification:  0.070644
    Precision:  0.752207
    Sensitivity/Recall: 0.731739
    Specificity:        0.961181
    F1 Score:   0.741832
--------------------------------------------------
Label: I-KP
TP:8446.0 FN:5134.0 FP:4192.0 TN:271029.0
--------------------------------------------------
    Accuracy:   0.967708
    Misclassification:  0.032292
    Precision:  0.668302
    Sensitivity/Recall: 0.621944
    Specificity:        0.984769
    F1 Score:   0.644290
--------------------------------------------------
Label: L-KP
TP:30105.0 FN:9952.0 FP:11100.0 TN:237644.0
--------------------------------------------------
    Accuracy:   0.927106
    Misclassification:  0.072894
    Precision:  0.730615
    Sensitivity/Recall: 0.751554
    Specificity:        0.955376
    F1 Score:   0.740937
--------------------------------------------------
Label: O
TP:75507.0 FN:13772.0 FP:10214.0 TN:189308.0
--------------------------------------------------
    Accuracy:   0.916946
    Misclassification:  0.083054
    Precision:  0.880846
    Sensitivity/Recall: 0.845742
    Specificity:        0.948808
    F1 Score:   0.862937
--------------------------------------------------
Label: U-KP
TP:88475.0 FN:17352.0 FP:21794.0 TN:161180.0
--------------------------------------------------
    Accuracy:   0.864453
    Misclassification:  0.135547
    Precision:  0.802356
    Sensitivity/Recall: 0.836034
    Specificity:        0.880890
    F1 Score:   0.818849
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-
Avg. Accuracy: 0.92111
Avg. Precision: 0.766865
Avg. F1-Score: 0.761769
Avg. Sensitivity: 0.757403
Avg. Specificity: 0.946205
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-
SeqEval Metrics:
              precision    recall  f1-score   support

          KP       0.79      0.77      0.78    145879

   micro avg       0.79      0.77      0.78    145879
   macro avg       0.79      0.77      0.78    145879
weighted avg       0.79      0.77      0.78    145879

Accuracy given by SeqEval: 80.28%
INFO: Total time of model test:26.186S
(pytorch) [rgoli@node1398 MetaMap-src]$ python main.py -m predict
====================================================================================================
Mode: predict
Sections Included: ['title', 'abstract']
Features: ['CEM', 'WFOF', 'POS', 'LEN', 'TI', 'TR']
Vocab Stemming: no
Logging Level: warn
====================================================================================================
42-th document processed: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 38.15it/s]
The 42 document calculation TF-IDF completed: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 7363.35it/s]
The 42 document has been calculated TextRank completed: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 641.14it/s]
The 42-th document feature is completed: : 42it [00:00, 3438.29it/s]
INFO: predict data saving completed!
PARAMS: {'word_embedding_dim': 128, 'char_embedding_dim': 32, 'word_max_len': 32, 'sentence_max_len': 256, 'hidden_dim': 128, 'use_crf': 'True', 'lstm_num_layers': 1, 'is_bidirectional': 'True', 'dropout': 0.5, 'tags_path': './interim_data/tags', 'epochs': 20, 'batch_size': 128, 'lr': 0.01, 'weight_decay': 0.0001, 'optim_scheduler_factor': 0.1, 'optim_scheduler_patience': 1, 'optim_scheduler_verbose': 'True'}
BiLSTM_CRF(
  (word_embedding): Embedding(22016, 128, padding_idx=0)
  (char_embedding): CharEncode(
    (embedding): Embedding(46, 32, padding_idx=0)
    (bilstm): LSTM(32, 32, bidirectional=True)
    (out): Linear(in_features=64, out_features=32, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (feature_mapping): Linear(in_features=5, out_features=64, bias=True)
  (bilstm): LSTM(224, 128, bidirectional=True)
  (hidden2tag): Linear(in_features=352, out_features=7, bias=True)
  (crf_layer): CRF()
  (dropout): Dropout(p=0.5, inplace=False)
  (batch_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer_norm1): LayerNorm((256, 224), eps=1e-05, elementwise_affine=True)
  (layer_norm2): LayerNorm((256, 352), eps=1e-05, elementwise_affine=True)
  (loss_fuc_cel): CrossEntropyLoss()
)
finish: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  9.32it/s]
Confusion Matrix:
 [[ 266.   37.   10.   36.   86.]
 [  11.  147.   41.   30.   12.]
 [   5.   21.  261.   19.  129.]
 [ 530.  102.  539. 1522. 1493.]
 [  57.   16.   49.  260.  563.]]
--------------------------------------------------
Label: B-KP
TP:266.0 FN:169.0 FP:603.0 TN:5204.0
--------------------------------------------------
    Accuracy:   0.876322
    Misclassification:  0.123678
    Precision:  0.306099
    Sensitivity/Recall: 0.611494
    Specificity:        0.896160
    F1 Score:   0.407975
--------------------------------------------------
Label: I-KP
TP:147.0 FN:94.0 FP:176.0 TN:5825.0
--------------------------------------------------
    Accuracy:   0.956745
    Misclassification:  0.043255
    Precision:  0.455108
    Sensitivity/Recall: 0.609959
    Specificity:        0.970672
    F1 Score:   0.521277
--------------------------------------------------
Label: L-KP
TP:261.0 FN:174.0 FP:639.0 TN:5168.0
--------------------------------------------------
    Accuracy:   0.869753
    Misclassification:  0.130247
    Precision:  0.290000
    Sensitivity/Recall: 0.600000
    Specificity:        0.889960
    F1 Score:   0.391011
--------------------------------------------------
Label: O
TP:1522.0 FN:2664.0 FP:345.0 TN:1711.0
--------------------------------------------------
    Accuracy:   0.517943
    Misclassification:  0.482057
    Precision:  0.815212
    Sensitivity/Recall: 0.363593
    Specificity:        0.832198
    F1 Score:   0.502891
--------------------------------------------------
Label: U-KP
TP:563.0 FN:382.0 FP:1720.0 TN:3577.0
--------------------------------------------------
    Accuracy:   0.663249
    Misclassification:  0.336751
    Precision:  0.246605
    Sensitivity/Recall: 0.595767
    Specificity:        0.675288
    F1 Score:   0.348823
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-
Avg. Accuracy: 0.77680
Avg. Precision: 0.422605
Avg. F1-Score: 0.434395
Avg. Sensitivity: 0.556163
Avg. Specificity: 0.852856
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-
SeqEval Metrics:
              precision    recall  f1-score   support

          KP       0.25      0.54      0.34      1380

   micro avg       0.25      0.54      0.34      1380
   macro avg       0.25      0.54      0.34      1380
weighted avg       0.25      0.54      0.34      1380

Accuracy given by SeqEval: 44.20%
INFO: Total time of model training:8.697S
(pytorch) [rgoli@node1398 MetaMap-src]$