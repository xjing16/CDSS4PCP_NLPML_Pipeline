/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[38;5;2mâœ” Auto-filled config with all values[0m
[38;5;2mâœ” Saved config[0m
config.cfg
You can now add your data and train your pipeline:
python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-20 21:17:50,655] [INFO] Set up nlp object from config
[2022-09-20 21:17:50,663] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-20 21:17:50,663] [INFO] Resuming training for: ['ner']
[2022-09-20 21:17:50,670] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-20 21:17:57,178] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-20 21:18:13,783] [INFO] Created vocabulary
[2022-09-20 21:18:15,214] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-20 21:18:18,363] [INFO] Initialized pipeline components: ['transformer']
[38;5;2mâœ” Created output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    218.46    0.00    0.00    0.00    0.00
 40     200           0.00  102051.70    0.00    0.00    0.00    0.00
 80     400           0.00  58016.29   26.63   58.33   17.25    0.27
120     600           0.00  38248.25   44.66   50.90   39.79    0.45
160     800           0.00  24189.78   44.53   47.06   42.25    0.45
200    1000           0.00  15177.97   44.77   46.74   42.96    0.45
240    1200           0.00   9498.76   45.13   46.30   44.01    0.45
280    1400           0.00   6342.24   44.93   46.27   43.66    0.45
320    1600           0.00   4198.10   45.29   46.64   44.01    0.45
360    1800           0.00   2921.71   45.22   47.31   43.31    0.45
400    2000           0.00   2056.72   44.20   45.52   42.96    0.44
440    2200           0.00   1549.21   44.28   45.69   42.96    0.44
480    2400           0.00   1187.70   44.89   46.59   43.31    0.45
520    2600           0.00    927.80   44.93   46.27   43.66    0.45
560    2800           0.00    673.23   45.17   46.79   43.66    0.45
600    3000           0.00    613.96   44.65   46.90   42.61    0.45
640    3200           0.00    464.02   44.40   46.36   42.61    0.44
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-20 21:38:23,625] [INFO] Set up nlp object from config
[2022-09-20 21:38:23,634] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-20 21:38:23,634] [INFO] Resuming training for: ['ner']
[2022-09-20 21:38:23,641] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-20 21:38:30,135] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-20 21:38:46,671] [INFO] Created vocabulary
[2022-09-20 21:38:48,091] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-20 21:38:50,065] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    573.80    0.00    0.00    0.00    0.00
 40     200           0.00  120909.12    0.00    0.00    0.00    0.00
 80     400           0.00  68072.80   44.66   69.12   32.98    0.45
120     600           0.00  44881.69   49.90   57.87   43.86    0.50
160     800           0.00  28419.35   52.06   55.82   48.77    0.52
200    1000           0.00  18076.50   51.10   53.67   48.77    0.51
240    1200           0.00  11683.71   51.26   52.79   49.82    0.51
280    1400           0.00   7721.71   50.26   50.00   50.53    0.50
320    1600           0.00   5315.60   50.18   50.90   49.47    0.50
360    1800           0.00   3606.86   50.00   51.29   48.77    0.50
400    2000           0.00   2626.69   49.82   50.54   49.12    0.50
440    2200           0.00   1861.53   49.73   50.36   49.12    0.50
480    2400           0.00   1609.79   49.91   51.49   48.42    0.50
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-20 21:57:08,088] [INFO] Set up nlp object from config
[2022-09-20 21:57:08,096] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-20 21:57:08,097] [INFO] Resuming training for: ['ner']
[2022-09-20 21:57:08,104] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-20 21:57:14,655] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-20 21:57:31,351] [INFO] Created vocabulary
[2022-09-20 21:57:32,764] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-20 21:57:34,734] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    457.91    0.00    0.00    0.00    0.00
 40     200           0.00  107499.48    0.00    0.00    0.00    0.00
 80     400           0.00  61249.63   22.84   48.68   14.92    0.23
120     600           0.00  40101.10   50.11   52.91   47.58    0.50
160     800           0.00  25757.03   50.00   52.19   47.98    0.50
200    1000           0.00  16469.48   50.31   51.04   49.60    0.50
240    1200           0.00  10378.86   50.41   50.82   50.00    0.50
280    1400           0.00   6698.26   50.50   50.20   50.81    0.51
320    1600           0.00   4449.24   50.81   50.81   50.81    0.51
360    1800           0.00   3005.05   52.40   51.98   52.82    0.52
400    2000           0.00   2216.30   51.81   51.60   52.02    0.52
440    2200           0.00   1572.01   51.02   51.65   50.40    0.51
480    2400           0.00   1212.67   50.30   50.61   50.00    0.50
520    2600           0.00    953.93   49.80   50.41   49.19    0.50
560    2800           0.00    851.52   50.40   50.40   50.40    0.50
600    3000           0.00    640.63   50.40   50.40   50.40    0.50
640    3200           0.00    493.74   50.10   49.80   50.40    0.50
680    3400           0.00    476.93   50.10   51.05   49.19    0.50
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-20 22:20:29,322] [INFO] Set up nlp object from config
[2022-09-20 22:20:29,331] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-20 22:20:29,331] [INFO] Resuming training for: ['ner']
[2022-09-20 22:20:29,338] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-20 22:20:35,867] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-20 22:20:52,587] [INFO] Created vocabulary
[2022-09-20 22:20:54,016] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-20 22:20:55,970] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    654.25    0.00    0.00    0.00    0.00
 50     200           0.00  124391.92    0.00    0.00    0.00    0.00
100     400           0.00  68622.66   32.88   65.77   21.92    0.33
150     600           0.00  41150.68   49.40   57.09   43.54    0.49
200     800           0.00  22519.51   50.41   54.96   46.55    0.50
250    1000           0.00  12447.53   49.68   53.66   46.25    0.50
300    1200           0.00   7405.54   49.35   53.71   45.65    0.49
350    1400           0.00   4716.53   49.27   53.52   45.65    0.49
400    1600           0.00   3075.02   49.35   53.71   45.65    0.49
450    1800           0.00   2152.44   48.43   53.65   44.14    0.48
500    2000           0.00   1558.01   48.38   52.65   44.74    0.48
550    2200           0.00   1132.34   48.38   52.65   44.74    0.48
600    2400           0.00    931.87   49.27   53.93   45.35    0.49
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-20 22:38:51,463] [INFO] Set up nlp object from config
[2022-09-20 22:38:51,471] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-20 22:38:51,471] [INFO] Resuming training for: ['ner']
[2022-09-20 22:38:51,478] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-20 22:38:57,978] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-20 22:39:14,472] [INFO] Created vocabulary
[2022-09-20 22:39:15,906] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-20 22:39:17,866] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    229.21    0.00    0.00    0.00    0.00
 40     200           0.00  107650.77    0.00    0.00    0.00    0.00
 80     400           0.00  63295.65   28.73   63.75   18.55    0.29
120     600           0.00  43905.59   47.16   56.00   40.73    0.47
160     800           0.00  28586.51   47.64   54.72   42.18    0.48
200    1000           0.00  19159.07   48.92   53.45   45.09    0.49
240    1200           0.00  12820.87   47.98   53.85   43.27    0.48
280    1400           0.00   8725.69   47.22   51.97   43.27    0.47
320    1600           0.00   5911.59   47.43   51.95   43.64    0.47
360    1800           0.00   4114.20   45.60   50.67   41.45    0.46
400    2000           0.00   3086.03   46.09   51.34   41.82    0.46
440    2200           0.00   2354.77   45.38   50.67   41.09    0.45
480    2400           0.00   1811.79   45.49   49.36   42.18    0.45
520    2600           0.00   1439.08   45.42   50.22   41.45    0.45
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-20 22:56:17,437] [INFO] Set up nlp object from config
[2022-09-20 22:56:17,446] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-20 22:56:17,446] [INFO] Resuming training for: ['ner']
[2022-09-20 22:56:17,453] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-20 22:56:23,946] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-20 22:56:40,542] [INFO] Created vocabulary
[2022-09-20 22:56:41,959] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-20 22:56:43,915] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    472.69    0.00    0.00    0.00    0.00
 40     200           0.00  111453.58    0.00    0.00    0.00    0.00
 80     400           0.00  61755.57   30.09   51.06   21.33    0.30
120     600           0.00  41174.43   45.15   45.87   44.44    0.45
160     800           0.00  25357.83   45.36   44.12   46.67    0.45
200    1000           0.00  15992.86   45.99   44.92   47.11    0.46
240    1200           0.00  10389.02   44.92   42.91   47.11    0.45
280    1400           0.00   6825.29   43.35   41.91   44.89    0.43
320    1600           0.00   4773.97   42.01   41.38   42.67    0.42
360    1800           0.00   3262.31   43.67   42.92   44.44    0.44
400    2000           0.00   2337.10   43.20   42.02   44.44    0.43
440    2200           0.00   1764.98   43.36   43.17   43.56    0.43
480    2400           0.00   1344.99   44.16   43.04   45.33    0.44
520    2600           0.00   1008.05   43.72   42.62   44.89    0.44
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-20 23:13:46,427] [INFO] Set up nlp object from config
[2022-09-20 23:13:46,435] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-20 23:13:46,435] [INFO] Resuming training for: ['ner']
[2022-09-20 23:13:46,442] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-20 23:13:52,973] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-20 23:14:09,471] [INFO] Created vocabulary
[2022-09-20 23:14:10,896] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-20 23:14:12,812] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    187.50    0.00    0.00    0.00    0.00
 40     200           0.00  109197.63    0.00    0.00    0.00    0.00
 80     400           0.00  60939.60   32.70   50.32   24.22    0.33
120     600           0.00  39838.19   44.82   49.44   40.99    0.45
160     800           0.00  25042.48   45.93   48.29   43.79    0.46
200    1000           0.00  16294.65   45.28   47.60   43.17    0.45
240    1200           0.00  10620.96   45.38   47.46   43.48    0.45
280    1400           0.00   7029.38   45.26   46.84   43.79    0.45
320    1600           0.00   4931.64   45.30   46.56   44.10    0.45
360    1800           0.00   3351.26   45.19   46.69   43.79    0.45
400    2000           0.00   2432.93   44.55   46.03   43.17    0.45
440    2200           0.00   1790.98   44.69   45.63   43.79    0.45
480    2400           0.00   1429.90   44.87   46.36   43.48    0.45
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-20 23:30:19,307] [INFO] Set up nlp object from config
[2022-09-20 23:30:19,316] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-20 23:30:19,316] [INFO] Resuming training for: ['ner']
[2022-09-20 23:30:19,323] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-20 23:30:25,793] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-20 23:30:42,457] [INFO] Created vocabulary
[2022-09-20 23:30:43,891] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-20 23:30:45,874] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    836.99    0.00    0.00    0.00    0.00
 40     200           0.00  121613.37    0.00    0.00    0.00    0.00
 80     400           0.00  67550.64   24.40   53.49   15.81    0.24
120     600           0.00  47300.03   39.61   46.12   34.71    0.40
160     800           0.00  31219.13   42.01   45.75   38.83    0.42
200    1000           0.00  20856.42   40.37   43.31   37.80    0.40
240    1200           0.00  13902.77   41.85   45.38   38.83    0.42
280    1400           0.00   9326.47   41.76   44.71   39.18    0.42
320    1600           0.00   6535.24   41.56   45.16   38.49    0.42
360    1800           0.00   4660.79   42.26   44.96   39.86    0.42
400    2000           0.00   3336.80   43.56   46.15   41.24    0.44
440    2200           0.00   2658.94   43.12   45.59   40.89    0.43
480    2400           0.00   1993.75   44.40   46.77   42.27    0.44
520    2600           0.00   1599.68   43.17   45.28   41.24    0.43
560    2800           0.00   1177.45   44.92   46.67   43.30    0.45
600    3000           0.00   1010.20   45.28   47.04   43.64    0.45
640    3200           0.00    887.59   44.65   47.31   42.27    0.45
680    3400           0.00    748.45   43.21   44.98   41.58    0.43
720    3600           0.00    613.56   44.93   47.51   42.61    0.45
760    3800           0.00    517.45   46.43   48.33   44.67    0.46
800    4000           0.00    445.83   45.08   47.01   43.30    0.45
840    4200           0.00    374.60   44.88   46.99   42.96    0.45
880    4400           0.00    347.84   44.17   46.24   42.27    0.44
920    4600           0.00    331.37   44.28   46.92   41.92    0.44
960    4800           0.00    307.60   44.81   47.67   42.27    0.45
1000    5000           0.00    239.13   44.72   46.64   42.96    0.45
1040    5200           0.00    285.34   44.32   46.59   42.27    0.44
1080    5400           0.00    232.00   44.36   46.27   42.61    0.44
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 00:10:42,999] [INFO] Set up nlp object from config
[2022-09-21 00:10:43,007] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 00:10:43,007] [INFO] Resuming training for: ['ner']
[2022-09-21 00:10:43,014] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 00:10:49,389] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 00:11:05,730] [INFO] Created vocabulary
[2022-09-21 00:11:07,136] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 00:11:09,104] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    869.42    0.00    0.00    0.00    0.00
 40     200           0.00  116205.15    0.00    0.00    0.00    0.00
 80     400           0.00  67872.04   29.58   55.91   20.11    0.30
120     600           0.00  46552.86   46.18   55.82   39.38    0.46
160     800           0.00  29643.04   46.97   52.07   42.78    0.47
200    1000           0.00  19052.41   46.95   52.45   42.49    0.47
240    1200           0.00  12348.67   45.96   52.16   41.08    0.46
280    1400           0.00   8066.74   45.91   51.59   41.36    0.46
320    1600           0.00   5583.88   46.18   52.73   41.08    0.46
360    1800           0.00   3910.12   45.82   50.51   41.93    0.46
400    2000           0.00   2841.73   45.82   50.51   41.93    0.46
440    2200           0.00   2231.03   45.71   51.99   40.79    0.46
480    2400           0.00   1701.27   46.32   51.75   41.93    0.46
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 00:29:50,083] [INFO] Set up nlp object from config
[2022-09-21 00:29:50,091] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 00:29:50,091] [INFO] Resuming training for: ['ner']
[2022-09-21 00:29:50,098] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 00:29:56,548] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 00:30:13,156] [INFO] Created vocabulary
[2022-09-21 00:30:14,627] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 00:30:16,609] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    444.09    0.00    0.00    0.00    0.00
 40     200           0.00  114698.82    0.00    0.00    0.00    0.00
 80     400           0.00  63908.81   28.35   54.00   19.22    0.28
120     600           0.00  42877.59   51.43   60.29   44.84    0.51
160     800           0.00  25990.19   52.87   57.26   49.11    0.53
200    1000           0.00  15820.51   51.74   53.41   50.18    0.52
240    1200           0.00   9696.15   52.80   53.68   51.96    0.53
280    1400           0.00   5849.24   52.27   53.33   51.25    0.52
320    1600           0.00   3906.45   52.00   53.16   50.89    0.52
360    1800           0.00   2560.31   52.30   54.20   50.53    0.52
400    2000           0.00   1747.55   51.55   53.01   50.18    0.52
440    2200           0.00   1272.41   52.08   52.94   51.25    0.52
480    2400           0.00   1048.10   51.39   53.46   49.47    0.51
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 00:47:13,886] [INFO] Set up nlp object from config
[2022-09-21 00:47:13,894] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 00:47:13,894] [INFO] Resuming training for: ['ner']
[2022-09-21 00:47:13,902] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 00:47:20,339] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 00:47:36,818] [INFO] Created vocabulary
[2022-09-21 00:47:38,234] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 00:47:40,230] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    679.30    0.00    0.00    0.00    0.00
 50     200           0.00  130986.10    0.00    0.00    0.00    0.00
100     400           0.00  74336.51   44.86   64.86   34.29    0.45
150     600           0.00  47658.14   49.80   55.22   45.36    0.50
200     800           0.00  29424.41   49.22   53.81   45.36    0.49
250    1000           0.00  18077.38   48.95   52.67   45.71    0.49
300    1200           0.00  11454.53   47.66   52.59   43.57    0.48
350    1400           0.00   7152.10   47.22   51.04   43.93    0.47
400    1600           0.00   4664.46   47.51   51.24   44.29    0.48
450    1800           0.00   3301.34   47.89   51.65   44.64    0.48
500    2000           0.00   2223.44   47.42   51.03   44.29    0.47
550    2200           0.00   1706.98   47.31   51.25   43.93    0.47
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 01:03:55,243] [INFO] Set up nlp object from config
[2022-09-21 01:03:55,251] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 01:03:55,251] [INFO] Resuming training for: ['ner']
[2022-09-21 01:03:55,258] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 01:04:01,738] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 01:04:18,260] [INFO] Created vocabulary
[2022-09-21 01:04:19,683] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 01:04:21,657] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    410.95    0.00    0.00    0.00    0.00
 40     200           0.00  118072.66    0.00    0.00    0.00    0.00
 80     400           0.00  65680.35   29.36   47.32   21.29    0.29
120     600           0.00  44923.59   47.11   48.51   45.78    0.47
160     800           0.00  28816.64   45.12   45.68   44.58    0.45
200    1000           0.00  18675.39   45.40   44.27   46.59    0.45
240    1200           0.00  12412.72   46.97   45.80   48.19    0.47
280    1400           0.00   8350.45   46.76   45.77   47.79    0.47
320    1600           0.00   5526.09   43.70   42.86   44.58    0.44
360    1800           0.00   3963.04   43.51   43.25   43.78    0.44
400    2000           0.00   2762.59   44.98   44.98   44.98    0.45
440    2200           0.00   2060.40   44.71   43.68   45.78    0.45
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 01:20:17,698] [INFO] Set up nlp object from config
[2022-09-21 01:20:17,707] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 01:20:17,707] [INFO] Resuming training for: ['ner']
[2022-09-21 01:20:17,714] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 01:20:24,107] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 01:20:40,490] [INFO] Created vocabulary
[2022-09-21 01:20:41,902] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 01:20:43,839] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    444.09    0.00    0.00    0.00    0.00
 40     200           0.00  126095.01    0.00    0.00    0.00    0.00
 80     400           0.00  71590.13   34.36   53.17   25.38    0.34
120     600           0.00  48250.53   45.12   45.56   44.70    0.45
160     800           0.00  31191.86   46.24   45.90   46.59    0.46
200    1000           0.00  20348.17   44.11   44.27   43.94    0.44
240    1200           0.00  13402.10   43.98   44.40   43.56    0.44
280    1400           0.00   9253.38   44.61   44.53   44.70    0.45
320    1600           0.00   6579.88   43.48   43.40   43.56    0.43
360    1800           0.00   4625.53   42.91   42.28   43.56    0.43
400    2000           0.00   3577.68   43.20   42.49   43.94    0.43
440    2200           0.00   2736.98   42.83   42.12   43.56    0.43
480    2400           0.00   2143.74   42.54   41.91   43.18    0.43
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 01:36:51,175] [INFO] Set up nlp object from config
[2022-09-21 01:36:51,184] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 01:36:51,184] [INFO] Resuming training for: ['ner']
[2022-09-21 01:36:51,191] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 01:36:57,567] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 01:37:14,022] [INFO] Created vocabulary
[2022-09-21 01:37:15,448] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 01:37:17,436] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    639.93    0.00    0.00    0.00    0.00
 50     200           0.00  127903.79    0.00    0.00    0.00    0.00
100     400           0.00  66133.70   30.24   52.29   21.27    0.30
150     600           0.00  39815.73   40.33   45.54   36.19    0.40
200     800           0.00  23108.63   42.19   44.26   40.30    0.42
250    1000           0.00  13083.85   41.38   42.52   40.30    0.41
300    1200           0.00   7654.04   40.62   42.62   38.81    0.41
350    1400           0.00   4741.38   41.76   42.91   40.67    0.42
400    1600           0.00   3042.77   42.37   43.36   41.42    0.42
450    1800           0.00   2028.74   42.15   43.31   41.04    0.42
500    2000           0.00   1474.94   42.40   42.64   42.16    0.42
550    2200           0.00   1104.12   40.92   41.96   39.93    0.41
600    2400           0.00    860.34   40.61   41.73   39.55    0.41
650    2600           0.00    714.88   41.07   42.29   39.93    0.41
700    2800           0.00    591.01   41.52   42.41   40.67    0.42
750    3000           0.00    479.59   41.00   42.13   39.93    0.41
800    3200           0.00    448.81   42.07   43.14   41.04    0.42
850    3400           0.00    378.16   41.23   42.63   39.93    0.41
900    3600           0.00    325.41   41.30   42.35   40.30    0.41
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 02:05:47,965] [INFO] Set up nlp object from config
[2022-09-21 02:05:47,973] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 02:05:47,973] [INFO] Resuming training for: ['ner']
[2022-09-21 02:05:47,981] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 02:05:54,489] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 02:06:11,028] [INFO] Created vocabulary
[2022-09-21 02:06:12,467] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 02:06:14,494] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    385.71    0.00    0.00    0.00    0.00
 40     200           0.00  116716.76    0.00    0.00    0.00    0.00
 80     400           0.00  65560.27   27.62   62.07   17.76    0.28
120     600           0.00  45983.15   44.78   51.72   39.47    0.45
160     800           0.00  29772.89   45.10   48.13   42.43    0.45
200    1000           0.00  19057.33   43.90   46.67   41.45    0.44
240    1200           0.00  12272.08   43.95   45.58   42.43    0.44
280    1400           0.00   8112.56   41.31   43.32   39.47    0.41
320    1600           0.00   5556.87   41.71   43.42   40.13    0.42
360    1800           0.00   4041.66   42.33   42.91   41.78    0.42
400    2000           0.00   2869.90   42.47   43.20   41.78    0.42
440    2200           0.00   2245.22   41.94   44.32   39.80    0.42
480    2400           0.00   1801.25   42.57   43.75   41.45    0.43
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
Total DS: 133, Train: 52 Val: 14 Test: 67
Experiment: 1

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.53      0.39      0.45       221

   micro avg       0.53      0.39      0.45       221
   macro avg       0.53      0.39      0.45       221
weighted avg       0.53      0.39      0.45       221

Precision given by SeqEval: 53.42%
Recall given by SeqEval: 38.91%
F1-Score given by SeqEval: 45.03%
Accuracy given by SeqEval: 98.48%
------------------------------------------------------------
Experiment: 2

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.60      0.45      0.51       216

   micro avg       0.60      0.45      0.51       216
   macro avg       0.60      0.45      0.51       216
weighted avg       0.60      0.45      0.51       216

Precision given by SeqEval: 60.25%
Recall given by SeqEval: 44.91%
F1-Score given by SeqEval: 51.46%
Accuracy given by SeqEval: 98.68%
------------------------------------------------------------
Experiment: 3

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.60      0.54      0.57       287

   micro avg       0.60      0.54      0.57       287
   macro avg       0.60      0.54      0.57       287
weighted avg       0.60      0.54      0.57       287

Precision given by SeqEval: 59.54%
Recall given by SeqEval: 54.36%
F1-Score given by SeqEval: 56.83%
Accuracy given by SeqEval: 99.14%
------------------------------------------------------------
Experiment: 4

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.61      0.51      0.55       251

   micro avg       0.61      0.51      0.55       251
   macro avg       0.61      0.51      0.55       251
weighted avg       0.61      0.51      0.55       251

Precision given by SeqEval: 60.77%
Recall given by SeqEval: 50.60%
F1-Score given by SeqEval: 55.22%
Accuracy given by SeqEval: 98.21%
------------------------------------------------------------
Experiment: 5

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.53      0.68      0.59       171

   micro avg       0.53      0.68      0.59       171
   macro avg       0.53      0.68      0.59       171
weighted avg       0.53      0.68      0.59       171

Precision given by SeqEval: 52.97%
Recall given by SeqEval: 67.84%
F1-Score given by SeqEval: 59.49%
Accuracy given by SeqEval: 98.95%
------------------------------------------------------------
Experiment: 6

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.70      0.55      0.62       410

   micro avg       0.70      0.55      0.62       410
   macro avg       0.70      0.55      0.62       410
weighted avg       0.70      0.55      0.62       410

Precision given by SeqEval: 69.75%
Recall given by SeqEval: 55.12%
F1-Score given by SeqEval: 61.58%
Accuracy given by SeqEval: 97.55%
------------------------------------------------------------
Experiment: 7

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.47      0.43      0.45       283

   micro avg       0.47      0.43      0.45       283
   macro avg       0.47      0.43      0.45       283
weighted avg       0.47      0.43      0.45       283

Precision given by SeqEval: 47.08%
Recall given by SeqEval: 42.76%
F1-Score given by SeqEval: 44.81%
Accuracy given by SeqEval: 97.38%
------------------------------------------------------------
Experiment: 8

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.65      0.56      0.60       169

   micro avg       0.65      0.56      0.60       169
   macro avg       0.65      0.56      0.60       169
weighted avg       0.65      0.56      0.60       169

Precision given by SeqEval: 64.83%
Recall given by SeqEval: 55.62%
F1-Score given by SeqEval: 59.87%
Accuracy given by SeqEval: 98.80%
------------------------------------------------------------
Experiment: 9

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.65      0.63      0.64       273

   micro avg       0.65      0.63      0.64       273
   macro avg       0.65      0.63      0.64       273
weighted avg       0.65      0.63      0.64       273

Precision given by SeqEval: 65.27%
Recall given by SeqEval: 62.64%
F1-Score given by SeqEval: 63.93%
Accuracy given by SeqEval: 99.14%
------------------------------------------------------------
Experiment: 10

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.69      0.62      0.65       575

   micro avg       0.69      0.62      0.65       575
   macro avg       0.69      0.62      0.65       575
weighted avg       0.69      0.62      0.65       575

Precision given by SeqEval: 69.01%
Recall given by SeqEval: 61.57%
F1-Score given by SeqEval: 65.07%
Accuracy given by SeqEval: 98.12%
------------------------------------------------------------
Experiment: 11

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.44      0.41      0.43       149

   micro avg       0.44      0.41      0.43       149
   macro avg       0.44      0.41      0.43       149
weighted avg       0.44      0.41      0.43       149

Precision given by SeqEval: 44.20%
Recall given by SeqEval: 40.94%
F1-Score given by SeqEval: 42.51%
Accuracy given by SeqEval: 98.82%
------------------------------------------------------------
Experiment: 12

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.52      0.50      0.51       190

   micro avg       0.52      0.50      0.51       190
   macro avg       0.52      0.50      0.51       190
weighted avg       0.52      0.50      0.51       190

Precision given by SeqEval: 52.49%
Recall given by SeqEval: 50.00%
F1-Score given by SeqEval: 51.21%
Accuracy given by SeqEval: 98.47%
------------------------------------------------------------
Experiment: 13

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.56      0.44      0.49       342

   micro avg       0.56      0.44      0.49       342
   macro avg       0.56      0.44      0.49       342
weighted avg       0.56      0.44      0.49       342

Precision given by SeqEval: 56.18%
Recall given by SeqEval: 43.86%
F1-Score given by SeqEval: 49.26%
Accuracy given by SeqEval: 98.41%
------------------------------------------------------------
Experiment: 14

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.63      0.54      0.58       199

   micro avg       0.63      0.54      0.58       199
   macro avg       0.63      0.54      0.58       199
weighted avg       0.63      0.54      0.58       199

Precision given by SeqEval: 62.57%
Recall given by SeqEval: 53.77%
F1-Score given by SeqEval: 57.84%
Accuracy given by SeqEval: 98.73%
------------------------------------------------------------
Experiment: 15

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.51      0.48      0.50       242

   micro avg       0.51      0.48      0.50       242
   macro avg       0.51      0.48      0.50       242
weighted avg       0.51      0.48      0.50       242
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 02:23:24,270] [INFO] Set up nlp object from config
[2022-09-21 02:23:24,279] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 02:23:24,279] [INFO] Resuming training for: ['ner']
[2022-09-21 02:23:24,286] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 02:23:30,712] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 02:23:47,285] [INFO] Created vocabulary
[2022-09-21 02:23:48,707] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 02:23:50,755] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    499.83    0.00    0.00    0.00    0.00
 40     200           0.00  120430.38    0.00    0.00    0.00    0.00
 80     400           0.00  68554.29   26.14   56.10   17.04    0.26
120     600           0.00  43829.47   46.06   49.16   43.33    0.46
160     800           0.00  27619.48   47.82   49.03   46.67    0.48
200    1000           0.00  18081.41   45.77   47.60   44.07    0.46
240    1200           0.00  12118.58   45.44   45.69   45.19    0.45
280    1400           0.00   8327.84   44.65   45.25   44.07    0.45
320    1600           0.00   5675.77   44.86   45.28   44.44    0.45
360    1800           0.00   4026.01   45.96   45.62   46.30    0.46
400    2000           0.00   3048.11   44.57   45.08   44.07    0.45
440    2200           0.00   2252.58   44.65   45.25   44.07    0.45
480    2400           0.00   1674.48   45.07   45.32   44.81    0.45
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 02:40:34,016] [INFO] Set up nlp object from config
[2022-09-21 02:40:34,024] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 02:40:34,024] [INFO] Resuming training for: ['ner']
[2022-09-21 02:40:34,031] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 02:40:40,450] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 02:40:56,859] [INFO] Created vocabulary
[2022-09-21 02:40:58,264] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 02:41:00,240] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    207.47    0.00    0.00    0.00    0.00
 40     200           0.00  103482.60    0.00    0.00    0.00    0.00
 80     400           0.00  56174.21   27.95   60.42   18.18    0.28
120     600           0.00  36941.75   43.91   53.36   37.30    0.44
160     800           0.00  23152.38   42.83   50.86   36.99    0.43
200    1000           0.00  15279.16   41.74   49.57   36.05    0.42
240    1200           0.00  10251.52   42.91   51.08   36.99    0.43
280    1400           0.00   6859.25   41.73   48.95   36.36    0.42
320    1600           0.00   4708.56   42.63   49.18   37.62    0.43
360    1800           0.00   3354.04   43.14   50.00   37.93    0.43
400    2000           0.00   2386.71   43.29   50.42   37.93    0.43
440    2200           0.00   1794.93   43.21   50.21   37.93    0.43
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 02:55:31,482] [INFO] Set up nlp object from config
[2022-09-21 02:55:31,491] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 02:55:31,492] [INFO] Resuming training for: ['ner']
[2022-09-21 02:55:31,499] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 02:55:37,960] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 02:55:54,527] [INFO] Created vocabulary
[2022-09-21 02:55:55,968] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 02:55:57,915] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    221.36    0.00    0.00    0.00    0.00
 40     200           0.00  111072.68    0.00    0.00    0.00    0.00
 80     400           0.00  66715.42   32.89   50.41   24.41    0.33
120     600           0.00  42857.40   46.44   43.34   50.00    0.46
160     800           0.00  26549.17   48.14   43.73   53.54    0.48
200    1000           0.00  16976.38   48.26   43.17   54.72    0.48
240    1200           0.00  10950.82   48.35   43.30   54.72    0.48
280    1400           0.00   7450.53   47.79   43.41   53.15    0.48
320    1600           0.00   5006.76   47.08   41.77   53.94    0.47
360    1800           0.00   3554.16   47.49   42.41   53.94    0.47
400    2000           0.00   2587.88   46.42   41.69   52.36    0.46
440    2200           0.00   1797.96   47.32   42.15   53.94    0.47
480    2400           0.00   1486.06   46.13   40.98   52.76    0.46
520    2600           0.00   1196.40   47.80   43.17   53.54    0.48
560    2800           0.00    956.11   46.75   42.22   52.36    0.47
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 03:14:44,119] [INFO] Set up nlp object from config
[2022-09-21 03:14:44,128] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 03:14:44,128] [INFO] Resuming training for: ['ner']
[2022-09-21 03:14:44,135] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 03:14:50,520] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 03:15:07,015] [INFO] Created vocabulary
[2022-09-21 03:15:08,456] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 03:15:10,452] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    183.51    0.00    0.00    0.00    0.00
 40     200           0.00  114784.18    0.00    0.00    0.00    0.00
 80     400           0.00  65087.45   33.98   48.28   26.22    0.34
120     600           0.00  42890.56   45.19   47.52   43.07    0.45
160     800           0.00  27818.74   45.09   46.43   43.82    0.45
200    1000           0.00  18671.02   43.96   43.01   44.94    0.44
240    1200           0.00  12569.06   43.59   42.65   44.57    0.44
280    1400           0.00   8646.34   41.89   40.78   43.07    0.42
320    1600           0.00   6022.36   41.40   40.88   41.95    0.41
360    1800           0.00   4257.68   41.19   40.81   41.57    0.41
400    2000           0.00   3054.62   42.18   40.99   43.45    0.42
440    2200           0.00   2443.81   41.77   41.24   42.32    0.42
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 03:30:08,466] [INFO] Set up nlp object from config
[2022-09-21 03:30:08,474] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 03:30:08,474] [INFO] Resuming training for: ['ner']
[2022-09-21 03:30:08,481] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 03:30:14,964] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 03:30:31,436] [INFO] Created vocabulary
[2022-09-21 03:30:32,861] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 03:30:34,826] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    480.71    0.00    0.00    0.00    0.00
 40     200           0.00  116087.94    0.00    0.00    0.00    0.00
 80     400           0.00  65506.70   30.42   59.22   20.47    0.30
120     600           0.00  45258.76   46.21   54.84   39.93    0.46
160     800           0.00  28728.31   45.04   52.21   39.60    0.45
200    1000           0.00  18832.38   43.18   49.57   38.26    0.43
240    1200           0.00  12188.91   42.70   48.31   38.26    0.43
280    1400           0.00   7738.28   43.45   49.15   38.93    0.43
320    1600           0.00   5166.57   42.32   47.88   37.92    0.42
360    1800           0.00   3593.30   43.99   48.97   39.93    0.44
400    2000           0.00   2690.90   44.12   48.78   40.27    0.44
440    2200           0.00   1914.17   43.28   48.74   38.93    0.43
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 03:45:11,295] [INFO] Set up nlp object from config
[2022-09-21 03:45:11,304] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 03:45:11,304] [INFO] Resuming training for: ['ner']
[2022-09-21 03:45:11,311] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 03:45:17,818] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 03:45:34,302] [INFO] Created vocabulary
[2022-09-21 03:45:35,752] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 03:45:37,714] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    181.64    0.00    0.00    0.00    0.00
 40     200           0.00  108976.29    0.00    0.00    0.00    0.00
 80     400           0.00  61161.48   31.93   51.35   23.17    0.32
120     600           0.00  42678.65   51.57   57.50   46.75    0.52
160     800           0.00  27823.43   51.08   54.63   47.97    0.51
200    1000           0.00  17737.06   49.79   51.29   48.37    0.50
240    1200           0.00  11023.29   50.00   50.84   49.19    0.50
280    1400           0.00   7070.42   48.66   49.37   47.97    0.49
320    1600           0.00   4723.31   49.79   50.85   48.78    0.50
360    1800           0.00   3260.39   51.03   51.67   50.41    0.51
400    2000           0.00   2319.26   50.61   50.82   50.41    0.51
440    2200           0.00   1638.88   51.61   51.20   52.03    0.52
480    2400           0.00   1377.71   49.90   49.80   50.00    0.50
520    2600           0.00   1120.53   48.87   49.38   48.37    0.49
560    2800           0.00    842.47   49.90   49.80   50.00    0.50
600    3000           0.00    697.39   49.90   49.80   50.00    0.50
640    3200           0.00    642.14   49.80   49.60   50.00    0.50
680    3400           0.00    544.47   49.59   50.00   49.19    0.50
720    3600           0.00    479.06   49.90   50.63   49.19    0.50
760    3800           0.00    443.17   48.76   49.58   47.97    0.49
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 04:10:43,189] [INFO] Set up nlp object from config
[2022-09-21 04:10:43,197] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 04:10:43,197] [INFO] Resuming training for: ['ner']
[2022-09-21 04:10:43,204] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 04:10:49,633] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 04:11:06,120] [INFO] Created vocabulary
[2022-09-21 04:11:07,537] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 04:11:09,489] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    949.70    0.00    0.00    0.00    0.00
 40     200           0.00  122848.98    0.00    0.00    0.00    0.00
 80     400           0.00  70474.79   24.10   46.08   16.32    0.24
120     600           0.00  47390.50   42.83   51.21   36.81    0.43
160     800           0.00  28715.58   46.90   51.02   43.40    0.47
200    1000           0.00  18128.57   48.16   51.17   45.49    0.48
240    1200           0.00  12157.10   47.58   51.20   44.44    0.48
280    1400           0.00   8321.87   46.27   50.00   43.06    0.46
320    1600           0.00   5598.46   46.24   50.41   42.71    0.46
360    1800           0.00   3918.17   46.86   50.00   44.10    0.47
400    2000           0.00   2743.95   45.98   49.80   42.71    0.46
440    2200           0.00   2054.90   46.75   50.20   43.75    0.47
480    2400           0.00   1618.17   47.41   50.79   44.44    0.47
520    2600           0.00   1235.97   45.77   51.29   41.32    0.46
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 04:31:41,236] [INFO] Set up nlp object from config
[2022-09-21 04:31:41,245] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 04:31:41,245] [INFO] Resuming training for: ['ner']
[2022-09-21 04:31:41,252] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 04:31:47,848] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 04:32:04,416] [INFO] Created vocabulary
[2022-09-21 04:32:05,837] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 04:32:07,802] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    207.47    0.00    0.00    0.00    0.00
 40     200           0.00  104252.44    0.00    0.00    0.00    0.00
 80     400           0.00  60790.78   35.92   57.36   26.15    0.36
120     600           0.00  38969.43   51.82   53.58   50.18    0.52
160     800           0.00  24920.67   51.67   51.40   51.94    0.52
200    1000           0.00  16775.96   52.07   50.84   53.36    0.52
240    1200           0.00  11278.50   50.51   48.23   53.00    0.51
280    1400           0.00   7781.61   50.59   48.09   53.36    0.51
320    1600           0.00   5379.89   50.77   49.01   52.65    0.51
360    1800           0.00   3885.47   49.75   47.73   51.94    0.50
400    2000           0.00   2803.05   49.24   47.39   51.24    0.49
440    2200           0.00   2042.08   50.00   48.20   51.94    0.50
480    2400           0.00   1504.04   49.23   47.99   50.53    0.49
520    2600           0.00   1217.56   49.66   47.87   51.59    0.50
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 04:49:21,815] [INFO] Set up nlp object from config
[2022-09-21 04:49:21,823] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 04:49:21,823] [INFO] Resuming training for: ['ner']
[2022-09-21 04:49:21,830] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 04:49:28,273] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 04:49:44,792] [INFO] Created vocabulary
[2022-09-21 04:49:46,234] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 04:49:48,164] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    187.50    0.00    0.00    0.00    0.00
 40     200           0.00  105580.69    0.00    0.00    0.00    0.00
 80     400           0.00  60303.91   33.84   57.78   23.93    0.34
120     600           0.00  39339.53   46.48   45.45   47.55    0.46
160     800           0.00  24086.51   44.68   43.70   45.71    0.45
200    1000           0.00  15068.69   44.31   42.74   46.01    0.44
240    1200           0.00   9747.61   43.79   42.29   45.40    0.44
280    1400           0.00   6396.79   42.47   41.72   43.25    0.42
320    1600           0.00   4377.59   43.32   41.95   44.79    0.43
360    1800           0.00   3082.22   43.22   42.03   44.48    0.43
400    2000           0.00   2270.27   43.35   42.27   44.48    0.43
440    2200           0.00   1811.85   42.92   41.74   44.17    0.43
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 05:04:44,674] [INFO] Set up nlp object from config
[2022-09-21 05:04:44,683] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 05:04:44,683] [INFO] Resuming training for: ['ner']
[2022-09-21 05:04:44,690] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 05:04:51,174] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 05:05:07,594] [INFO] Created vocabulary
[2022-09-21 05:05:09,029] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 05:05:10,960] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    198.00    0.00    0.00    0.00    0.00
 40     200           0.00  109112.07    0.00    0.00    0.00    0.00
 80     400           0.00  64119.25   32.43   64.29   21.69    0.32
120     600           0.00  44319.03   50.75   56.46   46.08    0.51
160     800           0.00  29104.05   50.40   53.56   47.59    0.50
200    1000           0.00  19437.01   49.92   52.13   47.89    0.50
240    1200           0.00  12674.33   49.14   50.80   47.59    0.49
280    1400           0.00   8446.46   49.07   50.32   47.89    0.49
320    1600           0.00   5534.00   47.74   49.51   46.08    0.48
360    1800           0.00   3861.42   48.22   49.52   46.99    0.48
400    2000           0.00   2800.26   47.59   49.20   46.08    0.48
440    2200           0.00   2003.08   47.83   49.36   46.39    0.48
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 05:20:08,322] [INFO] Set up nlp object from config
[2022-09-21 05:20:08,331] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 05:20:08,331] [INFO] Resuming training for: ['ner']
[2022-09-21 05:20:08,338] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 05:20:14,798] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 05:20:31,308] [INFO] Created vocabulary
[2022-09-21 05:20:32,726] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 05:20:34,707] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    187.50    0.00    0.00    0.00    0.00
 40     200           0.00  112361.38    0.00    0.00    0.00    0.00
 80     400           0.00  64736.98   35.15   59.68   24.92    0.35
120     600           0.00  44536.81   45.30   50.00   41.41    0.45
160     800           0.00  28308.26   48.19   49.30   47.14    0.48
200    1000           0.00  18235.24   47.67   48.94   46.46    0.48
240    1200           0.00  11763.09   47.14   48.57   45.79    0.47
280    1400           0.00   7522.98   46.77   48.55   45.12    0.47
320    1600           0.00   5026.99   47.02   49.08   45.12    0.47
360    1800           0.00   3536.64   46.40   48.53   44.44    0.46
400    2000           0.00   2533.97   45.77   47.97   43.77    0.46
440    2200           0.00   1820.03   46.96   48.56   45.45    0.47
480    2400           0.00   1417.14   47.20   49.09   45.45    0.47
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 05:36:50,508] [INFO] Set up nlp object from config
[2022-09-21 05:36:50,516] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 05:36:50,516] [INFO] Resuming training for: ['ner']
[2022-09-21 05:36:50,523] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 05:36:56,969] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 05:37:13,412] [INFO] Created vocabulary
[2022-09-21 05:37:14,839] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 05:37:16,821] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    502.82    0.00    0.00    0.00    0.00
 40     200           0.00  117307.67    0.00    0.00    0.00    0.00
 80     400           0.00  68409.00   37.53   55.41   28.37    0.38
120     600           0.00  43592.84   48.77   49.47   48.10    0.49
160     800           0.00  27608.14   47.93   47.77   48.10    0.48
200    1000           0.00  18099.40   45.86   45.70   46.02    0.46
240    1200           0.00  11917.01   46.90   45.45   48.44    0.47
280    1400           0.00   8165.68   46.68   45.97   47.40    0.47
320    1600           0.00   5601.29   45.81   45.27   46.37    0.46
360    1800           0.00   3954.30   45.17   45.02   45.33    0.45
400    2000           0.00   2981.14   46.28   45.21   47.40    0.46
440    2200           0.00   2305.43   44.86   43.75   46.02    0.45
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 05:52:19,874] [INFO] Set up nlp object from config
[2022-09-21 05:52:19,883] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 05:52:19,883] [INFO] Resuming training for: ['ner']
[2022-09-21 05:52:19,890] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 05:52:26,342] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 05:52:42,757] [INFO] Created vocabulary
[2022-09-21 05:52:44,168] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 05:52:46,098] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    499.83    0.00    0.00    0.00    0.00
 40     200           0.00  112599.56    0.00    0.00    0.00    0.00
 80     400           0.00  66134.40   28.23   39.89   21.85    0.28
120     600           0.00  42937.32   42.79   41.38   44.31    0.43
160     800           0.00  27876.23   44.79   41.76   48.31    0.45
200    1000           0.00  18484.49   45.49   42.51   48.92    0.45
240    1200           0.00  12321.59   46.26   42.71   50.46    0.46
280    1400           0.00   8417.37   45.76   42.97   48.92    0.46
320    1600           0.00   5920.18   44.73   42.12   47.69    0.45
360    1800           0.00   4091.20   44.25   41.99   46.77    0.44
400    2000           0.00   3051.99   45.69   42.86   48.92    0.46
440    2200           0.00   2254.11   45.82   43.09   48.92    0.46
480    2400           0.00   1858.15   43.60   41.32   46.15    0.44
520    2600           0.00   1368.23   42.86   41.50   44.31    0.43
560    2800           0.00   1207.86   45.06   42.70   47.69    0.45
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 06:11:42,316] [INFO] Set up nlp object from config
[2022-09-21 06:11:42,325] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 06:11:42,325] [INFO] Resuming training for: ['ner']
[2022-09-21 06:11:42,332] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 06:11:48,741] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 06:12:05,119] [INFO] Created vocabulary
[2022-09-21 06:12:06,544] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 06:12:08,474] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    191.45    0.00    0.00    0.00    0.00
 40     200           0.00  107629.79    0.00    0.00    0.00    0.00
 80     400           0.00  61850.56   28.70   60.19   18.84    0.29
120     600           0.00  42699.22   45.86   52.99   40.43    0.46
160     800           0.00  27987.70   46.40   48.99   44.07    0.46
200    1000           0.00  18411.33   46.30   48.04   44.68    0.46
240    1200           0.00  12259.23   45.10   46.18   44.07    0.45
280    1400           0.00   8588.01   44.10   44.44   43.77    0.44
320    1600           0.00   5884.36   43.96   45.45   42.55    0.44
360    1800           0.00   4230.09   43.79   44.76   42.86    0.44
400    2000           0.00   3122.21   44.51   45.95   43.16    0.45
440    2200           0.00   2199.09   43.80   44.14   43.47    0.44
480    2400           0.00   1789.41   43.59   44.34   42.86    0.44
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 06:28:21,511] [INFO] Set up nlp object from config
[2022-09-21 06:28:21,519] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 06:28:21,519] [INFO] Resuming training for: ['ner']
[2022-09-21 06:28:21,526] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 06:28:28,050] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 06:28:44,632] [INFO] Created vocabulary
[2022-09-21 06:28:46,063] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 06:28:48,163] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    207.47    0.00    0.00    0.00    0.00
 40     200           0.00  99243.42    0.00    0.00    0.00    0.00
 80     400           0.00  53132.15   27.88   69.05   17.47    0.28
120     600           0.00  34948.55   42.73   52.89   35.84    0.43
160     800           0.00  22104.00   46.49   52.26   41.87    0.46
200    1000           0.00  13910.90   46.67   52.24   42.17    0.47
240    1200           0.00   8967.89   45.25   49.64   41.57    0.45
280    1400           0.00   5781.79   46.05   50.72   42.17    0.46
320    1600           0.00   3968.46   46.20   49.83   43.07    0.46
360    1800           0.00   2676.06   45.98   49.31   43.07    0.46
400    2000           0.00   1943.79   45.65   50.18   41.87    0.46
440    2200           0.00   1461.61   45.25   49.64   41.57    0.45
480    2400           0.00   1127.25   45.53   49.47   42.17    0.46
520    2600           0.00    897.99   45.20   49.12   41.87    0.45
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last

Precision given by SeqEval: 51.32%
Recall given by SeqEval: 48.35%
F1-Score given by SeqEval: 49.79%
Accuracy given by SeqEval: 98.23%
------------------------------------------------------------
Experiment: 16

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.66      0.61      0.63       326

   micro avg       0.66      0.61      0.63       326
   macro avg       0.66      0.61      0.63       326
weighted avg       0.66      0.61      0.63       326

Precision given by SeqEval: 66.22%
Recall given by SeqEval: 60.74%
F1-Score given by SeqEval: 63.36%
Accuracy given by SeqEval: 98.33%
------------------------------------------------------------
Experiment: 17

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.58      0.48      0.52       286

   micro avg       0.58      0.48      0.52       286
   macro avg       0.58      0.48      0.52       286
weighted avg       0.58      0.48      0.52       286

Precision given by SeqEval: 57.56%
Recall given by SeqEval: 47.90%
F1-Score given by SeqEval: 52.29%
Accuracy given by SeqEval: 97.80%
------------------------------------------------------------
Experiment: 18

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.63      0.47      0.54       171

   micro avg       0.63      0.47      0.54       171
   macro avg       0.63      0.47      0.54       171
weighted avg       0.63      0.47      0.54       171

Precision given by SeqEval: 63.28%
Recall given by SeqEval: 47.37%
F1-Score given by SeqEval: 54.18%
Accuracy given by SeqEval: 98.98%
------------------------------------------------------------
Experiment: 19

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.70      0.75      0.73       403

   micro avg       0.70      0.75      0.73       403
   macro avg       0.70      0.75      0.73       403
weighted avg       0.70      0.75      0.73       403

Precision given by SeqEval: 70.05%
Recall given by SeqEval: 75.43%
F1-Score given by SeqEval: 72.64%
Accuracy given by SeqEval: 98.81%
------------------------------------------------------------
Experiment: 20

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.52      0.62      0.56       221

   micro avg       0.52      0.62      0.56       221
   macro avg       0.52      0.62      0.56       221
weighted avg       0.52      0.62      0.56       221

Precision given by SeqEval: 51.70%
Recall given by SeqEval: 61.99%
F1-Score given by SeqEval: 56.38%
Accuracy given by SeqEval: 98.45%
------------------------------------------------------------
Experiment: 21

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.49      0.40      0.44       183

   micro avg       0.49      0.40      0.44       183
   macro avg       0.49      0.40      0.44       183
weighted avg       0.49      0.40      0.44       183

Precision given by SeqEval: 49.33%
Recall given by SeqEval: 40.44%
F1-Score given by SeqEval: 44.44%
Accuracy given by SeqEval: 98.88%
------------------------------------------------------------
Experiment: 22

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.40      0.44      0.42       156

   micro avg       0.40      0.44      0.42       156
   macro avg       0.40      0.44      0.42       156
weighted avg       0.40      0.44      0.42       156

Precision given by SeqEval: 40.12%
Recall given by SeqEval: 44.23%
F1-Score given by SeqEval: 42.07%
Accuracy given by SeqEval: 98.87%
------------------------------------------------------------
Experiment: 23

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.69      0.59      0.63       493

   micro avg       0.69      0.59      0.63       493
   macro avg       0.69      0.59      0.63       493
weighted avg       0.69      0.59      0.63       493

Precision given by SeqEval: 68.81%
Recall given by SeqEval: 58.62%
F1-Score given by SeqEval: 63.31%
Accuracy given by SeqEval: 97.75%
------------------------------------------------------------
Experiment: 24

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.53      0.52      0.53       558

   micro avg       0.53      0.52      0.53       558
   macro avg       0.53      0.52      0.53       558
weighted avg       0.53      0.52      0.53       558

Precision given by SeqEval: 53.43%
Recall given by SeqEval: 51.61%
F1-Score given by SeqEval: 52.51%
Accuracy given by SeqEval: 98.09%
------------------------------------------------------------
Experiment: 25

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.72      0.70      0.71       366

   micro avg       0.72      0.70      0.71       366
   macro avg       0.72      0.70      0.71       366
weighted avg       0.72      0.70      0.71       366

Precision given by SeqEval: 71.63%
Recall given by SeqEval: 69.67%
F1-Score given by SeqEval: 70.64%
Accuracy given by SeqEval: 99.24%
------------------------------------------------------------
Experiment: 26

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.62      0.52      0.56       385

   micro avg       0.62      0.52      0.56       385
   macro avg       0.62      0.52      0.56       385
weighted avg       0.62      0.52      0.56       385

Precision given by SeqEval: 61.73%
Recall given by SeqEval: 51.95%
F1-Score given by SeqEval: 56.42%
Accuracy given by SeqEval: 97.34%
------------------------------------------------------------
Experiment: 27

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.63      0.55      0.59       157

   micro avg       0.63      0.55      0.59       157
   macro avg       0.63      0.55      0.59       157
weighted avg       0.63      0.55      0.59       157

Precision given by SeqEval: 63.24%
Recall given by SeqEval: 54.78%
F1-Score given by SeqEval: 58.70%
Accuracy given by SeqEval: 99.45%
------------------------------------------------------------
Experiment: 28

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.56      0.50      0.53       562

   micro avg       0.56      0.50      0.53       562
   macro avg       0.56      0.50      0.53       562
weighted avg       0.56      0.50      0.53       562

Precision given by SeqEval: 55.64%
Recall given by SeqEval: 50.00%
F1-Score given by SeqEval: 52.67%
Accuracy given by SeqEval: 97.47%
------------------------------------------------------------
Experiment: 29

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.38      0.42      0.40       137

   micro avg       0.38      0.42      0.40       137
   macro avg       0.38      0.42      0.40       137
weighted avg       0.38      0.42      0.40       137

Precision given by SeqEval: 37.75%
Recall given by SeqEval: 41.61%
F1-Score given by SeqEval: 39.58%
Accuracy given by SeqEval: 98.65%
------------------------------------------------------------
Experiment: 30

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.31      0.51      0.39        73

   micro avg       0.31      0.51      0.39        73
   macro avg       0.31      0.51      0.39        73
weighted avg       0.31      0.51      0.39        73
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 06:45:49,414] [INFO] Set up nlp object from config
[2022-09-21 06:45:49,423] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 06:45:49,423] [INFO] Resuming training for: ['ner']
[2022-09-21 06:45:49,431] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 06:45:55,986] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 06:46:12,616] [INFO] Created vocabulary
[2022-09-21 06:46:14,044] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 06:46:16,024] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    273.10    0.00    0.00    0.00    0.00
 40     200           0.00  110601.89    0.00    0.00    0.00    0.00
 80     400           0.00  65785.59   35.86   53.89   26.87    0.36
120     600           0.00  42394.10   45.59   49.31   42.39    0.46
160     800           0.00  26802.33   43.89   45.51   42.39    0.44
200    1000           0.00  17933.46   44.24   46.25   42.39    0.44
240    1200           0.00  12031.95   43.53   46.15   41.19    0.44
280    1400           0.00   8318.47   43.96   46.36   41.79    0.44
320    1600           0.00   5749.99   44.09   47.42   41.19    0.44
360    1800           0.00   4106.10   43.64   46.03   41.49    0.44
400    2000           0.00   3009.40   43.89   46.20   41.79    0.44
440    2200           0.00   2206.74   43.81   46.78   41.19    0.44
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 07:01:25,122] [INFO] Set up nlp object from config
[2022-09-21 07:01:25,130] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 07:01:25,130] [INFO] Resuming training for: ['ner']
[2022-09-21 07:01:25,137] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 07:01:31,688] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 07:01:48,283] [INFO] Created vocabulary
[2022-09-21 07:01:49,729] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 07:01:51,700] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    229.21    0.00    0.00    0.00    0.00
 40     200           0.00  103802.37    0.00    0.00    0.00    0.00
 80     400           0.00  61372.72   34.00   57.58   24.13    0.34
120     600           0.00  41694.88   52.56   54.83   50.48    0.53
160     800           0.00  27709.99   52.03   53.33   50.79    0.52
200    1000           0.00  18472.58   50.89   51.99   49.84    0.51
240    1200           0.00  12607.08   48.87   49.51   48.25    0.49
280    1400           0.00   8605.11   49.04   49.20   48.89    0.49
320    1600           0.00   6139.94   48.66   48.43   48.89    0.49
360    1800           0.00   4536.76   48.67   48.14   49.21    0.49
400    2000           0.00   3293.43   48.59   47.99   49.21    0.49
440    2200           0.00   2572.79   47.44   46.36   48.57    0.47
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 07:17:38,571] [INFO] Set up nlp object from config
[2022-09-21 07:17:38,580] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 07:17:38,580] [INFO] Resuming training for: ['ner']
[2022-09-21 07:17:38,587] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 07:17:45,116] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 07:18:01,774] [INFO] Created vocabulary
[2022-09-21 07:18:03,208] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 07:18:05,195] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    438.48    0.00    0.00    0.00    0.00
 40     200           0.00  117885.33    0.00    0.00    0.00    0.00
 80     400           0.00  66586.95   35.56   51.20   27.23    0.36
120     600           0.00  44501.34   47.95   46.25   49.79    0.48
160     800           0.00  29053.17   47.62   44.61   51.06    0.48
200    1000           0.00  19371.18   47.41   44.57   50.64    0.47
240    1200           0.00  12898.26   47.15   43.80   51.06    0.47
280    1400           0.00   8748.77   46.67   43.27   50.64    0.47
320    1600           0.00   6055.06   46.43   43.49   49.79    0.46
360    1800           0.00   4332.83   46.83   43.87   50.21    0.47
400    2000           0.00   3057.10   46.30   42.65   50.64    0.46
440    2200           0.00   2489.20   46.61   43.82   49.79    0.47
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 07:34:00,985] [INFO] Set up nlp object from config
[2022-09-21 07:34:00,994] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 07:34:00,994] [INFO] Resuming training for: ['ner']
[2022-09-21 07:34:01,001] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 07:34:07,480] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 07:34:24,100] [INFO] Created vocabulary
[2022-09-21 07:34:25,546] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 07:34:27,602] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    229.21    0.00    0.00    0.00    0.00
 40     200           0.00  104413.04    0.00    0.00    0.00    0.00
 80     400           0.00  59215.47   19.67   42.25   12.82    0.20
120     600           0.00  38698.81   41.12   45.36   37.61    0.41
160     800           0.00  24435.24   41.78   46.35   38.03    0.42
200    1000           0.00  15691.08   43.09   47.67   39.32    0.43
240    1200           0.00  10599.22   43.84   47.06   41.03    0.44
280    1400           0.00   7059.61   42.86   46.50   39.74    0.43
320    1600           0.00   4755.61   43.74   46.83   41.03    0.44
360    1800           0.00   3377.14   43.58   47.03   40.60    0.44
400    2000           0.00   2413.01   43.12   46.53   40.17    0.43
440    2200           0.00   1778.48   43.72   47.96   40.17    0.44
480    2400           0.00   1486.34   43.09   47.67   39.32    0.43
520    2600           0.00   1093.65   43.71   49.20   39.32    0.44
560    2800           0.00    883.21   43.33   48.92   38.89    0.43
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 07:53:22,063] [INFO] Set up nlp object from config
[2022-09-21 07:53:22,072] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 07:53:22,072] [INFO] Resuming training for: ['ner']
[2022-09-21 07:53:22,079] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 07:53:28,521] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 07:53:45,075] [INFO] Created vocabulary
[2022-09-21 07:53:46,507] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 07:53:48,583] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    429.66    0.00    0.00    0.00    0.00
 40     200           0.00  112049.61    0.00    0.00    0.00    0.00
 80     400           0.00  61948.82   26.67   41.79   19.58    0.27
120     600           0.00  38100.17   42.28   44.57   40.21    0.42
160     800           0.00  23722.16   44.94   44.11   45.80    0.45
200    1000           0.00  15092.06   45.76   44.41   47.20    0.46
240    1200           0.00   9837.41   45.39   44.33   46.50    0.45
280    1400           0.00   6445.33   44.71   43.67   45.80    0.45
320    1600           0.00   4258.05   45.44   44.75   46.15    0.45
360    1800           0.00   2935.42   43.64   42.91   44.41    0.44
400    2000           0.00   2226.54   44.33   43.58   45.10    0.44
440    2200           0.00   1758.77   44.48   43.88   45.10    0.44
480    2400           0.00   1326.39   43.62   41.94   45.45    0.44
520    2600           0.00    988.29   43.52   43.00   44.06    0.44
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 08:11:22,984] [INFO] Set up nlp object from config
[2022-09-21 08:11:22,993] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 08:11:22,993] [INFO] Resuming training for: ['ner']
[2022-09-21 08:11:23,000] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 08:11:29,631] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 08:11:46,433] [INFO] Created vocabulary
[2022-09-21 08:11:47,882] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 08:11:49,870] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    229.21    0.00    0.00    0.00    0.00
 40     200           0.00  104469.05    0.00    0.00    0.00    0.00
 80     400           0.00  61789.79   20.63   43.82   13.49    0.21
120     600           0.00  41394.28   38.15   43.04   34.26    0.38
160     800           0.00  26130.07   40.37   42.97   38.06    0.40
200    1000           0.00  16890.44   41.83   44.53   39.45    0.42
240    1200           0.00  11293.36   42.78   46.72   39.45    0.43
280    1400           0.00   7383.45   41.73   45.68   38.41    0.42
320    1600           0.00   4806.40   42.46   45.97   39.45    0.42
360    1800           0.00   3322.69   41.83   46.41   38.06    0.42
400    2000           0.00   2452.99   41.73   45.68   38.41    0.42
440    2200           0.00   1862.44   39.32   43.33   35.99    0.39
480    2400           0.00   1428.56   38.87   42.74   35.64    0.39
520    2600           0.00   1087.13   39.10   42.80   35.99    0.39
560    2800           0.00    842.79   38.72   42.39   35.64    0.39
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 08:30:49,722] [INFO] Set up nlp object from config
[2022-09-21 08:30:49,731] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 08:30:49,731] [INFO] Resuming training for: ['ner']
[2022-09-21 08:30:49,738] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 08:30:56,286] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 08:31:12,949] [INFO] Created vocabulary
[2022-09-21 08:31:14,401] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 08:31:16,349] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    897.18    0.00    0.00    0.00    0.00
 50     200           0.00  130173.12    0.00    0.00    0.00    0.00
100     400           0.00  72976.83   37.39   67.02   25.93    0.37
150     600           0.00  45421.47   51.12   56.16   46.91    0.51
200     800           0.00  26208.81   52.99   55.11   51.03    0.53
250    1000           0.00  14431.99   51.82   54.02   49.79    0.52
300    1200           0.00   8250.38   50.66   53.95   47.74    0.51
350    1400           0.00   4950.38   50.21   51.98   48.56    0.50
400    1600           0.00   3131.38   49.78   53.02   46.91    0.50
450    1800           0.00   2116.50   49.67   52.78   46.91    0.50
500    2000           0.00   1478.26   48.91   52.09   46.09    0.49
550    2200           0.00   1141.54   48.38   50.91   46.09    0.48
600    2400           0.00    776.60   48.48   51.14   46.09    0.48
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 08:49:22,303] [INFO] Set up nlp object from config
[2022-09-21 08:49:22,311] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 08:49:22,311] [INFO] Resuming training for: ['ner']
[2022-09-21 08:49:22,318] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 08:49:28,860] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 08:49:45,478] [INFO] Created vocabulary
[2022-09-21 08:49:46,928] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 08:49:48,879] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    869.42    0.00    0.00    0.00    0.00
 40     200           0.00  118769.72    0.00    0.00    0.00    0.00
 80     400           0.00  66471.67   23.64   54.17   15.12    0.24
120     600           0.00  44816.14   45.42   46.72   44.19    0.45
160     800           0.00  28569.98   47.28   45.82   48.84    0.47
200    1000           0.00  18486.74   46.88   45.76   48.06    0.47
240    1200           0.00  12270.20   45.90   44.24   47.67    0.46
280    1400           0.00   8325.90   46.90   45.45   48.45    0.47
320    1600           0.00   5858.30   45.77   45.42   46.12    0.46
360    1800           0.00   4158.69   45.72   43.93   47.67    0.46
400    2000           0.00   3042.00   45.61   44.04   47.29    0.46
440    2200           0.00   2263.86   43.59   43.02   44.19    0.44
480    2400           0.00   1763.40   44.40   42.81   46.12    0.44
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 09:07:06,624] [INFO] Set up nlp object from config
[2022-09-21 09:07:06,632] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 09:07:06,632] [INFO] Resuming training for: ['ner']
[2022-09-21 09:07:06,639] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 09:07:13,182] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 09:07:29,860] [INFO] Created vocabulary
[2022-09-21 09:07:31,297] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 09:07:33,233] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    273.10    0.00    0.00    0.00    0.00
 40     200           0.00  109520.94    0.00    0.00    0.00    0.00
 80     400           0.00  64495.90   38.94   57.14   29.53    0.39
120     600           0.00  42836.56   48.00   52.38   44.30    0.48
160     800           0.00  27268.40   44.76   46.72   42.95    0.45
200    1000           0.00  17993.86   42.53   44.65   40.60    0.43
240    1200           0.00  12086.32   43.14   46.01   40.60    0.43
280    1400           0.00   8432.81   42.33   44.61   40.27    0.42
320    1600           0.00   5872.18   42.03   43.96   40.27    0.42
360    1800           0.00   4144.91   41.48   43.54   39.60    0.41
400    2000           0.00   2978.02   40.77   42.39   39.26    0.41
440    2200           0.00   2277.24   40.63   42.49   38.93    0.41
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 09:22:02,280] [INFO] Set up nlp object from config
[2022-09-21 09:22:02,288] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 09:22:02,288] [INFO] Resuming training for: ['ner']
[2022-09-21 09:22:02,295] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 09:22:08,785] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 09:22:25,519] [INFO] Created vocabulary
[2022-09-21 09:22:26,950] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 09:22:28,927] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    181.64    0.00    0.00    0.00    0.00
 40     200           0.00  109308.37    0.00    0.00    0.00    0.00
 80     400           0.00  59153.08   36.41   55.15   27.17    0.36
120     600           0.00  40702.83   47.64   52.16   43.84    0.48
160     800           0.00  26646.33   48.39   50.59   46.38    0.48
200    1000           0.00  17074.59   47.21   48.47   46.01    0.47
240    1200           0.00  10965.96   48.07   48.70   47.46    0.48
280    1400           0.00   7199.69   48.52   49.62   47.46    0.49
320    1600           0.00   5006.52   48.53   49.25   47.83    0.49
360    1800           0.00   3569.51   47.57   49.22   46.01    0.48
400    2000           0.00   2689.87   46.90   48.64   45.29    0.47
440    2200           0.00   2102.31   47.12   48.29   46.01    0.47
480    2400           0.00   1598.93   46.64   48.08   45.29    0.47
520    2600           0.00   1201.77   47.37   49.22   45.65    0.47
560    2800           0.00   1004.69   47.67   49.04   46.38    0.48
600    3000           0.00    884.89   47.01   48.46   45.65    0.47
640    3200           0.00    716.73   46.62   48.44   44.93    0.47
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 09:43:46,469] [INFO] Set up nlp object from config
[2022-09-21 09:43:46,478] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 09:43:46,478] [INFO] Resuming training for: ['ner']
[2022-09-21 09:43:46,485] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 09:43:52,978] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 09:44:09,638] [INFO] Created vocabulary
[2022-09-21 09:44:11,073] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 09:44:13,041] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    863.27    0.00    0.00    0.00    0.00
 50     200           0.00  135180.92    0.00    0.00    0.00    0.00
100     400           0.00  76485.02   28.98   45.81   21.19    0.29
150     600           0.00  47554.06   42.53   46.62   39.10    0.43
200     800           0.00  27277.32   44.26   48.24   40.90    0.44
250    1000           0.00  15692.85   44.24   46.25   42.39    0.44
300    1200           0.00   9349.46   44.34   46.84   42.09    0.44
350    1400           0.00   5510.60   44.02   47.26   41.19    0.44
400    1600           0.00   3585.72   43.49   44.65   42.39    0.43
450    1800           0.00   2509.72   43.28   44.87   41.79    0.43
500    2000           0.00   1813.43   43.55   45.45   41.79    0.44
550    2200           0.00   1281.58   42.72   45.45   40.30    0.43
600    2400           0.00   1042.80   42.81   46.05   40.00    0.43
650    2600           0.00    840.05   41.65   44.56   39.10    0.42
700    2800           0.00    617.19   42.81   44.92   40.90    0.43
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 10:05:07,478] [INFO] Set up nlp object from config
[2022-09-21 10:05:07,486] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 10:05:07,486] [INFO] Resuming training for: ['ner']
[2022-09-21 10:05:07,493] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 10:05:14,002] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 10:05:30,594] [INFO] Created vocabulary
[2022-09-21 10:05:32,030] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 10:05:34,130] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    480.71    0.00    0.00    0.00    0.00
 40     200           0.00  121154.78    0.00    0.00    0.00    0.00
 80     400           0.00  69603.91   38.10   56.69   28.69    0.38
120     600           0.00  48216.10   48.66   46.86   50.60    0.49
160     800           0.00  30386.84   49.28   44.92   54.58    0.49
200    1000           0.00  19559.14   48.83   44.44   54.18    0.49
240    1200           0.00  12680.95   48.51   43.40   54.98    0.49
280    1400           0.00   8349.62   47.70   42.86   53.78    0.48
320    1600           0.00   5714.99   46.73   42.04   52.59    0.47
360    1800           0.00   4018.83   47.14   42.72   52.59    0.47
400    2000           0.00   2779.96   47.10   42.14   53.39    0.47
440    2200           0.00   2113.37   45.96   41.07   52.19    0.46
480    2400           0.00   1628.57   46.49   42.43   51.39    0.46
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 10:22:14,351] [INFO] Set up nlp object from config
[2022-09-21 10:22:14,359] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 10:22:14,359] [INFO] Resuming training for: ['ner']
[2022-09-21 10:22:14,367] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 10:22:20,933] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 10:22:37,720] [INFO] Created vocabulary
[2022-09-21 10:22:39,173] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 10:22:41,156] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    221.36    0.00    0.00    0.00    0.00
 40     200           0.00  109064.68    0.00    0.00    0.00    0.00
 80     400           0.00  62562.00   23.01   40.00   16.15    0.23
120     600           0.00  40487.58   37.35   37.80   36.92    0.37
160     800           0.00  25309.94   40.51   38.54   42.69    0.41
200    1000           0.00  16249.70   39.64   37.59   41.92    0.40
240    1200           0.00  10386.48   37.69   36.59   38.85    0.38
280    1400           0.00   6929.10   38.49   37.78   39.23    0.38
320    1600           0.00   4813.49   38.79   38.01   39.62    0.39
360    1800           0.00   3418.02   37.95   37.45   38.46    0.38
400    2000           0.00   2606.36   37.57   36.04   39.23    0.38
440    2200           0.00   1853.80   37.06   35.44   38.85    0.37
480    2400           0.00   1459.41   36.70   35.77   37.69    0.37
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 10:38:54,894] [INFO] Set up nlp object from config
[2022-09-21 10:38:54,902] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 10:38:54,902] [INFO] Resuming training for: ['ner']
[2022-09-21 10:38:54,909] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 10:39:01,508] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 10:39:18,251] [INFO] Created vocabulary
[2022-09-21 10:39:19,697] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 10:39:21,683] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    207.47    0.00    0.00    0.00    0.00
 40     200           0.00  110770.82    0.00    0.00    0.00    0.00
 80     400           0.00  60355.86   31.84   59.66   21.71    0.32
120     600           0.00  40360.69   44.84   53.62   38.53    0.45
160     800           0.00  24706.41   46.76   52.90   41.90    0.47
200    1000           0.00  15864.50   45.35   50.76   40.98    0.45
240    1200           0.00  10099.83   45.61   50.94   41.28    0.46
280    1400           0.00   6531.45   45.30   50.19   41.28    0.45
320    1600           0.00   4100.43   45.61   50.94   41.28    0.46
360    1800           0.00   2777.61   44.41   48.90   40.67    0.44
400    2000           0.00   2103.52   45.00   49.45   41.28    0.45
440    2200           0.00   1558.30   43.51   48.50   39.45    0.44
480    2400           0.00   1253.02   43.45   47.46   40.06    0.43
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 10:55:54,330] [INFO] Set up nlp object from config
[2022-09-21 10:55:54,339] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 10:55:54,339] [INFO] Resuming training for: ['ner']
[2022-09-21 10:55:54,346] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 10:56:00,812] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 10:56:17,367] [INFO] Created vocabulary
[2022-09-21 10:56:18,814] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 10:56:20,902] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    408.20    0.00    0.00    0.00    0.00
 40     200           0.00  117220.48    0.00    0.00    0.00    0.00
 80     400           0.00  62626.40   29.47   43.41   22.31    0.29
120     600           0.00  42111.17   38.33   40.17   36.65    0.38
160     800           0.00  25868.00   40.63   40.23   41.04    0.41
200    1000           0.00  16100.71   40.71   40.39   41.04    0.41
240    1200           0.00  10195.48   44.53   43.68   45.42    0.45
280    1400           0.00   6574.62   44.71   44.80   44.62    0.45
320    1600           0.00   4492.35   45.07   45.53   44.62    0.45
360    1800           0.00   3125.17   46.09   46.37   45.82    0.46
400    2000           0.00   2227.75   45.12   46.06   44.22    0.45
440    2200           0.00   1702.57   45.16   45.71   44.62    0.45
480    2400           0.00   1294.43   44.67   45.12   44.22    0.45
520    2600           0.00   1017.01   44.90   46.03   43.82    0.45
560    2800           0.00    743.69   44.44   45.08   43.82    0.44
600    3000           0.00    640.33   44.35   45.76   43.03    0.44
640    3200           0.00    534.04   44.40   45.42   43.43    0.44
680    3400           0.00    478.90   44.72   46.55   43.03    0.45
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last

Precision given by SeqEval: 31.36%
Recall given by SeqEval: 50.68%
F1-Score given by SeqEval: 38.74%
Accuracy given by SeqEval: 98.66%
------------------------------------------------------------
Experiment: 31

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.59      0.39      0.47       194

   micro avg       0.59      0.39      0.47       194
   macro avg       0.59      0.39      0.47       194
weighted avg       0.59      0.39      0.47       194

Precision given by SeqEval: 58.91%
Recall given by SeqEval: 39.18%
F1-Score given by SeqEval: 47.06%
Accuracy given by SeqEval: 98.66%
------------------------------------------------------------
Experiment: 32

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.62      0.52      0.57       271

   micro avg       0.62      0.52      0.57       271
   macro avg       0.62      0.52      0.57       271
weighted avg       0.62      0.52      0.57       271

Precision given by SeqEval: 61.84%
Recall given by SeqEval: 52.03%
F1-Score given by SeqEval: 56.51%
Accuracy given by SeqEval: 98.70%
------------------------------------------------------------
Experiment: 33

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.58      0.74      0.65       105

   micro avg       0.58      0.74      0.65       105
   macro avg       0.58      0.74      0.65       105
weighted avg       0.58      0.74      0.65       105

Precision given by SeqEval: 58.21%
Recall given by SeqEval: 74.29%
F1-Score given by SeqEval: 65.27%
Accuracy given by SeqEval: 99.25%
------------------------------------------------------------
Experiment: 34

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.47      0.54      0.50       200

   micro avg       0.47      0.54      0.50       200
   macro avg       0.47      0.54      0.50       200
weighted avg       0.47      0.54      0.50       200

Precision given by SeqEval: 47.35%
Recall given by SeqEval: 53.50%
F1-Score given by SeqEval: 50.23%
Accuracy given by SeqEval: 98.85%
------------------------------------------------------------
Experiment: 35

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.73      0.53      0.62       491

   micro avg       0.73      0.53      0.62       491
   macro avg       0.73      0.53      0.62       491
weighted avg       0.73      0.53      0.62       491

Precision given by SeqEval: 73.11%
Recall given by SeqEval: 53.16%
F1-Score given by SeqEval: 61.56%
Accuracy given by SeqEval: 98.56%
------------------------------------------------------------
Experiment: 36

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.52      0.45      0.49       205

   micro avg       0.52      0.45      0.49       205
   macro avg       0.52      0.45      0.49       205
weighted avg       0.52      0.45      0.49       205

Precision given by SeqEval: 52.25%
Recall given by SeqEval: 45.37%
F1-Score given by SeqEval: 48.56%
Accuracy given by SeqEval: 98.05%
------------------------------------------------------------
Experiment: 37

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.63      0.75      0.69        83

   micro avg       0.63      0.75      0.69        83
   macro avg       0.63      0.75      0.69        83
weighted avg       0.63      0.75      0.69        83

Precision given by SeqEval: 63.27%
Recall given by SeqEval: 74.70%
F1-Score given by SeqEval: 68.51%
Accuracy given by SeqEval: 99.48%
------------------------------------------------------------
Experiment: 38

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.66      0.67      0.66       420

   micro avg       0.66      0.67      0.66       420
   macro avg       0.66      0.67      0.66       420
weighted avg       0.66      0.67      0.66       420

Precision given by SeqEval: 65.65%
Recall given by SeqEval: 66.90%
F1-Score given by SeqEval: 66.27%
Accuracy given by SeqEval: 98.15%
------------------------------------------------------------
Experiment: 39

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.56      0.61      0.58       305

   micro avg       0.56      0.61      0.58       305
   macro avg       0.56      0.61      0.58       305
weighted avg       0.56      0.61      0.58       305

Precision given by SeqEval: 55.89%
Recall given by SeqEval: 60.66%
F1-Score given by SeqEval: 58.18%
Accuracy given by SeqEval: 98.90%
------------------------------------------------------------
Experiment: 40

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.57      0.50      0.53       149

   micro avg       0.57      0.50      0.53       149
   macro avg       0.57      0.50      0.53       149
weighted avg       0.57      0.50      0.53       149

Precision given by SeqEval: 57.36%
Recall given by SeqEval: 49.66%
F1-Score given by SeqEval: 53.24%
Accuracy given by SeqEval: 98.94%
------------------------------------------------------------
Experiment: 41

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.41      0.45      0.43       257

   micro avg       0.41      0.45      0.43       257
   macro avg       0.41      0.45      0.43       257
weighted avg       0.41      0.45      0.43       257

Precision given by SeqEval: 41.07%
Recall given by SeqEval: 44.75%
F1-Score given by SeqEval: 42.83%
Accuracy given by SeqEval: 98.72%
------------------------------------------------------------
Experiment: 42

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.62      0.54      0.58       179

   micro avg       0.62      0.54      0.58       179
   macro avg       0.62      0.54      0.58       179
weighted avg       0.62      0.54      0.58       179

Precision given by SeqEval: 61.78%
Recall given by SeqEval: 54.19%
F1-Score given by SeqEval: 57.74%
Accuracy given by SeqEval: 99.27%
------------------------------------------------------------
Experiment: 43

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.62      0.69      0.65       124

   micro avg       0.62      0.69      0.65       124
   macro avg       0.62      0.69      0.65       124
weighted avg       0.62      0.69      0.65       124

Precision given by SeqEval: 62.50%
Recall given by SeqEval: 68.55%
F1-Score given by SeqEval: 65.38%
Accuracy given by SeqEval: 99.16%
------------------------------------------------------------
Experiment: 44

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.61      0.57      0.59       100

   micro avg       0.61      0.57      0.59       100
   macro avg       0.61      0.57      0.59       100
weighted avg       0.61      0.57      0.59       100

Precision given by SeqEval: 60.64%
Recall given by SeqEval: 57.00%
F1-Score given by SeqEval: 58.76%
Accuracy given by SeqEval: 99.07%
------------------------------------------------------------
Experiment: 45

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.62      0.52      0.57       244

   micro avg       0.62      0.52      0.57       244
   macro avg       0.62      0.52      0.57       244
weighted avg       0.62      0.52      0.57       244
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 11:20:29,598] [INFO] Set up nlp object from config
[2022-09-21 11:20:29,607] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 11:20:29,607] [INFO] Resuming training for: ['ner']
[2022-09-21 11:20:29,614] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 11:20:36,072] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 11:20:52,596] [INFO] Created vocabulary
[2022-09-21 11:20:54,025] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 11:20:56,067] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    273.10    0.00    0.00    0.00    0.00
 40     200           0.00  116464.77    0.00    0.00    0.00    0.00
 80     400           0.00  65629.95   26.87   61.64   17.18    0.27
120     600           0.00  45329.81   40.52   47.21   35.50    0.41
160     800           0.00  27723.96   43.46   45.96   41.22    0.43
200    1000           0.00  17289.54   44.81   48.03   41.98    0.45
240    1200           0.00  11239.46   44.85   47.64   42.37    0.45
280    1400           0.00   7627.34   44.13   46.98   41.60    0.44
320    1600           0.00   5224.70   43.23   45.92   40.84    0.43
360    1800           0.00   3623.36   42.57   44.92   40.46    0.43
400    2000           0.00   2539.60   42.71   44.77   40.84    0.43
440    2200           0.00   2020.89   42.08   44.30   40.08    0.42
480    2400           0.00   1427.87   42.08   44.30   40.08    0.42
520    2600           0.00   1191.28   40.73   43.16   38.55    0.41
560    2800           0.00    870.38   40.08   43.17   37.40    0.40
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 11:39:20,754] [INFO] Set up nlp object from config
[2022-09-21 11:39:20,763] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 11:39:20,763] [INFO] Resuming training for: ['ner']
[2022-09-21 11:39:20,770] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 11:39:27,385] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 11:39:44,091] [INFO] Created vocabulary
[2022-09-21 11:39:45,535] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 11:39:47,644] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    221.36    0.00    0.00    0.00    0.00
 40     200           0.00  111688.36    0.00    0.00    0.00    0.00
 80     400           0.00  66758.61   28.25   46.30   20.33    0.28
120     600           0.00  43803.57   44.36   42.54   46.34    0.44
160     800           0.00  27758.14   44.03   40.69   47.97    0.44
200    1000           0.00  17763.92   44.74   41.61   48.37    0.45
240    1200           0.00  11961.49   45.07   41.58   49.19    0.45
280    1400           0.00   7977.28   45.49   42.31   49.19    0.45
320    1600           0.00   5605.93   45.08   42.20   48.37    0.45
360    1800           0.00   4089.98   43.70   40.14   47.97    0.44
400    2000           0.00   3032.63   44.65   41.46   48.37    0.45
440    2200           0.00   2275.97   43.99   40.34   48.37    0.44
480    2400           0.00   1782.84   43.91   40.20   48.37    0.44
520    2600           0.00   1374.38   43.43   39.40   48.37    0.43
560    2800           0.00   1073.68   43.38   39.60   47.97    0.43
600    3000           0.00    817.42   43.14   39.20   47.97    0.43
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 11:58:57,742] [INFO] Set up nlp object from config
[2022-09-21 11:58:57,750] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 11:58:57,750] [INFO] Resuming training for: ['ner']
[2022-09-21 11:58:57,758] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 11:59:04,233] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 11:59:20,874] [INFO] Created vocabulary
[2022-09-21 11:59:22,307] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 11:59:24,233] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    273.10    0.00    0.00    0.00    0.00
 40     200           0.00  112719.01    0.00    0.00    0.00    0.00
 80     400           0.00  67282.94   29.89   48.15   21.67    0.30
120     600           0.00  45860.56   44.95   47.08   43.00    0.45
160     800           0.00  29635.07   44.66   44.01   45.33    0.45
200    1000           0.00  19100.81   44.77   43.91   45.67    0.45
240    1200           0.00  12739.82   44.44   44.22   44.67    0.44
280    1400           0.00   8590.38   44.73   42.94   46.67    0.45
320    1600           0.00   5914.23   44.26   42.95   45.67    0.44
360    1800           0.00   4232.02   42.41   40.36   44.67    0.42
400    2000           0.00   3030.50   42.56   40.92   44.33    0.43
440    2200           0.00   2315.23   42.81   41.99   43.67    0.43
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 12:14:27,035] [INFO] Set up nlp object from config
[2022-09-21 12:14:27,044] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 12:14:27,044] [INFO] Resuming training for: ['ner']
[2022-09-21 12:14:27,051] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 12:14:33,657] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 12:14:50,389] [INFO] Created vocabulary
[2022-09-21 12:14:51,824] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 12:14:53,800] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    836.99    0.00    0.00    0.00    0.00
 40     200           0.00  122027.10    0.00    0.00    0.00    0.00
 80     400           0.00  68505.10   30.77   60.78   20.60    0.31
120     600           0.00  47273.49   44.02   52.53   37.87    0.44
160     800           0.00  30507.36   45.15   51.49   40.20    0.45
200    1000           0.00  20464.54   45.17   50.00   41.20    0.45
240    1200           0.00  13628.36   44.08   48.79   40.20    0.44
280    1400           0.00   9221.97   43.67   48.77   39.53    0.44
320    1600           0.00   6400.42   43.51   48.37   39.53    0.44
360    1800           0.00   4459.72   42.83   48.73   38.21    0.43
400    2000           0.00   3209.55   43.04   48.74   38.54    0.43
440    2200           0.00   2412.81   43.30   48.36   39.20    0.43
480    2400           0.00   1855.70   42.96   48.54   38.54    0.43
520    2600           0.00   1427.81   43.64   48.19   39.87    0.44
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs42Spacy_V.json[0m
[38;5;2mâœ” Generated output file (33 documents): gs42Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (9 documents): gs42Spacy_V.spacy[0m
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 12:35:05,456] [INFO] Set up nlp object from config
[2022-09-21 12:35:05,465] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-21 12:35:05,465] [INFO] Resuming training for: ['ner']
[2022-09-21 12:35:05,472] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-09-21 12:35:11,938] [INFO] Copying vocab from: en_core_sci_lg
[2022-09-21 12:35:28,531] [INFO] Created vocabulary
[2022-09-21 12:35:29,960] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-21 12:35:32,017] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../sciSpacyGS42[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    221.36    0.00    0.00    0.00    0.00
 40     200           0.00  109615.25    0.00    0.00    0.00    0.00
 80     400           0.00  64245.07   17.29   40.66   10.98    0.17
120     600           0.00  44646.26   45.38   52.33   40.06    0.45
160     800           0.00  28438.73   47.94   51.54   44.81    0.48
200    1000           0.00  18469.14   47.87   51.01   45.10    0.48
240    1200           0.00  12174.80   47.68   49.84   45.70    0.48
280    1400           0.00   8116.16   46.58   48.86   44.51    0.47
320    1600           0.00   5806.54   46.73   49.18   44.51    0.47
360    1800           0.00   4102.70   46.33   50.17   43.03    0.46
400    2000           0.00   3040.89   46.39   49.17   43.92    0.46
440    2200           0.00   2321.49   46.80   49.34   44.51    0.47
480    2400           0.00   1757.93   46.20   49.49   43.32    0.46
[38;5;2mâœ” Saved pipeline to output directory[0m
../sciSpacyGS42/model-last

Precision given by SeqEval: 61.54%
Recall given by SeqEval: 52.46%
F1-Score given by SeqEval: 56.64%
Accuracy given by SeqEval: 98.82%
------------------------------------------------------------
Experiment: 46

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.64      0.60      0.62       281

   micro avg       0.64      0.60      0.62       281
   macro avg       0.64      0.60      0.62       281
weighted avg       0.64      0.60      0.62       281

Precision given by SeqEval: 64.12%
Recall given by SeqEval: 59.79%
F1-Score given by SeqEval: 61.88%
Accuracy given by SeqEval: 98.13%
------------------------------------------------------------
Experiment: 47

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.47      0.42      0.44       160

   micro avg       0.47      0.42      0.44       160
   macro avg       0.47      0.42      0.44       160
weighted avg       0.47      0.42      0.44       160

Precision given by SeqEval: 46.58%
Recall given by SeqEval: 42.50%
F1-Score given by SeqEval: 44.44%
Accuracy given by SeqEval: 98.72%
------------------------------------------------------------
Experiment: 48

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.53      0.71      0.61       244

   micro avg       0.53      0.71      0.61       244
   macro avg       0.53      0.71      0.61       244
weighted avg       0.53      0.71      0.61       244

Precision given by SeqEval: 53.40%
Recall given by SeqEval: 70.90%
F1-Score given by SeqEval: 60.92%
Accuracy given by SeqEval: 97.86%
------------------------------------------------------------
Experiment: 49

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.58      0.55      0.57       260

   micro avg       0.58      0.55      0.57       260
   macro avg       0.58      0.55      0.57       260
weighted avg       0.58      0.55      0.57       260

Precision given by SeqEval: 58.30%
Recall given by SeqEval: 55.38%
F1-Score given by SeqEval: 56.80%
Accuracy given by SeqEval: 98.26%
------------------------------------------------------------
Experiment: 50

SeqEval Metrics on sciSpacy  + 42GS 34 Train + 8 Validation + 91GS Test:

              precision    recall  f1-score   support

          KP       0.54      0.60      0.57       217

   micro avg       0.54      0.60      0.57       217
   macro avg       0.54      0.60      0.57       217
weighted avg       0.54      0.60      0.57       217

Precision given by SeqEval: 54.17%
Recall given by SeqEval: 59.91%
F1-Score given by SeqEval: 56.89%
Accuracy given by SeqEval: 98.46%
------------------------------------------------------------
 
 
+------------------------------------------+ 
| PALMETTO CLUSTER PBS RESOURCES REQUESTED | 
+------------------------------------------+ 
 
mem=62gb,walltime=17:00:00,ncpus=24
 
 
+-------------------------------------+ 
| PALMETTO CLUSTER PBS RESOURCES USED | 
+-------------------------------------+ 
 
cput=17:46:33,mem=19735324kb,walltime=15:35:33,ncpus=24,cpupercent=113,vmem=49308224kb
 
 
