[38;5;2mâœ” Auto-filled config with all values[0m
[38;5;2mâœ” Saved config[0m
config.cfg
You can now add your data and train your pipeline:
python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs66Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs66Spacy_V.json[0m
[38;5;2mâœ” Generated output file (52 documents): gs66Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (14 documents): gs66Spacy_V.spacy[0m
[2022-09-10 17:33:01,708] [INFO] Set up nlp object from config
[2022-09-10 17:33:01,717] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-10 17:33:01,717] [INFO] Resuming training for: ['ner']
[2022-09-10 17:33:01,726] [INFO] Copying tokenizer from: ../cdssSciSpacy/model-best
[2022-09-10 17:33:09,194] [INFO] Copying vocab from: ../cdssSciSpacy/model-best
[2022-09-10 17:33:22,430] [INFO] Created vocabulary
[2022-09-10 17:33:23,919] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-10 17:33:25,544] [INFO] Initialized pipeline components: ['transformer']
[38;5;2mâœ” Created output directory: ../cdssSciSpacyGS66[0m
[38;5;4mâ„¹ Saving to output directory: ../cdssSciSpacyGS66[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    101.78   68.34   66.37   70.42    0.68
 28     200           0.00  64685.80   70.12   73.96   66.67    0.70
 57     400           0.00  43982.80   70.05   74.08   66.43    0.70
 85     600           0.00  29446.02   68.17   73.12   63.85    0.68
114     800           0.00  20602.20   66.33   71.35   61.97    0.66
142    1000           0.00  14682.70   65.50   70.35   61.27    0.65
171    1200           0.00  10326.07   65.84   69.63   62.44    0.66
200    1400           0.00   7671.97   64.60   68.32   61.27    0.65
228    1600           0.00   5785.21   64.09   68.35   60.33    0.64
257    1800           0.00   4432.31   64.56   69.75   60.09    0.65
[38;5;2mâœ” Saved pipeline to output directory[0m
../cdssSciSpacyGS66/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs66Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs66Spacy_V.json[0m
[38;5;2mâœ” Generated output file (52 documents): gs66Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (14 documents): gs66Spacy_V.spacy[0m
[2022-09-10 17:50:56,248] [INFO] Set up nlp object from config
[2022-09-10 17:50:56,257] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-10 17:50:56,257] [INFO] Resuming training for: ['ner']
[2022-09-10 17:50:56,266] [INFO] Copying tokenizer from: ../cdssSciSpacy/model-best
[2022-09-10 17:51:03,759] [INFO] Copying vocab from: ../cdssSciSpacy/model-best
[2022-09-10 17:51:17,009] [INFO] Created vocabulary
[2022-09-10 17:51:18,498] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-10 17:51:20,095] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../cdssSciSpacyGS66[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00      0.07   48.20   43.87   53.47    0.48
 28     200           0.00  54738.81   47.70   46.41   49.05    0.48
 57     400           0.00  40053.32   49.31   50.00   48.63    0.49
 85     600           0.00  27824.34   50.95   50.95   50.95    0.51
114     800           0.00  19575.94   49.32   48.77   49.89    0.49
142    1000           0.00  14571.54   50.10   49.90   50.32    0.50
171    1200           0.00  10499.43   50.57   49.80   51.37    0.51
200    1400           0.00   7949.63   50.10   49.49   50.74    0.50
228    1600           0.00   5820.58   49.84   48.98   50.74    0.50
257    1800           0.00   4414.47   48.95   48.65   49.26    0.49
285    2000           0.00   3482.14   49.63   49.58   49.68    0.50
314    2200           0.00   2840.82   49.22   48.37   50.11    0.49
[38;5;2mâœ” Saved pipeline to output directory[0m
../cdssSciSpacyGS66/model-last
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs66Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs66Spacy_V.json[0m
[38;5;2mâœ” Generated output file (52 documents): gs66Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (14 documents): gs66Spacy_V.spacy[0m
[2022-09-10 18:07:36,681] [INFO] Set up nlp object from config
[2022-09-10 18:07:36,691] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-10 18:07:36,691] [INFO] Resuming training for: ['ner']
[2022-09-10 18:07:36,700] [INFO] Copying tokenizer from: ../cdssSciSpacy/model-best
[2022-09-10 18:07:44,163] [INFO] Copying vocab from: ../cdssSciSpacy/model-best
[2022-09-10 18:07:57,458] [INFO] Created vocabulary
[2022-09-10 18:07:58,947] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-10 18:08:00,531] [INFO] Initialized pipeline components: ['transformer']
[38;5;4mâ„¹ Saving to output directory: ../cdssSciSpacyGS66[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    200.10   75.28   75.35   75.20    0.75
 28     200           0.00  53828.40   74.95   81.52   69.35    0.75
 57     400           0.00  36912.84   74.48   80.71   69.15    0.74
 85     600           0.00  24063.83   73.55   80.72   67.54    0.74
114     800           0.00  16171.32   73.22   78.84   68.35    0.73
142    1000           0.00  11139.48   72.77   78.06   68.15    0.73
171    1200           0.00   7794.46   72.85   79.33   67.34    0.73
200    1400           0.00   5708.21   72.81   78.69   67.74    0.73
228    1600           0.00   4222.52   72.28   77.73   67.54    0.72
[38;5;2mâœ” Saved pipeline to output directory[0m
../cdssSciSpacyGS66/model-last
Total DS: 133, Train: 52 Val: 14 Test: 67
Experiment: 1

SeqEval Metrics on sciSpacy + Synthetic 1866 Train / 622 Val + 66GS 52 Train + 14 Validation + 67GS Test:

              precision    recall  f1-score   support

          KP       0.59      0.59      0.59       213

   micro avg       0.59      0.59      0.59       213
   macro avg       0.59      0.59      0.59       213
weighted avg       0.59      0.59      0.59       213

Precision given by SeqEval: 59.15%
Recall given by SeqEval: 59.15%
F1-Score given by SeqEval: 59.15%
Accuracy given by SeqEval: 98.73%
------------------------------------------------------------
Experiment: 2

SeqEval Metrics on sciSpacy + Synthetic 1866 Train / 622 Val + 66GS 52 Train + 14 Validation + 67GS Test:

              precision    recall  f1-score   support

          KP       0.53      0.51      0.52       131

   micro avg       0.53      0.51      0.52       131
   macro avg       0.53      0.51      0.52       131
weighted avg       0.53      0.51      0.52       131

Precision given by SeqEval: 53.17%
Recall given by SeqEval: 51.15%
F1-Score given by SeqEval: 52.14%
Accuracy given by SeqEval: 99.09%
------------------------------------------------------------
Experiment: 3

SeqEval Metrics on sciSpacy + Synthetic 1866 Train / 622 Val + 66GS 52 Train + 14 Validation + 67GS Test:

              precision    recall  f1-score   support

          KP       0.61      0.38      0.47       316

   micro avg       0.61      0.38      0.47       316
   macro avg       0.61      0.38      0.47       316
weighted avg       0.61      0.38      0.47       316

Precision given by SeqEval: 61.34%
Recall given by SeqEval: 37.66%
F1-Score given by SeqEval: 46.67%
Accuracy given by SeqEval: 98.41%
------------------------------------------------------------
 
 
+------------------------------------------+ 
| PALMETTO CLUSTER PBS RESOURCES REQUESTED | 
+------------------------------------------+ 
 
mem=62gb,walltime=10:00:00,ncpus=24
 
 
+-------------------------------------+ 
| PALMETTO CLUSTER PBS RESOURCES USED | 
+-------------------------------------+ 
 
cput=00:52:13,mem=15879312kb,walltime=00:48:26,ncpus=24,cpupercent=103,vmem=47406220kb
 
 
