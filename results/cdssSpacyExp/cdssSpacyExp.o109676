[38;5;2mâœ” Auto-filled config with all values[0m
[38;5;2mâœ” Saved config[0m
config.cfg
You can now add your data and train your pipeline:
python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs66Spacy_T.json[0m
[38;5;4mâ„¹ Auto-detected token-per-line NER format[0m
[38;5;3mâš  Document delimiters found, automatic document segmentation with `-n`
disabled.[0m
[38;5;3mâš  No sentence boundaries found. Use `-s` to automatically segment
sentences.[0m
[38;5;2mâœ” Generated output file (1 documents): gs66Spacy_V.json[0m
[38;5;2mâœ” Generated output file (52 documents): gs66Spacy_T.spacy[0m
[38;5;2mâœ” Generated output file (14 documents): gs66Spacy_V.spacy[0m
[2022-09-10 17:24:53,880] [INFO] Set up nlp object from config
[2022-09-10 17:24:53,890] [INFO] Pipeline: ['transformer', 'ner']
[2022-09-10 17:24:53,890] [INFO] Resuming training for: ['ner']
[2022-09-10 17:24:53,899] [INFO] Copying tokenizer from: ../cdssSciSpacy/model-best
[2022-09-10 17:25:01,427] [INFO] Copying vocab from: ../cdssSciSpacy/model-best
[2022-09-10 17:25:14,529] [INFO] Created vocabulary
[2022-09-10 17:25:16,022] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-09-10 17:25:18,502] [INFO] Initialized pipeline components: ['transformer']
[38;5;2mâœ” Created output directory: ../cdssSciSpacyGS66[0m
[38;5;4mâ„¹ Saving to output directory: ../cdssSciSpacyGS66[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    101.78   68.34   66.37   70.42    0.68
 28     200           0.00  64685.80   70.12   73.96   66.67    0.70
 57     400           0.00  43982.47   70.05   74.08   66.43    0.70
 85     600           0.00  29445.49   68.17   73.12   63.85    0.68
 
 
+------------------------------------------+ 
| PALMETTO CLUSTER PBS RESOURCES REQUESTED | 
+------------------------------------------+ 
 
mem=62gb,walltime=10:00:00,ncpus=24
 
 
+-------------------------------------+ 
| PALMETTO CLUSTER PBS RESOURCES USED | 
+-------------------------------------+ 
 
cput=00:07:00,mem=11229624kb,walltime=00:07:21,ncpus=24,cpupercent=72,vmem=39492404kb
 
 
