(pytorch) [rgoli@node0089 NLP_KPIdentify]$ python -m spacy train -g 0 keywordExtraction/config.cfg --output ./cdssSpacyBERToutput3 --paths.train ./data/finetuneBERT_T.spacy --paths.dev ./data/finetuneBERT_V.spacy
✔ Created output directory: cdssSpacyBERToutput3
ℹ Saving to output directory: cdssSpacyBERToutput3
ℹ Using GPU: 0

=========================== Initializing pipeline ===========================
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-08-30 20:17:49,579] [INFO] Set up nlp object from config
[2022-08-30 20:17:49,587] [INFO] Pipeline: ['transformer', 'ner']
[2022-08-30 20:17:49,587] [INFO] Resuming training for: ['ner']
[2022-08-30 20:17:49,594] [INFO] Copying tokenizer from: en_core_sci_lg
/home/rgoli/.conda/envs/pytorch/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_sci_lg' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
[2022-08-30 20:17:55,822] [INFO] Copying vocab from: en_core_sci_lg
[2022-08-30 20:18:11,920] [INFO] Created vocabulary
[2022-08-30 20:18:13,314] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-08-30 20:18:15,936] [INFO] Initialized pipeline components: ['transformer']
✔ Initialized pipeline

============================= Training pipeline =============================
ℹ Pipeline: ['transformer', 'ner']
ℹ Initial learn rate: 0.0
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
  0       0           0.00    395.92    0.00    0.00    0.00    0.00
 40     200           0.00  107336.37    0.00    0.00    0.00    0.00
 80     400           0.00  59192.31   43.91   63.58   33.54    0.44
120     600           0.00  34343.75   50.56   52.82   48.48    0.51
160     800           0.00  21407.70   48.62   49.07   48.17    0.49
200    1000           0.00  13889.52   49.24   49.39   49.09    0.49
240    1200           0.00   9322.70   48.09   48.31   47.87    0.48
280    1400           0.00   6357.76   47.58   47.29   47.87    0.48
320    1600           0.00   4477.03   47.02   47.09   46.95    0.47
360    1800           0.00   3222.26   46.91   47.50   46.34    0.47
400    2000           0.00   2453.77   46.20   46.06   46.34    0.46
440    2200           0.00   1834.89   47.96   47.46   48.48    0.48
✔ Saved pipeline to output directory
cdssSpacyBERToutput3/model-last
(pytorch) [rgoli@node0089 NLP_KPIdentify]$